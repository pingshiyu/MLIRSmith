// -----// IR Dump After ConvertVectorToLLVMPass (convert-vector-to-llvm) //----- //
#map = affine_map<(d0, d1) -> (d0)>
#set = affine_set<() : (80610 >= 0, 1340 >= 0, 81930 >= 0)>
#set1 = affine_set<() : (24 >= 0, 30 >= 0)>
module {
  llvm.func @printF16(i16)
  llvm.func @printF32(f32)
  llvm.func @printNewline()
  llvm.func @printI64(i64)
  func.func @func1(%arg0: vector<16xi32>, %arg1: memref<?xf32>, %arg2: i1) {
    %cst = arith.constant dense<[true, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false]> : vector<16xi1>
    %cst_0 = arith.constant dense<0x4D08837C> : vector<24x16xf32>
    %0 = builtin.unrealized_conversion_cast %cst_0 : vector<24x16xf32> to !llvm.array<24 x vector<16xf32>>
    %idx432 = index.constant 432
    %cst_1 = arith.constant dense<8> : vector<16xindex>
    %1 = builtin.unrealized_conversion_cast %cst_1 : vector<16xindex> to vector<16xi64>
    %false = arith.constant false
    %c265471212_i64 = arith.constant 265471212 : i64
    %c4623_i16 = arith.constant 4623 : i16
    %c22394_i16 = arith.constant 22394 : i16
    %c1941353413_i32 = arith.constant 1941353413 : i32
    %c-29278_i16 = arith.constant -29278 : i16
    %c281204932_i64 = arith.constant 281204932 : i64
    %cst_2 = arith.constant 0x4D08837C : f32
    %cst_3 = arith.constant 3.350400e+04 : f16
    %cst_4 = arith.constant 5.033600e+04 : f16
    %c771421837_i32 = arith.constant 771421837 : i32
    %c445093745_i32 = arith.constant 445093745 : i32
    %true = arith.constant true
    %cst_5 = arith.constant 0x4E228E1D : f32
    %cst_6 = arith.constant 1.731200e+04 : f16
    %c0 = arith.constant 0 : index
    %2 = builtin.unrealized_conversion_cast %c0 : index to i64
    %c4 = arith.constant 4 : index
    %c5 = arith.constant 5 : index
    %3 = builtin.unrealized_conversion_cast %c5 : index to i64
    %c6 = arith.constant 6 : index
    %c7 = arith.constant 7 : index
    %4 = builtin.unrealized_conversion_cast %c7 : index to i64
    %c9 = arith.constant 9 : index
    %c10 = arith.constant 10 : index
    %c12 = arith.constant 12 : index
    %c13 = arith.constant 13 : index
    %c17 = arith.constant 17 : index
    %c21 = arith.constant 21 : index
    %c22 = arith.constant 22 : index
    %c24 = arith.constant 24 : index
    %c25 = arith.constant 25 : index
    %c26 = arith.constant 26 : index
    %5 = builtin.unrealized_conversion_cast %c26 : index to i64
    %c29 = arith.constant 29 : index
    %c30 = arith.constant 30 : index
    %6 = tensor.empty(%c17) : tensor<?x3xi1>
    %7 = tensor.empty() : tensor<16xi64>
    %8 = tensor.empty() : tensor<16xi1>
    %alloc = memref.alloc(%c24) : memref<?xf16>
    %alloc_7 = memref.alloc() : memref<16xf32>
    %9 = builtin.unrealized_conversion_cast %alloc_7 : memref<16xf32> to !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>
    %alloc_8 = memref.alloc(%c12, %c26) : memref<?x?xi16>
    %alloc_9 = memref.alloc(%c12) : memref<?xf16>
    %alloc_10 = memref.alloc(%c9) : memref<?x16xi64>
    %alloc_11 = memref.alloc(%c21) : memref<?xf16>
    %alloc_12 = memref.alloc(%c6) : memref<?xi1>
    %10 = builtin.unrealized_conversion_cast %alloc_12 : memref<?xi1> to !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>
    %alloc_13 = memref.alloc(%c9) : memref<?xi32>
    %alloc_14 = memref.alloc(%c9) : memref<?xi16>
    %11 = spirv.CL.s_abs %c1941353413_i32 : i32
    %alloc_15 = memref.alloc() : memref<16xi1>
    %12 = llvm.extractvalue %10[1] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %13 = llvm.getelementptr %12[%2] : (!llvm.ptr, i64) -> !llvm.ptr, i1
    %14 = llvm.load %13 {alignment = 1 : i64} : !llvm.ptr -> vector<16xi1>
    %15 = affine.vector_load %alloc_14[%c25] : memref<?xi16>, vector<3xi16>
    memref.store %c22394_i16, %alloc_14[%c0] : memref<?xi16>
    %16 = spirv.GL.FMix %cst_6 : f16, %cst_4 : f16, %cst_4 : f16 -> f16
    %17 = spirv.CL.fabs %16 : f16
    %18 = spirv.GL.Log %cst_6 : f16
    %19 = spirv.GL.InverseSqrt %cst_4 : f16
    %20 = spirv.GL.Acos %cst_3 : f16
    %21 = spirv.CL.cos %cst_3 : f16
    %22 = spirv.FOrdNotEqual %cst_4, %cst_3 : f16
    %23 = spirv.CL.pow %19, %18 : f16
    %24 = spirv.CL.exp %cst_4 : f16
    %25 = spirv.FOrdLessThanEqual %18, %cst_3 : f16
    %26 = spirv.CL.log %21 : f16
    %27 = spirv.FUnordNotEqual %cst_5, %cst_2 : f32
    scf.parallel (%arg3, %arg4) = (%c6, %c10) to (%c5, %c29) step (%c22, %c26) {
      memref.copy %alloc_11, %alloc_9 : memref<?xf16> to memref<?xf16>
      %510 = affine.if #set() -> memref<16xi16> {
        %alloc_19 = memref.alloc() : memref<16xi16>
        affine.yield %alloc_19 : memref<16xi16>
      } else {
        affine.store %11, %alloc_13[%c4] : memref<?xi32>
        %alloc_19 = memref.alloc() : memref<16xi16>
        affine.yield %alloc_19 : memref<16xi16>
      }
      bufferization.dealloc_tensor %6 : tensor<?x3xi1>
      scf.yield
    }
    %28 = spirv.CL.rint %cst_5 : f32
    %29 = spirv.CL.rint %26 : f16
    affine.vector_store %14, %alloc_12[%c24] : memref<?xi1>, vector<16xi1>
    %30 = spirv.CL.cos %20 : f16
    %31 = spirv.IsNan %cst_5 : f32
    %32 = spirv.BitReverse %c445093745_i32 : i32
    memref.store %c281204932_i64, %alloc_10[%c0, %c0] : memref<?x16xi64>
    %33 = spirv.GL.FSign %28 : f32
    %34 = spirv.CL.ceil %18 : f16
    %35 = llvm.mlir.undef : vector<16xf32>
    %36 = llvm.mlir.constant(0 : i32) : i32
    %37 = llvm.insertelement %28, %35[%36 : i32] : vector<16xf32>
    %38 = llvm.shufflevector %37, %35 [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] : vector<16xf32> 
    %39 = llvm.intr.fmuladd(%38, %38, %38)  : (vector<16xf32>, vector<16xf32>, vector<16xf32>) -> vector<16xf32>
    %40 = spirv.CL.s_min %c771421837_i32, %11 : i32
    bufferization.dealloc_tensor %7 : tensor<16xi64>
    %41 = affine.vector_load %arg1[%c0] : memref<?xf32>, vector<24xf32>
    %42 = spirv.CL.erf %19 : f16
    %43 = spirv.UGreaterThanEqual %c265471212_i64, %c281204932_i64 : i64
    %44 = spirv.GL.Acos %18 : f16
    %45 = spirv.CL.rint %cst_3 : f16
    %cst_16 = arith.constant 0.000000e+00 : f32
    %cst_17 = arith.constant dense<0.000000e+00> : vector<24x16xf32>
    %46 = builtin.unrealized_conversion_cast %cst_17 : vector<24x16xf32> to !llvm.array<24 x vector<16xf32>>
    %47 = llvm.extractvalue %0[0] : !llvm.array<24 x vector<16xf32>> 
    %48 = llvm.extractvalue %0[0] : !llvm.array<24 x vector<16xf32>> 
    %49 = llvm.extractvalue %0[0] : !llvm.array<24 x vector<16xf32>> 
    %50 = llvm.intr.fmuladd(%47, %48, %49)  : (vector<16xf32>, vector<16xf32>, vector<16xf32>) -> vector<16xf32>
    %51 = llvm.insertvalue %50, %46[0] : !llvm.array<24 x vector<16xf32>> 
    %52 = llvm.extractvalue %0[1] : !llvm.array<24 x vector<16xf32>> 
    %53 = llvm.extractvalue %0[1] : !llvm.array<24 x vector<16xf32>> 
    %54 = llvm.extractvalue %0[1] : !llvm.array<24 x vector<16xf32>> 
    %55 = llvm.intr.fmuladd(%52, %53, %54)  : (vector<16xf32>, vector<16xf32>, vector<16xf32>) -> vector<16xf32>
    %56 = llvm.insertvalue %55, %51[1] : !llvm.array<24 x vector<16xf32>> 
    %57 = llvm.extractvalue %0[2] : !llvm.array<24 x vector<16xf32>> 
    %58 = llvm.extractvalue %0[2] : !llvm.array<24 x vector<16xf32>> 
    %59 = llvm.extractvalue %0[2] : !llvm.array<24 x vector<16xf32>> 
    %60 = llvm.intr.fmuladd(%57, %58, %59)  : (vector<16xf32>, vector<16xf32>, vector<16xf32>) -> vector<16xf32>
    %61 = llvm.insertvalue %60, %56[2] : !llvm.array<24 x vector<16xf32>> 
    %62 = llvm.extractvalue %0[3] : !llvm.array<24 x vector<16xf32>> 
    %63 = llvm.extractvalue %0[3] : !llvm.array<24 x vector<16xf32>> 
    %64 = llvm.extractvalue %0[3] : !llvm.array<24 x vector<16xf32>> 
    %65 = llvm.intr.fmuladd(%62, %63, %64)  : (vector<16xf32>, vector<16xf32>, vector<16xf32>) -> vector<16xf32>
    %66 = llvm.insertvalue %65, %61[3] : !llvm.array<24 x vector<16xf32>> 
    %67 = llvm.extractvalue %0[4] : !llvm.array<24 x vector<16xf32>> 
    %68 = llvm.extractvalue %0[4] : !llvm.array<24 x vector<16xf32>> 
    %69 = llvm.extractvalue %0[4] : !llvm.array<24 x vector<16xf32>> 
    %70 = llvm.intr.fmuladd(%67, %68, %69)  : (vector<16xf32>, vector<16xf32>, vector<16xf32>) -> vector<16xf32>
    %71 = llvm.insertvalue %70, %66[4] : !llvm.array<24 x vector<16xf32>> 
    %72 = llvm.extractvalue %0[5] : !llvm.array<24 x vector<16xf32>> 
    %73 = llvm.extractvalue %0[5] : !llvm.array<24 x vector<16xf32>> 
    %74 = llvm.extractvalue %0[5] : !llvm.array<24 x vector<16xf32>> 
    %75 = llvm.intr.fmuladd(%72, %73, %74)  : (vector<16xf32>, vector<16xf32>, vector<16xf32>) -> vector<16xf32>
    %76 = llvm.insertvalue %75, %71[5] : !llvm.array<24 x vector<16xf32>> 
    %77 = llvm.extractvalue %0[6] : !llvm.array<24 x vector<16xf32>> 
    %78 = llvm.extractvalue %0[6] : !llvm.array<24 x vector<16xf32>> 
    %79 = llvm.extractvalue %0[6] : !llvm.array<24 x vector<16xf32>> 
    %80 = llvm.intr.fmuladd(%77, %78, %79)  : (vector<16xf32>, vector<16xf32>, vector<16xf32>) -> vector<16xf32>
    %81 = llvm.insertvalue %80, %76[6] : !llvm.array<24 x vector<16xf32>> 
    %82 = llvm.extractvalue %0[7] : !llvm.array<24 x vector<16xf32>> 
    %83 = llvm.extractvalue %0[7] : !llvm.array<24 x vector<16xf32>> 
    %84 = llvm.extractvalue %0[7] : !llvm.array<24 x vector<16xf32>> 
    %85 = llvm.intr.fmuladd(%82, %83, %84)  : (vector<16xf32>, vector<16xf32>, vector<16xf32>) -> vector<16xf32>
    %86 = llvm.insertvalue %85, %81[7] : !llvm.array<24 x vector<16xf32>> 
    %87 = llvm.extractvalue %0[8] : !llvm.array<24 x vector<16xf32>> 
    %88 = llvm.extractvalue %0[8] : !llvm.array<24 x vector<16xf32>> 
    %89 = llvm.extractvalue %0[8] : !llvm.array<24 x vector<16xf32>> 
    %90 = llvm.intr.fmuladd(%87, %88, %89)  : (vector<16xf32>, vector<16xf32>, vector<16xf32>) -> vector<16xf32>
    %91 = llvm.insertvalue %90, %86[8] : !llvm.array<24 x vector<16xf32>> 
    %92 = llvm.extractvalue %0[9] : !llvm.array<24 x vector<16xf32>> 
    %93 = llvm.extractvalue %0[9] : !llvm.array<24 x vector<16xf32>> 
    %94 = llvm.extractvalue %0[9] : !llvm.array<24 x vector<16xf32>> 
    %95 = llvm.intr.fmuladd(%92, %93, %94)  : (vector<16xf32>, vector<16xf32>, vector<16xf32>) -> vector<16xf32>
    %96 = llvm.insertvalue %95, %91[9] : !llvm.array<24 x vector<16xf32>> 
    %97 = llvm.extractvalue %0[10] : !llvm.array<24 x vector<16xf32>> 
    %98 = llvm.extractvalue %0[10] : !llvm.array<24 x vector<16xf32>> 
    %99 = llvm.extractvalue %0[10] : !llvm.array<24 x vector<16xf32>> 
    %100 = llvm.intr.fmuladd(%97, %98, %99)  : (vector<16xf32>, vector<16xf32>, vector<16xf32>) -> vector<16xf32>
    %101 = llvm.insertvalue %100, %96[10] : !llvm.array<24 x vector<16xf32>> 
    %102 = llvm.extractvalue %0[11] : !llvm.array<24 x vector<16xf32>> 
    %103 = llvm.extractvalue %0[11] : !llvm.array<24 x vector<16xf32>> 
    %104 = llvm.extractvalue %0[11] : !llvm.array<24 x vector<16xf32>> 
    %105 = llvm.intr.fmuladd(%102, %103, %104)  : (vector<16xf32>, vector<16xf32>, vector<16xf32>) -> vector<16xf32>
    %106 = llvm.insertvalue %105, %101[11] : !llvm.array<24 x vector<16xf32>> 
    %107 = llvm.extractvalue %0[12] : !llvm.array<24 x vector<16xf32>> 
    %108 = llvm.extractvalue %0[12] : !llvm.array<24 x vector<16xf32>> 
    %109 = llvm.extractvalue %0[12] : !llvm.array<24 x vector<16xf32>> 
    %110 = llvm.intr.fmuladd(%107, %108, %109)  : (vector<16xf32>, vector<16xf32>, vector<16xf32>) -> vector<16xf32>
    %111 = llvm.insertvalue %110, %106[12] : !llvm.array<24 x vector<16xf32>> 
    %112 = llvm.extractvalue %0[13] : !llvm.array<24 x vector<16xf32>> 
    %113 = llvm.extractvalue %0[13] : !llvm.array<24 x vector<16xf32>> 
    %114 = llvm.extractvalue %0[13] : !llvm.array<24 x vector<16xf32>> 
    %115 = llvm.intr.fmuladd(%112, %113, %114)  : (vector<16xf32>, vector<16xf32>, vector<16xf32>) -> vector<16xf32>
    %116 = llvm.insertvalue %115, %111[13] : !llvm.array<24 x vector<16xf32>> 
    %117 = llvm.extractvalue %0[14] : !llvm.array<24 x vector<16xf32>> 
    %118 = llvm.extractvalue %0[14] : !llvm.array<24 x vector<16xf32>> 
    %119 = llvm.extractvalue %0[14] : !llvm.array<24 x vector<16xf32>> 
    %120 = llvm.intr.fmuladd(%117, %118, %119)  : (vector<16xf32>, vector<16xf32>, vector<16xf32>) -> vector<16xf32>
    %121 = llvm.insertvalue %120, %116[14] : !llvm.array<24 x vector<16xf32>> 
    %122 = llvm.extractvalue %0[15] : !llvm.array<24 x vector<16xf32>> 
    %123 = llvm.extractvalue %0[15] : !llvm.array<24 x vector<16xf32>> 
    %124 = llvm.extractvalue %0[15] : !llvm.array<24 x vector<16xf32>> 
    %125 = llvm.intr.fmuladd(%122, %123, %124)  : (vector<16xf32>, vector<16xf32>, vector<16xf32>) -> vector<16xf32>
    %126 = llvm.insertvalue %125, %121[15] : !llvm.array<24 x vector<16xf32>> 
    %127 = llvm.extractvalue %0[16] : !llvm.array<24 x vector<16xf32>> 
    %128 = llvm.extractvalue %0[16] : !llvm.array<24 x vector<16xf32>> 
    %129 = llvm.extractvalue %0[16] : !llvm.array<24 x vector<16xf32>> 
    %130 = llvm.intr.fmuladd(%127, %128, %129)  : (vector<16xf32>, vector<16xf32>, vector<16xf32>) -> vector<16xf32>
    %131 = llvm.insertvalue %130, %126[16] : !llvm.array<24 x vector<16xf32>> 
    %132 = llvm.extractvalue %0[17] : !llvm.array<24 x vector<16xf32>> 
    %133 = llvm.extractvalue %0[17] : !llvm.array<24 x vector<16xf32>> 
    %134 = llvm.extractvalue %0[17] : !llvm.array<24 x vector<16xf32>> 
    %135 = llvm.intr.fmuladd(%132, %133, %134)  : (vector<16xf32>, vector<16xf32>, vector<16xf32>) -> vector<16xf32>
    %136 = llvm.insertvalue %135, %131[17] : !llvm.array<24 x vector<16xf32>> 
    %137 = llvm.extractvalue %0[18] : !llvm.array<24 x vector<16xf32>> 
    %138 = llvm.extractvalue %0[18] : !llvm.array<24 x vector<16xf32>> 
    %139 = llvm.extractvalue %0[18] : !llvm.array<24 x vector<16xf32>> 
    %140 = llvm.intr.fmuladd(%137, %138, %139)  : (vector<16xf32>, vector<16xf32>, vector<16xf32>) -> vector<16xf32>
    %141 = llvm.insertvalue %140, %136[18] : !llvm.array<24 x vector<16xf32>> 
    %142 = llvm.extractvalue %0[19] : !llvm.array<24 x vector<16xf32>> 
    %143 = llvm.extractvalue %0[19] : !llvm.array<24 x vector<16xf32>> 
    %144 = llvm.extractvalue %0[19] : !llvm.array<24 x vector<16xf32>> 
    %145 = llvm.intr.fmuladd(%142, %143, %144)  : (vector<16xf32>, vector<16xf32>, vector<16xf32>) -> vector<16xf32>
    %146 = llvm.insertvalue %145, %141[19] : !llvm.array<24 x vector<16xf32>> 
    %147 = llvm.extractvalue %0[20] : !llvm.array<24 x vector<16xf32>> 
    %148 = llvm.extractvalue %0[20] : !llvm.array<24 x vector<16xf32>> 
    %149 = llvm.extractvalue %0[20] : !llvm.array<24 x vector<16xf32>> 
    %150 = llvm.intr.fmuladd(%147, %148, %149)  : (vector<16xf32>, vector<16xf32>, vector<16xf32>) -> vector<16xf32>
    %151 = llvm.insertvalue %150, %146[20] : !llvm.array<24 x vector<16xf32>> 
    %152 = llvm.extractvalue %0[21] : !llvm.array<24 x vector<16xf32>> 
    %153 = llvm.extractvalue %0[21] : !llvm.array<24 x vector<16xf32>> 
    %154 = llvm.extractvalue %0[21] : !llvm.array<24 x vector<16xf32>> 
    %155 = llvm.intr.fmuladd(%152, %153, %154)  : (vector<16xf32>, vector<16xf32>, vector<16xf32>) -> vector<16xf32>
    %156 = llvm.insertvalue %155, %151[21] : !llvm.array<24 x vector<16xf32>> 
    %157 = llvm.extractvalue %0[22] : !llvm.array<24 x vector<16xf32>> 
    %158 = llvm.extractvalue %0[22] : !llvm.array<24 x vector<16xf32>> 
    %159 = llvm.extractvalue %0[22] : !llvm.array<24 x vector<16xf32>> 
    %160 = llvm.intr.fmuladd(%157, %158, %159)  : (vector<16xf32>, vector<16xf32>, vector<16xf32>) -> vector<16xf32>
    %161 = llvm.insertvalue %160, %156[22] : !llvm.array<24 x vector<16xf32>> 
    %162 = llvm.extractvalue %0[23] : !llvm.array<24 x vector<16xf32>> 
    %163 = llvm.extractvalue %0[23] : !llvm.array<24 x vector<16xf32>> 
    %164 = llvm.extractvalue %0[23] : !llvm.array<24 x vector<16xf32>> 
    %165 = llvm.intr.fmuladd(%162, %163, %164)  : (vector<16xf32>, vector<16xf32>, vector<16xf32>) -> vector<16xf32>
    %166 = llvm.insertvalue %165, %161[23] : !llvm.array<24 x vector<16xf32>> 
    %167 = builtin.unrealized_conversion_cast %166 : !llvm.array<24 x vector<16xf32>> to vector<24x16xf32>
    %168 = spirv.CL.log %17 : f16
    %169 = spirv.CL.ceil %20 : f16
    %170 = spirv.CL.s_max %c771421837_i32, %c1941353413_i32 : i32
    %171 = spirv.GL.Asin %21 : f16
    %172 = llvm.bitcast %39 : vector<16xf32> to vector<16xi32>
    vector.print %14 : vector<16xi1>
    %173 = spirv.FOrdGreaterThan %cst_3, %24 : f16
    %174 = spirv.CL.exp %cst_6 : f16
    %175 = spirv.CL.round %21 : f16
    %176 = spirv.CL.floor %175 : f16
    %177 = spirv.IEqual %c-29278_i16, %c22394_i16 : i16
    %178 = spirv.CL.pow %45, %24 : f16
    %179 = affine.load %alloc_10[%c30, %c4] : memref<?x16xi64>
    %180 = spirv.CL.cos %17 : f16
    %181 = spirv.CL.rsqrt %19 : f16
    %182 = memref.realloc %alloc : memref<?xf16> to memref<3xf16>
    linalg.transpose ins(%alloc_11 : memref<?xf16>) outs(%alloc : memref<?xf16>) permutation = [0] 
    %183 = spirv.GL.Cosh %29 : f16
    %184 = spirv.UGreaterThan %c-29278_i16, %c22394_i16 : i16
    %185 = spirv.CL.ceil %30 : f16
    scf.parallel (%arg3) = (%c13) to (%idx432) step (%c7) {
      vector.warp_execute_on_lane_0(%c0)[32] {
        memref.copy %arg1, %arg1 : memref<?xf32> to memref<?xf32>
      }
      memref.copy %alloc_8, %alloc_8 : memref<?x?xi16> to memref<?x?xi16>
      %510 = memref.realloc %alloc_13 : memref<?xi32> to memref<3xi32>
      scf.yield
    }
    %186 = spirv.CL.erf %30 : f16
    %187 = spirv.GL.UMax %32, %c1941353413_i32 : i32
    %188 = spirv.GL.Floor %183 : f16
    %189 = spirv.GL.SSign %c4623_i16 : i16
    %190 = spirv.CL.tanh %18 : f16
    %191 = spirv.GL.FSign %17 : f16
    linalg.transpose ins(%8 : tensor<16xi1>) outs(%alloc_15 : memref<16xi1>) permutation = [0] 
    %192 = spirv.GL.FMax %24, %42 : f16
    %193 = spirv.GL.UClamp %c4623_i16, %c4623_i16, %c22394_i16 : i16
    %194 = spirv.CL.log %cst_6 : f16
    %195 = spirv.Unordered %18, %24 : f16
    %196 = llvm.extractvalue %9[1] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %197 = llvm.getelementptr %196[%3] : (!llvm.ptr, i64) -> !llvm.ptr, f32
    %198 = llvm.getelementptr %197[%1] : (!llvm.ptr, vector<16xi64>) -> !llvm.vec<16 x ptr>, f32
    llvm.intr.masked.scatter %38, %198, %cst {alignment = 4 : i32} : vector<16xf32>, vector<16xi1> into !llvm.vec<16 x ptr>
    %199 = spirv.FUnordLessThanEqual %19, %180 : f16
    %alloc_18 = memref.alloc() : memref<16x3xi64>
    %200 = builtin.unrealized_conversion_cast %alloc_18 : memref<16x3xi64> to !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)>
    %201 = llvm.mlir.undef : !llvm.array<24 x vector<16xi64>>
    %202 = llvm.mlir.undef : vector<16xi64>
    %203 = llvm.mlir.constant(0 : i32) : i32
    %204 = llvm.insertelement %179, %202[%203 : i32] : vector<16xi64>
    %205 = llvm.shufflevector %204, %204 [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] : vector<16xi64> 
    %206 = llvm.insertvalue %205, %201[0] : !llvm.array<24 x vector<16xi64>> 
    %207 = llvm.insertvalue %205, %206[1] : !llvm.array<24 x vector<16xi64>> 
    %208 = llvm.insertvalue %205, %207[2] : !llvm.array<24 x vector<16xi64>> 
    %209 = llvm.insertvalue %205, %208[3] : !llvm.array<24 x vector<16xi64>> 
    %210 = llvm.insertvalue %205, %209[4] : !llvm.array<24 x vector<16xi64>> 
    %211 = llvm.insertvalue %205, %210[5] : !llvm.array<24 x vector<16xi64>> 
    %212 = llvm.insertvalue %205, %211[6] : !llvm.array<24 x vector<16xi64>> 
    %213 = llvm.insertvalue %205, %212[7] : !llvm.array<24 x vector<16xi64>> 
    %214 = llvm.insertvalue %205, %213[8] : !llvm.array<24 x vector<16xi64>> 
    %215 = llvm.insertvalue %205, %214[9] : !llvm.array<24 x vector<16xi64>> 
    %216 = llvm.insertvalue %205, %215[10] : !llvm.array<24 x vector<16xi64>> 
    %217 = llvm.insertvalue %205, %216[11] : !llvm.array<24 x vector<16xi64>> 
    %218 = llvm.insertvalue %205, %217[12] : !llvm.array<24 x vector<16xi64>> 
    %219 = llvm.insertvalue %205, %218[13] : !llvm.array<24 x vector<16xi64>> 
    %220 = llvm.insertvalue %205, %219[14] : !llvm.array<24 x vector<16xi64>> 
    %221 = llvm.insertvalue %205, %220[15] : !llvm.array<24 x vector<16xi64>> 
    %222 = llvm.insertvalue %205, %221[16] : !llvm.array<24 x vector<16xi64>> 
    %223 = llvm.insertvalue %205, %222[17] : !llvm.array<24 x vector<16xi64>> 
    %224 = llvm.insertvalue %205, %223[18] : !llvm.array<24 x vector<16xi64>> 
    %225 = llvm.insertvalue %205, %224[19] : !llvm.array<24 x vector<16xi64>> 
    %226 = llvm.insertvalue %205, %225[20] : !llvm.array<24 x vector<16xi64>> 
    %227 = llvm.insertvalue %205, %226[21] : !llvm.array<24 x vector<16xi64>> 
    %228 = llvm.insertvalue %205, %227[22] : !llvm.array<24 x vector<16xi64>> 
    %229 = llvm.insertvalue %205, %228[23] : !llvm.array<24 x vector<16xi64>> 
    %230 = builtin.unrealized_conversion_cast %229 : !llvm.array<24 x vector<16xi64>> to vector<24x16xi64>
    %231 = llvm.mlir.undef : !llvm.array<24 x vector<16xi1>>
    %232 = llvm.mlir.undef : vector<16xi1>
    %233 = llvm.mlir.constant(0 : i32) : i32
    %234 = llvm.insertelement %195, %232[%233 : i32] : vector<16xi1>
    %235 = llvm.shufflevector %234, %234 [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] : vector<16xi1> 
    %236 = llvm.insertvalue %235, %231[0] : !llvm.array<24 x vector<16xi1>> 
    %237 = llvm.insertvalue %235, %236[1] : !llvm.array<24 x vector<16xi1>> 
    %238 = llvm.insertvalue %235, %237[2] : !llvm.array<24 x vector<16xi1>> 
    %239 = llvm.insertvalue %235, %238[3] : !llvm.array<24 x vector<16xi1>> 
    %240 = llvm.insertvalue %235, %239[4] : !llvm.array<24 x vector<16xi1>> 
    %241 = llvm.insertvalue %235, %240[5] : !llvm.array<24 x vector<16xi1>> 
    %242 = llvm.insertvalue %235, %241[6] : !llvm.array<24 x vector<16xi1>> 
    %243 = llvm.insertvalue %235, %242[7] : !llvm.array<24 x vector<16xi1>> 
    %244 = llvm.insertvalue %235, %243[8] : !llvm.array<24 x vector<16xi1>> 
    %245 = llvm.insertvalue %235, %244[9] : !llvm.array<24 x vector<16xi1>> 
    %246 = llvm.insertvalue %235, %245[10] : !llvm.array<24 x vector<16xi1>> 
    %247 = llvm.insertvalue %235, %246[11] : !llvm.array<24 x vector<16xi1>> 
    %248 = llvm.insertvalue %235, %247[12] : !llvm.array<24 x vector<16xi1>> 
    %249 = llvm.insertvalue %235, %248[13] : !llvm.array<24 x vector<16xi1>> 
    %250 = llvm.insertvalue %235, %249[14] : !llvm.array<24 x vector<16xi1>> 
    %251 = llvm.insertvalue %235, %250[15] : !llvm.array<24 x vector<16xi1>> 
    %252 = llvm.insertvalue %235, %251[16] : !llvm.array<24 x vector<16xi1>> 
    %253 = llvm.insertvalue %235, %252[17] : !llvm.array<24 x vector<16xi1>> 
    %254 = llvm.insertvalue %235, %253[18] : !llvm.array<24 x vector<16xi1>> 
    %255 = llvm.insertvalue %235, %254[19] : !llvm.array<24 x vector<16xi1>> 
    %256 = llvm.insertvalue %235, %255[20] : !llvm.array<24 x vector<16xi1>> 
    %257 = llvm.insertvalue %235, %256[21] : !llvm.array<24 x vector<16xi1>> 
    %258 = llvm.insertvalue %235, %257[22] : !llvm.array<24 x vector<16xi1>> 
    %259 = llvm.insertvalue %235, %258[23] : !llvm.array<24 x vector<16xi1>> 
    %260 = builtin.unrealized_conversion_cast %259 : !llvm.array<24 x vector<16xi1>> to vector<24x16xi1>
    %261 = llvm.mlir.undef : !llvm.array<24 x vector<16xi32>>
    %262 = llvm.mlir.undef : vector<16xi32>
    %263 = llvm.mlir.constant(0 : i32) : i32
    %264 = llvm.insertelement %187, %262[%263 : i32] : vector<16xi32>
    %265 = llvm.shufflevector %264, %264 [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] : vector<16xi32> 
    %266 = llvm.insertvalue %265, %261[0] : !llvm.array<24 x vector<16xi32>> 
    %267 = llvm.insertvalue %265, %266[1] : !llvm.array<24 x vector<16xi32>> 
    %268 = llvm.insertvalue %265, %267[2] : !llvm.array<24 x vector<16xi32>> 
    %269 = llvm.insertvalue %265, %268[3] : !llvm.array<24 x vector<16xi32>> 
    %270 = llvm.insertvalue %265, %269[4] : !llvm.array<24 x vector<16xi32>> 
    %271 = llvm.insertvalue %265, %270[5] : !llvm.array<24 x vector<16xi32>> 
    %272 = llvm.insertvalue %265, %271[6] : !llvm.array<24 x vector<16xi32>> 
    %273 = llvm.insertvalue %265, %272[7] : !llvm.array<24 x vector<16xi32>> 
    %274 = llvm.insertvalue %265, %273[8] : !llvm.array<24 x vector<16xi32>> 
    %275 = llvm.insertvalue %265, %274[9] : !llvm.array<24 x vector<16xi32>> 
    %276 = llvm.insertvalue %265, %275[10] : !llvm.array<24 x vector<16xi32>> 
    %277 = llvm.insertvalue %265, %276[11] : !llvm.array<24 x vector<16xi32>> 
    %278 = llvm.insertvalue %265, %277[12] : !llvm.array<24 x vector<16xi32>> 
    %279 = llvm.insertvalue %265, %278[13] : !llvm.array<24 x vector<16xi32>> 
    %280 = llvm.insertvalue %265, %279[14] : !llvm.array<24 x vector<16xi32>> 
    %281 = llvm.insertvalue %265, %280[15] : !llvm.array<24 x vector<16xi32>> 
    %282 = llvm.insertvalue %265, %281[16] : !llvm.array<24 x vector<16xi32>> 
    %283 = llvm.insertvalue %265, %282[17] : !llvm.array<24 x vector<16xi32>> 
    %284 = llvm.insertvalue %265, %283[18] : !llvm.array<24 x vector<16xi32>> 
    %285 = llvm.insertvalue %265, %284[19] : !llvm.array<24 x vector<16xi32>> 
    %286 = llvm.insertvalue %265, %285[20] : !llvm.array<24 x vector<16xi32>> 
    %287 = llvm.insertvalue %265, %286[21] : !llvm.array<24 x vector<16xi32>> 
    %288 = llvm.insertvalue %265, %287[22] : !llvm.array<24 x vector<16xi32>> 
    %289 = llvm.insertvalue %265, %288[23] : !llvm.array<24 x vector<16xi32>> 
    %290 = builtin.unrealized_conversion_cast %289 : !llvm.array<24 x vector<16xi32>> to vector<24x16xi32>
    %291 = llvm.extractvalue %200[1] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %292 = llvm.mlir.constant(3 : index) : i64
    %293 = llvm.mul %4, %292  : i64
    %294 = llvm.add %293, %5  : i64
    %295 = llvm.getelementptr %291[%294] : (!llvm.ptr, i64) -> !llvm.ptr, i64
    %296 = llvm.mlir.undef : !llvm.array<24 x vector<16xi64>>
    %297 = llvm.extractvalue %289[0] : !llvm.array<24 x vector<16xi32>> 
    %298 = llvm.extractvalue %259[0] : !llvm.array<24 x vector<16xi1>> 
    %299 = llvm.extractvalue %229[0] : !llvm.array<24 x vector<16xi64>> 
    %300 = llvm.getelementptr %295[%297] : (!llvm.ptr, vector<16xi32>) -> !llvm.vec<16 x ptr>, i64
    %301 = llvm.intr.masked.gather %300, %298, %299 {alignment = 8 : i32} : (!llvm.vec<16 x ptr>, vector<16xi1>, vector<16xi64>) -> vector<16xi64>
    %302 = llvm.insertvalue %301, %296[0] : !llvm.array<24 x vector<16xi64>> 
    %303 = llvm.extractvalue %289[1] : !llvm.array<24 x vector<16xi32>> 
    %304 = llvm.extractvalue %259[1] : !llvm.array<24 x vector<16xi1>> 
    %305 = llvm.extractvalue %229[1] : !llvm.array<24 x vector<16xi64>> 
    %306 = llvm.getelementptr %295[%303] : (!llvm.ptr, vector<16xi32>) -> !llvm.vec<16 x ptr>, i64
    %307 = llvm.intr.masked.gather %306, %304, %305 {alignment = 8 : i32} : (!llvm.vec<16 x ptr>, vector<16xi1>, vector<16xi64>) -> vector<16xi64>
    %308 = llvm.insertvalue %307, %302[1] : !llvm.array<24 x vector<16xi64>> 
    %309 = llvm.extractvalue %289[2] : !llvm.array<24 x vector<16xi32>> 
    %310 = llvm.extractvalue %259[2] : !llvm.array<24 x vector<16xi1>> 
    %311 = llvm.extractvalue %229[2] : !llvm.array<24 x vector<16xi64>> 
    %312 = llvm.getelementptr %295[%309] : (!llvm.ptr, vector<16xi32>) -> !llvm.vec<16 x ptr>, i64
    %313 = llvm.intr.masked.gather %312, %310, %311 {alignment = 8 : i32} : (!llvm.vec<16 x ptr>, vector<16xi1>, vector<16xi64>) -> vector<16xi64>
    %314 = llvm.insertvalue %313, %308[2] : !llvm.array<24 x vector<16xi64>> 
    %315 = llvm.extractvalue %289[3] : !llvm.array<24 x vector<16xi32>> 
    %316 = llvm.extractvalue %259[3] : !llvm.array<24 x vector<16xi1>> 
    %317 = llvm.extractvalue %229[3] : !llvm.array<24 x vector<16xi64>> 
    %318 = llvm.getelementptr %295[%315] : (!llvm.ptr, vector<16xi32>) -> !llvm.vec<16 x ptr>, i64
    %319 = llvm.intr.masked.gather %318, %316, %317 {alignment = 8 : i32} : (!llvm.vec<16 x ptr>, vector<16xi1>, vector<16xi64>) -> vector<16xi64>
    %320 = llvm.insertvalue %319, %314[3] : !llvm.array<24 x vector<16xi64>> 
    %321 = llvm.extractvalue %289[4] : !llvm.array<24 x vector<16xi32>> 
    %322 = llvm.extractvalue %259[4] : !llvm.array<24 x vector<16xi1>> 
    %323 = llvm.extractvalue %229[4] : !llvm.array<24 x vector<16xi64>> 
    %324 = llvm.getelementptr %295[%321] : (!llvm.ptr, vector<16xi32>) -> !llvm.vec<16 x ptr>, i64
    %325 = llvm.intr.masked.gather %324, %322, %323 {alignment = 8 : i32} : (!llvm.vec<16 x ptr>, vector<16xi1>, vector<16xi64>) -> vector<16xi64>
    %326 = llvm.insertvalue %325, %320[4] : !llvm.array<24 x vector<16xi64>> 
    %327 = llvm.extractvalue %289[5] : !llvm.array<24 x vector<16xi32>> 
    %328 = llvm.extractvalue %259[5] : !llvm.array<24 x vector<16xi1>> 
    %329 = llvm.extractvalue %229[5] : !llvm.array<24 x vector<16xi64>> 
    %330 = llvm.getelementptr %295[%327] : (!llvm.ptr, vector<16xi32>) -> !llvm.vec<16 x ptr>, i64
    %331 = llvm.intr.masked.gather %330, %328, %329 {alignment = 8 : i32} : (!llvm.vec<16 x ptr>, vector<16xi1>, vector<16xi64>) -> vector<16xi64>
    %332 = llvm.insertvalue %331, %326[5] : !llvm.array<24 x vector<16xi64>> 
    %333 = llvm.extractvalue %289[6] : !llvm.array<24 x vector<16xi32>> 
    %334 = llvm.extractvalue %259[6] : !llvm.array<24 x vector<16xi1>> 
    %335 = llvm.extractvalue %229[6] : !llvm.array<24 x vector<16xi64>> 
    %336 = llvm.getelementptr %295[%333] : (!llvm.ptr, vector<16xi32>) -> !llvm.vec<16 x ptr>, i64
    %337 = llvm.intr.masked.gather %336, %334, %335 {alignment = 8 : i32} : (!llvm.vec<16 x ptr>, vector<16xi1>, vector<16xi64>) -> vector<16xi64>
    %338 = llvm.insertvalue %337, %332[6] : !llvm.array<24 x vector<16xi64>> 
    %339 = llvm.extractvalue %289[7] : !llvm.array<24 x vector<16xi32>> 
    %340 = llvm.extractvalue %259[7] : !llvm.array<24 x vector<16xi1>> 
    %341 = llvm.extractvalue %229[7] : !llvm.array<24 x vector<16xi64>> 
    %342 = llvm.getelementptr %295[%339] : (!llvm.ptr, vector<16xi32>) -> !llvm.vec<16 x ptr>, i64
    %343 = llvm.intr.masked.gather %342, %340, %341 {alignment = 8 : i32} : (!llvm.vec<16 x ptr>, vector<16xi1>, vector<16xi64>) -> vector<16xi64>
    %344 = llvm.insertvalue %343, %338[7] : !llvm.array<24 x vector<16xi64>> 
    %345 = llvm.extractvalue %289[8] : !llvm.array<24 x vector<16xi32>> 
    %346 = llvm.extractvalue %259[8] : !llvm.array<24 x vector<16xi1>> 
    %347 = llvm.extractvalue %229[8] : !llvm.array<24 x vector<16xi64>> 
    %348 = llvm.getelementptr %295[%345] : (!llvm.ptr, vector<16xi32>) -> !llvm.vec<16 x ptr>, i64
    %349 = llvm.intr.masked.gather %348, %346, %347 {alignment = 8 : i32} : (!llvm.vec<16 x ptr>, vector<16xi1>, vector<16xi64>) -> vector<16xi64>
    %350 = llvm.insertvalue %349, %344[8] : !llvm.array<24 x vector<16xi64>> 
    %351 = llvm.extractvalue %289[9] : !llvm.array<24 x vector<16xi32>> 
    %352 = llvm.extractvalue %259[9] : !llvm.array<24 x vector<16xi1>> 
    %353 = llvm.extractvalue %229[9] : !llvm.array<24 x vector<16xi64>> 
    %354 = llvm.getelementptr %295[%351] : (!llvm.ptr, vector<16xi32>) -> !llvm.vec<16 x ptr>, i64
    %355 = llvm.intr.masked.gather %354, %352, %353 {alignment = 8 : i32} : (!llvm.vec<16 x ptr>, vector<16xi1>, vector<16xi64>) -> vector<16xi64>
    %356 = llvm.insertvalue %355, %350[9] : !llvm.array<24 x vector<16xi64>> 
    %357 = llvm.extractvalue %289[10] : !llvm.array<24 x vector<16xi32>> 
    %358 = llvm.extractvalue %259[10] : !llvm.array<24 x vector<16xi1>> 
    %359 = llvm.extractvalue %229[10] : !llvm.array<24 x vector<16xi64>> 
    %360 = llvm.getelementptr %295[%357] : (!llvm.ptr, vector<16xi32>) -> !llvm.vec<16 x ptr>, i64
    %361 = llvm.intr.masked.gather %360, %358, %359 {alignment = 8 : i32} : (!llvm.vec<16 x ptr>, vector<16xi1>, vector<16xi64>) -> vector<16xi64>
    %362 = llvm.insertvalue %361, %356[10] : !llvm.array<24 x vector<16xi64>> 
    %363 = llvm.extractvalue %289[11] : !llvm.array<24 x vector<16xi32>> 
    %364 = llvm.extractvalue %259[11] : !llvm.array<24 x vector<16xi1>> 
    %365 = llvm.extractvalue %229[11] : !llvm.array<24 x vector<16xi64>> 
    %366 = llvm.getelementptr %295[%363] : (!llvm.ptr, vector<16xi32>) -> !llvm.vec<16 x ptr>, i64
    %367 = llvm.intr.masked.gather %366, %364, %365 {alignment = 8 : i32} : (!llvm.vec<16 x ptr>, vector<16xi1>, vector<16xi64>) -> vector<16xi64>
    %368 = llvm.insertvalue %367, %362[11] : !llvm.array<24 x vector<16xi64>> 
    %369 = llvm.extractvalue %289[12] : !llvm.array<24 x vector<16xi32>> 
    %370 = llvm.extractvalue %259[12] : !llvm.array<24 x vector<16xi1>> 
    %371 = llvm.extractvalue %229[12] : !llvm.array<24 x vector<16xi64>> 
    %372 = llvm.getelementptr %295[%369] : (!llvm.ptr, vector<16xi32>) -> !llvm.vec<16 x ptr>, i64
    %373 = llvm.intr.masked.gather %372, %370, %371 {alignment = 8 : i32} : (!llvm.vec<16 x ptr>, vector<16xi1>, vector<16xi64>) -> vector<16xi64>
    %374 = llvm.insertvalue %373, %368[12] : !llvm.array<24 x vector<16xi64>> 
    %375 = llvm.extractvalue %289[13] : !llvm.array<24 x vector<16xi32>> 
    %376 = llvm.extractvalue %259[13] : !llvm.array<24 x vector<16xi1>> 
    %377 = llvm.extractvalue %229[13] : !llvm.array<24 x vector<16xi64>> 
    %378 = llvm.getelementptr %295[%375] : (!llvm.ptr, vector<16xi32>) -> !llvm.vec<16 x ptr>, i64
    %379 = llvm.intr.masked.gather %378, %376, %377 {alignment = 8 : i32} : (!llvm.vec<16 x ptr>, vector<16xi1>, vector<16xi64>) -> vector<16xi64>
    %380 = llvm.insertvalue %379, %374[13] : !llvm.array<24 x vector<16xi64>> 
    %381 = llvm.extractvalue %289[14] : !llvm.array<24 x vector<16xi32>> 
    %382 = llvm.extractvalue %259[14] : !llvm.array<24 x vector<16xi1>> 
    %383 = llvm.extractvalue %229[14] : !llvm.array<24 x vector<16xi64>> 
    %384 = llvm.getelementptr %295[%381] : (!llvm.ptr, vector<16xi32>) -> !llvm.vec<16 x ptr>, i64
    %385 = llvm.intr.masked.gather %384, %382, %383 {alignment = 8 : i32} : (!llvm.vec<16 x ptr>, vector<16xi1>, vector<16xi64>) -> vector<16xi64>
    %386 = llvm.insertvalue %385, %380[14] : !llvm.array<24 x vector<16xi64>> 
    %387 = llvm.extractvalue %289[15] : !llvm.array<24 x vector<16xi32>> 
    %388 = llvm.extractvalue %259[15] : !llvm.array<24 x vector<16xi1>> 
    %389 = llvm.extractvalue %229[15] : !llvm.array<24 x vector<16xi64>> 
    %390 = llvm.getelementptr %295[%387] : (!llvm.ptr, vector<16xi32>) -> !llvm.vec<16 x ptr>, i64
    %391 = llvm.intr.masked.gather %390, %388, %389 {alignment = 8 : i32} : (!llvm.vec<16 x ptr>, vector<16xi1>, vector<16xi64>) -> vector<16xi64>
    %392 = llvm.insertvalue %391, %386[15] : !llvm.array<24 x vector<16xi64>> 
    %393 = llvm.extractvalue %289[16] : !llvm.array<24 x vector<16xi32>> 
    %394 = llvm.extractvalue %259[16] : !llvm.array<24 x vector<16xi1>> 
    %395 = llvm.extractvalue %229[16] : !llvm.array<24 x vector<16xi64>> 
    %396 = llvm.getelementptr %295[%393] : (!llvm.ptr, vector<16xi32>) -> !llvm.vec<16 x ptr>, i64
    %397 = llvm.intr.masked.gather %396, %394, %395 {alignment = 8 : i32} : (!llvm.vec<16 x ptr>, vector<16xi1>, vector<16xi64>) -> vector<16xi64>
    %398 = llvm.insertvalue %397, %392[16] : !llvm.array<24 x vector<16xi64>> 
    %399 = llvm.extractvalue %289[17] : !llvm.array<24 x vector<16xi32>> 
    %400 = llvm.extractvalue %259[17] : !llvm.array<24 x vector<16xi1>> 
    %401 = llvm.extractvalue %229[17] : !llvm.array<24 x vector<16xi64>> 
    %402 = llvm.getelementptr %295[%399] : (!llvm.ptr, vector<16xi32>) -> !llvm.vec<16 x ptr>, i64
    %403 = llvm.intr.masked.gather %402, %400, %401 {alignment = 8 : i32} : (!llvm.vec<16 x ptr>, vector<16xi1>, vector<16xi64>) -> vector<16xi64>
    %404 = llvm.insertvalue %403, %398[17] : !llvm.array<24 x vector<16xi64>> 
    %405 = llvm.extractvalue %289[18] : !llvm.array<24 x vector<16xi32>> 
    %406 = llvm.extractvalue %259[18] : !llvm.array<24 x vector<16xi1>> 
    %407 = llvm.extractvalue %229[18] : !llvm.array<24 x vector<16xi64>> 
    %408 = llvm.getelementptr %295[%405] : (!llvm.ptr, vector<16xi32>) -> !llvm.vec<16 x ptr>, i64
    %409 = llvm.intr.masked.gather %408, %406, %407 {alignment = 8 : i32} : (!llvm.vec<16 x ptr>, vector<16xi1>, vector<16xi64>) -> vector<16xi64>
    %410 = llvm.insertvalue %409, %404[18] : !llvm.array<24 x vector<16xi64>> 
    %411 = llvm.extractvalue %289[19] : !llvm.array<24 x vector<16xi32>> 
    %412 = llvm.extractvalue %259[19] : !llvm.array<24 x vector<16xi1>> 
    %413 = llvm.extractvalue %229[19] : !llvm.array<24 x vector<16xi64>> 
    %414 = llvm.getelementptr %295[%411] : (!llvm.ptr, vector<16xi32>) -> !llvm.vec<16 x ptr>, i64
    %415 = llvm.intr.masked.gather %414, %412, %413 {alignment = 8 : i32} : (!llvm.vec<16 x ptr>, vector<16xi1>, vector<16xi64>) -> vector<16xi64>
    %416 = llvm.insertvalue %415, %410[19] : !llvm.array<24 x vector<16xi64>> 
    %417 = llvm.extractvalue %289[20] : !llvm.array<24 x vector<16xi32>> 
    %418 = llvm.extractvalue %259[20] : !llvm.array<24 x vector<16xi1>> 
    %419 = llvm.extractvalue %229[20] : !llvm.array<24 x vector<16xi64>> 
    %420 = llvm.getelementptr %295[%417] : (!llvm.ptr, vector<16xi32>) -> !llvm.vec<16 x ptr>, i64
    %421 = llvm.intr.masked.gather %420, %418, %419 {alignment = 8 : i32} : (!llvm.vec<16 x ptr>, vector<16xi1>, vector<16xi64>) -> vector<16xi64>
    %422 = llvm.insertvalue %421, %416[20] : !llvm.array<24 x vector<16xi64>> 
    %423 = llvm.extractvalue %289[21] : !llvm.array<24 x vector<16xi32>> 
    %424 = llvm.extractvalue %259[21] : !llvm.array<24 x vector<16xi1>> 
    %425 = llvm.extractvalue %229[21] : !llvm.array<24 x vector<16xi64>> 
    %426 = llvm.getelementptr %295[%423] : (!llvm.ptr, vector<16xi32>) -> !llvm.vec<16 x ptr>, i64
    %427 = llvm.intr.masked.gather %426, %424, %425 {alignment = 8 : i32} : (!llvm.vec<16 x ptr>, vector<16xi1>, vector<16xi64>) -> vector<16xi64>
    %428 = llvm.insertvalue %427, %422[21] : !llvm.array<24 x vector<16xi64>> 
    %429 = llvm.extractvalue %289[22] : !llvm.array<24 x vector<16xi32>> 
    %430 = llvm.extractvalue %259[22] : !llvm.array<24 x vector<16xi1>> 
    %431 = llvm.extractvalue %229[22] : !llvm.array<24 x vector<16xi64>> 
    %432 = llvm.getelementptr %295[%429] : (!llvm.ptr, vector<16xi32>) -> !llvm.vec<16 x ptr>, i64
    %433 = llvm.intr.masked.gather %432, %430, %431 {alignment = 8 : i32} : (!llvm.vec<16 x ptr>, vector<16xi1>, vector<16xi64>) -> vector<16xi64>
    %434 = llvm.insertvalue %433, %428[22] : !llvm.array<24 x vector<16xi64>> 
    %435 = llvm.extractvalue %289[23] : !llvm.array<24 x vector<16xi32>> 
    %436 = llvm.extractvalue %259[23] : !llvm.array<24 x vector<16xi1>> 
    %437 = llvm.extractvalue %229[23] : !llvm.array<24 x vector<16xi64>> 
    %438 = llvm.getelementptr %295[%435] : (!llvm.ptr, vector<16xi32>) -> !llvm.vec<16 x ptr>, i64
    %439 = llvm.intr.masked.gather %438, %436, %437 {alignment = 8 : i32} : (!llvm.vec<16 x ptr>, vector<16xi1>, vector<16xi64>) -> vector<16xi64>
    %440 = llvm.insertvalue %439, %434[23] : !llvm.array<24 x vector<16xi64>> 
    %441 = builtin.unrealized_conversion_cast %440 : !llvm.array<24 x vector<16xi64>> to vector<24x16xi64>
    %442 = llvm.mlir.undef : vector<1xf32>
    %443 = llvm.mlir.constant(0 : i32) : i32
    %444 = llvm.insertelement %28, %442[%443 : i32] : vector<1xf32>
    %445 = builtin.unrealized_conversion_cast %444 : vector<1xf32> to vector<f32>
    %446 = spirv.LogicalEqual %22, %false : i1
    vector.print %14 : vector<16xi1>
    vector.print %15 : vector<3xi16>
    vector.print %15 : vector<3xi16>
    vector.print %38 : vector<16xf32>
    vector.print %39 : vector<16xf32>
    vector.print %41 : vector<24xf32>
    vector.print %cst_0 : vector<24x16xf32>
    vector.print %167 : vector<24x16xf32>
    vector.print %172 : vector<16xi32>
    vector.print %cst : vector<16xi1>
    vector.print %230 : vector<24x16xi64>
    vector.print %260 : vector<24x16xi1>
    vector.print %290 : vector<24x16xi32>
    vector.print %441 : vector<24x16xi64>
    vector.print %445 : vector<f32>
    %447 = arith.extui %arg2 : i1 to i64
    llvm.call @printI64(%447) : (i64) -> ()
    llvm.call @printNewline() : () -> ()
    %448 = arith.extui %false : i1 to i64
    llvm.call @printI64(%448) : (i64) -> ()
    llvm.call @printNewline() : () -> ()
    llvm.call @printI64(%c265471212_i64) : (i64) -> ()
    llvm.call @printNewline() : () -> ()
    %449 = arith.extsi %c4623_i16 : i16 to i64
    llvm.call @printI64(%449) : (i64) -> ()
    llvm.call @printNewline() : () -> ()
    %450 = arith.extsi %c22394_i16 : i16 to i64
    llvm.call @printI64(%450) : (i64) -> ()
    llvm.call @printNewline() : () -> ()
    %451 = arith.extui %false : i1 to i64
    llvm.call @printI64(%451) : (i64) -> ()
    llvm.call @printNewline() : () -> ()
    %452 = arith.extsi %c1941353413_i32 : i32 to i64
    llvm.call @printI64(%452) : (i64) -> ()
    llvm.call @printNewline() : () -> ()
    %453 = arith.extsi %c-29278_i16 : i16 to i64
    llvm.call @printI64(%453) : (i64) -> ()
    llvm.call @printNewline() : () -> ()
    llvm.call @printI64(%c281204932_i64) : (i64) -> ()
    llvm.call @printNewline() : () -> ()
    llvm.call @printF32(%cst_2) : (f32) -> ()
    llvm.call @printNewline() : () -> ()
    %454 = llvm.bitcast %cst_3 : f16 to i16
    llvm.call @printF16(%454) : (i16) -> ()
    llvm.call @printNewline() : () -> ()
    %455 = llvm.bitcast %cst_4 : f16 to i16
    llvm.call @printF16(%455) : (i16) -> ()
    llvm.call @printNewline() : () -> ()
    %456 = arith.extsi %c771421837_i32 : i32 to i64
    llvm.call @printI64(%456) : (i64) -> ()
    llvm.call @printNewline() : () -> ()
    %457 = arith.extsi %c445093745_i32 : i32 to i64
    llvm.call @printI64(%457) : (i64) -> ()
    llvm.call @printNewline() : () -> ()
    %458 = arith.extui %true : i1 to i64
    llvm.call @printI64(%458) : (i64) -> ()
    llvm.call @printNewline() : () -> ()
    llvm.call @printF32(%cst_5) : (f32) -> ()
    llvm.call @printNewline() : () -> ()
    %459 = llvm.bitcast %cst_6 : f16 to i16
    llvm.call @printF16(%459) : (i16) -> ()
    llvm.call @printNewline() : () -> ()
    %460 = arith.extsi %11 : i32 to i64
    llvm.call @printI64(%460) : (i64) -> ()
    llvm.call @printNewline() : () -> ()
    %461 = llvm.bitcast %16 : f16 to i16
    llvm.call @printF16(%461) : (i16) -> ()
    llvm.call @printNewline() : () -> ()
    %462 = llvm.bitcast %17 : f16 to i16
    llvm.call @printF16(%462) : (i16) -> ()
    llvm.call @printNewline() : () -> ()
    %463 = llvm.bitcast %18 : f16 to i16
    llvm.call @printF16(%463) : (i16) -> ()
    llvm.call @printNewline() : () -> ()
    %464 = llvm.bitcast %19 : f16 to i16
    llvm.call @printF16(%464) : (i16) -> ()
    llvm.call @printNewline() : () -> ()
    %465 = llvm.bitcast %20 : f16 to i16
    llvm.call @printF16(%465) : (i16) -> ()
    llvm.call @printNewline() : () -> ()
    %466 = llvm.bitcast %21 : f16 to i16
    llvm.call @printF16(%466) : (i16) -> ()
    llvm.call @printNewline() : () -> ()
    %467 = arith.extui %22 : i1 to i64
    llvm.call @printI64(%467) : (i64) -> ()
    llvm.call @printNewline() : () -> ()
    %468 = llvm.bitcast %23 : f16 to i16
    llvm.call @printF16(%468) : (i16) -> ()
    llvm.call @printNewline() : () -> ()
    %469 = llvm.bitcast %24 : f16 to i16
    llvm.call @printF16(%469) : (i16) -> ()
    llvm.call @printNewline() : () -> ()
    %470 = arith.extui %25 : i1 to i64
    llvm.call @printI64(%470) : (i64) -> ()
    llvm.call @printNewline() : () -> ()
    %471 = llvm.bitcast %26 : f16 to i16
    llvm.call @printF16(%471) : (i16) -> ()
    llvm.call @printNewline() : () -> ()
    %472 = arith.extui %27 : i1 to i64
    llvm.call @printI64(%472) : (i64) -> ()
    llvm.call @printNewline() : () -> ()
    llvm.call @printF32(%28) : (f32) -> ()
    llvm.call @printNewline() : () -> ()
    %473 = llvm.bitcast %29 : f16 to i16
    llvm.call @printF16(%473) : (i16) -> ()
    llvm.call @printNewline() : () -> ()
    %474 = llvm.bitcast %30 : f16 to i16
    llvm.call @printF16(%474) : (i16) -> ()
    llvm.call @printNewline() : () -> ()
    %475 = arith.extui %31 : i1 to i64
    llvm.call @printI64(%475) : (i64) -> ()
    llvm.call @printNewline() : () -> ()
    %476 = arith.extsi %32 : i32 to i64
    llvm.call @printI64(%476) : (i64) -> ()
    llvm.call @printNewline() : () -> ()
    llvm.call @printF32(%33) : (f32) -> ()
    llvm.call @printNewline() : () -> ()
    %477 = llvm.bitcast %34 : f16 to i16
    llvm.call @printF16(%477) : (i16) -> ()
    llvm.call @printNewline() : () -> ()
    %478 = arith.extsi %40 : i32 to i64
    llvm.call @printI64(%478) : (i64) -> ()
    llvm.call @printNewline() : () -> ()
    %479 = llvm.bitcast %42 : f16 to i16
    llvm.call @printF16(%479) : (i16) -> ()
    llvm.call @printNewline() : () -> ()
    %480 = arith.extui %43 : i1 to i64
    llvm.call @printI64(%480) : (i64) -> ()
    llvm.call @printNewline() : () -> ()
    %481 = llvm.bitcast %44 : f16 to i16
    llvm.call @printF16(%481) : (i16) -> ()
    llvm.call @printNewline() : () -> ()
    %482 = llvm.bitcast %45 : f16 to i16
    llvm.call @printF16(%482) : (i16) -> ()
    llvm.call @printNewline() : () -> ()
    %483 = llvm.bitcast %168 : f16 to i16
    llvm.call @printF16(%483) : (i16) -> ()
    llvm.call @printNewline() : () -> ()
    %484 = llvm.bitcast %169 : f16 to i16
    llvm.call @printF16(%484) : (i16) -> ()
    llvm.call @printNewline() : () -> ()
    %485 = arith.extsi %170 : i32 to i64
    llvm.call @printI64(%485) : (i64) -> ()
    llvm.call @printNewline() : () -> ()
    %486 = llvm.bitcast %171 : f16 to i16
    llvm.call @printF16(%486) : (i16) -> ()
    llvm.call @printNewline() : () -> ()
    %487 = arith.extui %173 : i1 to i64
    llvm.call @printI64(%487) : (i64) -> ()
    llvm.call @printNewline() : () -> ()
    %488 = llvm.bitcast %174 : f16 to i16
    llvm.call @printF16(%488) : (i16) -> ()
    llvm.call @printNewline() : () -> ()
    %489 = llvm.bitcast %175 : f16 to i16
    llvm.call @printF16(%489) : (i16) -> ()
    llvm.call @printNewline() : () -> ()
    %490 = llvm.bitcast %176 : f16 to i16
    llvm.call @printF16(%490) : (i16) -> ()
    llvm.call @printNewline() : () -> ()
    %491 = arith.extui %177 : i1 to i64
    llvm.call @printI64(%491) : (i64) -> ()
    llvm.call @printNewline() : () -> ()
    %492 = llvm.bitcast %178 : f16 to i16
    llvm.call @printF16(%492) : (i16) -> ()
    llvm.call @printNewline() : () -> ()
    llvm.call @printI64(%179) : (i64) -> ()
    llvm.call @printNewline() : () -> ()
    %493 = llvm.bitcast %180 : f16 to i16
    llvm.call @printF16(%493) : (i16) -> ()
    llvm.call @printNewline() : () -> ()
    %494 = llvm.bitcast %181 : f16 to i16
    llvm.call @printF16(%494) : (i16) -> ()
    llvm.call @printNewline() : () -> ()
    %495 = llvm.bitcast %183 : f16 to i16
    llvm.call @printF16(%495) : (i16) -> ()
    llvm.call @printNewline() : () -> ()
    %496 = arith.extui %184 : i1 to i64
    llvm.call @printI64(%496) : (i64) -> ()
    llvm.call @printNewline() : () -> ()
    %497 = llvm.bitcast %185 : f16 to i16
    llvm.call @printF16(%497) : (i16) -> ()
    llvm.call @printNewline() : () -> ()
    %498 = llvm.bitcast %186 : f16 to i16
    llvm.call @printF16(%498) : (i16) -> ()
    llvm.call @printNewline() : () -> ()
    %499 = arith.extsi %187 : i32 to i64
    llvm.call @printI64(%499) : (i64) -> ()
    llvm.call @printNewline() : () -> ()
    %500 = llvm.bitcast %188 : f16 to i16
    llvm.call @printF16(%500) : (i16) -> ()
    llvm.call @printNewline() : () -> ()
    %501 = arith.extsi %189 : i16 to i64
    llvm.call @printI64(%501) : (i64) -> ()
    llvm.call @printNewline() : () -> ()
    %502 = llvm.bitcast %190 : f16 to i16
    llvm.call @printF16(%502) : (i16) -> ()
    llvm.call @printNewline() : () -> ()
    %503 = llvm.bitcast %191 : f16 to i16
    llvm.call @printF16(%503) : (i16) -> ()
    llvm.call @printNewline() : () -> ()
    %504 = llvm.bitcast %192 : f16 to i16
    llvm.call @printF16(%504) : (i16) -> ()
    llvm.call @printNewline() : () -> ()
    %505 = arith.extsi %193 : i16 to i64
    llvm.call @printI64(%505) : (i64) -> ()
    llvm.call @printNewline() : () -> ()
    %506 = llvm.bitcast %194 : f16 to i16
    llvm.call @printF16(%506) : (i16) -> ()
    llvm.call @printNewline() : () -> ()
    %507 = arith.extui %195 : i1 to i64
    llvm.call @printI64(%507) : (i64) -> ()
    llvm.call @printNewline() : () -> ()
    %508 = arith.extui %199 : i1 to i64
    llvm.call @printI64(%508) : (i64) -> ()
    llvm.call @printNewline() : () -> ()
    %509 = arith.extui %446 : i1 to i64
    llvm.call @printI64(%509) : (i64) -> ()
    llvm.call @printNewline() : () -> ()
    return
  }
  func.func @func2() {
    %cst = arith.constant dense<771421837> : vector<2xi32>
    %cst_0 = arith.constant dense<4623> : vector<3xi16>
    %cst_1 = arith.constant dense<22394> : vector<i16>
    %0 = builtin.unrealized_conversion_cast %cst_1 : vector<i16> to vector<1xi16>
    %c29 = arith.constant 29 : index
    %false = index.bool.constant false
    %false_2 = arith.constant false
    %c265471212_i64 = arith.constant 265471212 : i64
    %c4623_i16 = arith.constant 4623 : i16
    %c22394_i16 = arith.constant 22394 : i16
    %c1941353413_i32 = arith.constant 1941353413 : i32
    %c-29278_i16 = arith.constant -29278 : i16
    %c281204932_i64 = arith.constant 281204932 : i64
    %cst_3 = arith.constant 0x4D08837C : f32
    %cst_4 = arith.constant 3.350400e+04 : f16
    %cst_5 = arith.constant 5.033600e+04 : f16
    %c771421837_i32 = arith.constant 771421837 : i32
    %c445093745_i32 = arith.constant 445093745 : i32
    %true = arith.constant true
    %cst_6 = arith.constant 0x4E228E1D : f32
    %cst_7 = arith.constant 1.731200e+04 : f16
    %c0 = arith.constant 0 : index
    %c1 = arith.constant 1 : index
    %c2 = arith.constant 2 : index
    %c5 = arith.constant 5 : index
    %c6 = arith.constant 6 : index
    %c7 = arith.constant 7 : index
    %c9 = arith.constant 9 : index
    %c10 = arith.constant 10 : index
    %c11 = arith.constant 11 : index
    %c12 = arith.constant 12 : index
    %c13 = arith.constant 13 : index
    %c14 = arith.constant 14 : index
    %c15 = arith.constant 15 : index
    %c16 = arith.constant 16 : index
    %c17 = arith.constant 17 : index
    %c22 = arith.constant 22 : index
    %c23 = arith.constant 23 : index
    %c25 = arith.constant 25 : index
    %c26 = arith.constant 26 : index
    %c27 = arith.constant 27 : index
    %c30 = arith.constant 30 : index
    %1 = tensor.empty(%c23, %c25) : tensor<?x?xi16>
    %2 = tensor.empty(%c5, %c15) : tensor<?x?xf16>
    %3 = tensor.empty(%c17) : tensor<?x3xi1>
    %alloc = memref.alloc() : memref<16xf32>
    %alloc_8 = memref.alloc(%c12, %c26) : memref<?x?xi16>
    %alloc_9 = memref.alloc(%c10) : memref<?xi16>
    %alloc_10 = memref.alloc(%c27) : memref<?xf32>
    %alloc_11 = memref.alloc(%c22, %c11) : memref<?x?xf32>
    %alloc_12 = memref.alloc() : memref<16x3xi16>
    %alloc_13 = memref.alloc() : memref<16x3xf16>
    %alloc_14 = memref.alloc() : memref<16xf16>
    %alloc_15 = memref.alloc(%c9) : memref<?xi32>
    %alloc_16 = memref.alloc(%c9) : memref<?xi16>
    %alloc_17 = memref.alloc() : memref<24x16xi16>
    %4 = tensor.empty() : tensor<48xi64>
    %5 = spirv.GL.FMix %cst_4 : f16, %cst_5 : f16, %cst_4 : f16 -> f16
    %6 = spirv.FOrdEqual %5, %cst_4 : f16
    %7 = spirv.IsInf %cst_5 : f16
    %8 = spirv.GL.Cosh %cst_7 : f16
    %9 = spirv.CL.sin %8 : f16
    %10 = scf.while (%arg0 = %4) : (tensor<48xi64>) -> tensor<48xi64> {
      scf.condition(%false_2) %arg0 : tensor<48xi64>
    } do {
    ^bb0(%arg0: tensor<48xi64>):
      %114 = memref.realloc %alloc_16 : memref<?xi16> to memref<24xi16>
      %alloc_20 = memref.alloc(%c14, %c23) : memref<?x?xf16>
      memref.tensor_store %2, %alloc_20 : memref<?x?xf16>
      memref.alloca_scope  {
        memref.assume_alignment %alloc_11, 16 : memref<?x?xf32>
        %alloc_21 = memref.alloc(%c16) : memref<?x3xi1>
        memref.tensor_store %3, %alloc_21 : memref<?x3xi1>
      }
      vector.print %cst : vector<2xi32>
      memref.assume_alignment %alloc_14, 4 : memref<16xf16>
      scf.yield %arg0 : tensor<48xi64>
    }
    %11 = spirv.CL.fabs %cst_4 : f16
    %12 = spirv.GL.Cosh %cst_3 : f32
    %13 = spirv.CL.rsqrt %11 : f16
    %14 = spirv.CL.cos %12 : f32
    %15 = spirv.GL.Cos %11 : f16
    vector.warp_execute_on_lane_0(%c0)[32] {
      scf.execute_region {
        %114 = memref.realloc %alloc_10 : memref<?xf32> to memref<14xf32>
        %115 = llvm.mlir.undef : vector<24xf16>
        %116 = llvm.mlir.constant(0 : i32) : i32
        %117 = llvm.insertelement %9, %115[%116 : i32] : vector<24xf16>
        %118 = llvm.shufflevector %117, %115 [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] : vector<24xf16> 
        vector.transfer_write %118, %alloc_13[%c30, %c9] {in_bounds = [true], permutation_map = #map} : vector<24xf16>, memref<16x3xf16>
        scf.yield
      }
    }
    %16 = affine.if #set1() -> memref<24x16xi64> {
      memref.alloca_scope  {
        memref.copy %alloc_14, %alloc_14 : memref<16xf16> to memref<16xf16>
      }
      %alloc_20 = memref.alloc() : memref<24x16xi64>
      affine.yield %alloc_20 : memref<24x16xi64>
    } else {
      %alloc_20 = memref.alloc() : memref<24x16xi64>
      affine.yield %alloc_20 : memref<24x16xi64>
    }
    %17 = spirv.FUnordLessThan %cst_5, %11 : f16
    %18 = llvm.mlir.undef : vector<2xi1>
    %19 = llvm.mlir.constant(0 : i32) : i32
    %20 = llvm.insertelement %17, %18[%19 : i32] : vector<2xi1>
    %21 = llvm.shufflevector %20, %18 [0, 0] : vector<2xi1> 
    vector.transfer_write %cst_0, %alloc_12[%c16, %c29] {in_bounds = [true], permutation_map = #map} : vector<3xi16>, memref<16x3xi16>
    %22 = spirv.CL.rsqrt %cst_3 : f32
    %23 = spirv.FUnordLessThan %5, %8 : f16
    %24 = spirv.FUnordEqual %14, %12 : f32
    %25 = spirv.GL.UMax %c-29278_i16, %c-29278_i16 : i16
    %26 = spirv.FUnordGreaterThan %5, %cst_7 : f16
    %27 = llvm.mlir.constant(0 : index) : i64
    %28 = llvm.extractelement %0[%27 : i64] : vector<1xi16>
    memref.store %28, %alloc_17[%c30, %c10] : memref<24x16xi16>
    %29 = spirv.CL.rsqrt %cst_7 : f16
    %30 = spirv.CL.ceil %14 : f32
    %31 = spirv.UGreaterThanEqual %c4623_i16, %25 : i16
    %32 = spirv.UGreaterThanEqual %c771421837_i32, %c771421837_i32 : i32
    %alloc_18 = memref.alloc() : memref<i32>
    %33 = scf.while (%arg0 = %24) : (i1) -> i1 {
      scf.condition(%true) %31 : i1
    } do {
    ^bb0(%arg0: i1):
      memref.copy %alloc_15, %alloc_15 : memref<?xi32> to memref<?xi32>
      memref.store %c4623_i16, %alloc_12[%c7, %c1] : memref<16x3xi16>
      memref.copy %alloc_11, %alloc_11 : memref<?x?xf32> to memref<?x?xf32>
      scf.yield %17 : i1
    }
    %34 = scf.parallel (%arg0, %arg1) = (%c10, %c9) to (%c29, %c14) step (%c13, %c6) init (%cst_3) -> f32 {
      vector.print %cst_0 : vector<3xi16>
      scf.reduce(%cst_3)  : f32 {
      ^bb0(%arg2: f32, %arg3: f32):
        scf.reduce.return %cst_6 : f32
      }
      scf.yield
    }
    %35 = spirv.GL.Atan %5 : f16
    %36 = spirv.CL.rsqrt %29 : f16
    linalg.transpose ins(%1 : tensor<?x?xi16>) outs(%alloc_8 : memref<?x?xi16>) permutation = [1, 0] 
    %37 = spirv.FUnordLessThanEqual %12, %14 : f32
    memref.copy %alloc_11, %alloc_11 : memref<?x?xf32> to memref<?x?xf32>
    %38 = spirv.CL.ceil %22 : f32
    %39 = spirv.GL.SAbs %c265471212_i64 : i64
    %40 = spirv.ULessThan %39, %c265471212_i64 : i64
    scf.parallel (%arg0) = (%c2) to (%c10) step (%c11) {
      %114 = memref.realloc %alloc_9 : memref<?xi16> to memref<16xi16>
      scf.yield
    }
    %41 = spirv.GL.FSign %38 : f32
    %42 = spirv.GL.FMix %8 : f16, %13 : f16, %5 : f16 -> f16
    %43 = spirv.GL.Log %cst_6 : f32
    %44 = spirv.GL.Atan %cst_5 : f16
    %45 = spirv.GL.FMax %5, %42 : f16
    %46 = spirv.CL.tanh %45 : f16
    vector.print %cst_0 : vector<3xi16>
    %47 = spirv.GL.Exp %45 : f16
    %48 = spirv.FUnordLessThan %5, %13 : f16
    %49 = spirv.CL.round %8 : f16
    %50 = spirv.CL.u_min %c-29278_i16, %c-29278_i16 : i16
    %51 = spirv.CL.u_max %c265471212_i64, %c281204932_i64 : i64
    memref.store %c445093745_i32, %alloc_18[] : memref<i32>
    %52 = spirv.Unordered %14, %cst_3 : f32
    %53 = spirv.CL.tanh %43 : f32
    %alloc_19 = memref.alloc() : memref<f16>
    affine.vector_store %cst, %alloc_18[] : memref<i32>, vector<2xi32>
    %54 = spirv.GL.Log %30 : f32
    %55 = spirv.IsNan %43 : f32
    %56 = scf.while (%arg0 = %cst_1) : (vector<i16>) -> vector<i16> {
      scf.condition(%55) %cst_1 : vector<i16>
    } do {
    ^bb0(%arg0: vector<i16>):
      %114 = memref.atomic_rmw assign %30, %alloc[%c1] : (f32, memref<16xf32>) -> f32
      memref.copy %alloc_19, %alloc_19 : memref<f16> to memref<f16>
      scf.yield %cst_1 : vector<i16>
    }
    %57 = spirv.GL.UClamp %39, %39, %39 : i64
    %58 = spirv.FOrdLessThanEqual %54, %12 : f32
    %59 = spirv.GL.Asin %35 : f16
    %60 = spirv.GL.Sqrt %cst_7 : f16
    %61 = llvm.mlir.undef : vector<16xf32>
    %62 = llvm.mlir.constant(0 : i32) : i32
    %63 = llvm.insertelement %41, %61[%62 : i32] : vector<16xf32>
    %64 = llvm.shufflevector %63, %61 [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] : vector<16xf32> 
    %65 = llvm.intr.fmuladd(%64, %64, %64)  : (vector<16xf32>, vector<16xf32>, vector<16xf32>) -> vector<16xf32>
    %66 = spirv.LogicalOr %32, %55 : i1
    vector.print %cst : vector<2xi32>
    vector.print %21 : vector<2xi1>
    vector.print %cst_0 : vector<3xi16>
    vector.print %cst_1 : vector<i16>
    vector.print %cst : vector<2xi32>
    vector.print %64 : vector<16xf32>
    vector.print %65 : vector<16xf32>
    %67 = arith.extui %false_2 : i1 to i64
    llvm.call @printI64(%67) : (i64) -> ()
    llvm.call @printNewline() : () -> ()
    llvm.call @printI64(%c265471212_i64) : (i64) -> ()
    llvm.call @printNewline() : () -> ()
    %68 = arith.extsi %c4623_i16 : i16 to i64
    llvm.call @printI64(%68) : (i64) -> ()
    llvm.call @printNewline() : () -> ()
    %69 = arith.extsi %c22394_i16 : i16 to i64
    llvm.call @printI64(%69) : (i64) -> ()
    llvm.call @printNewline() : () -> ()
    %70 = arith.extui %false_2 : i1 to i64
    llvm.call @printI64(%70) : (i64) -> ()
    llvm.call @printNewline() : () -> ()
    %71 = arith.extsi %c1941353413_i32 : i32 to i64
    llvm.call @printI64(%71) : (i64) -> ()
    llvm.call @printNewline() : () -> ()
    %72 = arith.extsi %c-29278_i16 : i16 to i64
    llvm.call @printI64(%72) : (i64) -> ()
    llvm.call @printNewline() : () -> ()
    llvm.call @printI64(%c281204932_i64) : (i64) -> ()
    llvm.call @printNewline() : () -> ()
    llvm.call @printF32(%cst_3) : (f32) -> ()
    llvm.call @printNewline() : () -> ()
    %73 = llvm.bitcast %cst_4 : f16 to i16
    llvm.call @printF16(%73) : (i16) -> ()
    llvm.call @printNewline() : () -> ()
    %74 = llvm.bitcast %cst_5 : f16 to i16
    llvm.call @printF16(%74) : (i16) -> ()
    llvm.call @printNewline() : () -> ()
    %75 = arith.extsi %c771421837_i32 : i32 to i64
    llvm.call @printI64(%75) : (i64) -> ()
    llvm.call @printNewline() : () -> ()
    %76 = arith.extsi %c445093745_i32 : i32 to i64
    llvm.call @printI64(%76) : (i64) -> ()
    llvm.call @printNewline() : () -> ()
    %77 = arith.extui %true : i1 to i64
    llvm.call @printI64(%77) : (i64) -> ()
    llvm.call @printNewline() : () -> ()
    llvm.call @printF32(%cst_6) : (f32) -> ()
    llvm.call @printNewline() : () -> ()
    %78 = llvm.bitcast %cst_7 : f16 to i16
    llvm.call @printF16(%78) : (i16) -> ()
    llvm.call @printNewline() : () -> ()
    %79 = llvm.bitcast %5 : f16 to i16
    llvm.call @printF16(%79) : (i16) -> ()
    llvm.call @printNewline() : () -> ()
    %80 = arith.extui %6 : i1 to i64
    llvm.call @printI64(%80) : (i64) -> ()
    llvm.call @printNewline() : () -> ()
    %81 = arith.extui %7 : i1 to i64
    llvm.call @printI64(%81) : (i64) -> ()
    llvm.call @printNewline() : () -> ()
    %82 = llvm.bitcast %8 : f16 to i16
    llvm.call @printF16(%82) : (i16) -> ()
    llvm.call @printNewline() : () -> ()
    %83 = llvm.bitcast %9 : f16 to i16
    llvm.call @printF16(%83) : (i16) -> ()
    llvm.call @printNewline() : () -> ()
    %84 = llvm.bitcast %11 : f16 to i16
    llvm.call @printF16(%84) : (i16) -> ()
    llvm.call @printNewline() : () -> ()
    llvm.call @printF32(%12) : (f32) -> ()
    llvm.call @printNewline() : () -> ()
    %85 = llvm.bitcast %13 : f16 to i16
    llvm.call @printF16(%85) : (i16) -> ()
    llvm.call @printNewline() : () -> ()
    llvm.call @printF32(%14) : (f32) -> ()
    llvm.call @printNewline() : () -> ()
    %86 = llvm.bitcast %15 : f16 to i16
    llvm.call @printF16(%86) : (i16) -> ()
    llvm.call @printNewline() : () -> ()
    %87 = arith.extui %17 : i1 to i64
    llvm.call @printI64(%87) : (i64) -> ()
    llvm.call @printNewline() : () -> ()
    llvm.call @printF32(%22) : (f32) -> ()
    llvm.call @printNewline() : () -> ()
    %88 = arith.extui %23 : i1 to i64
    llvm.call @printI64(%88) : (i64) -> ()
    llvm.call @printNewline() : () -> ()
    %89 = arith.extui %24 : i1 to i64
    llvm.call @printI64(%89) : (i64) -> ()
    llvm.call @printNewline() : () -> ()
    %90 = arith.extsi %25 : i16 to i64
    llvm.call @printI64(%90) : (i64) -> ()
    llvm.call @printNewline() : () -> ()
    %91 = arith.extui %26 : i1 to i64
    llvm.call @printI64(%91) : (i64) -> ()
    llvm.call @printNewline() : () -> ()
    %92 = llvm.bitcast %29 : f16 to i16
    llvm.call @printF16(%92) : (i16) -> ()
    llvm.call @printNewline() : () -> ()
    llvm.call @printF32(%30) : (f32) -> ()
    llvm.call @printNewline() : () -> ()
    %93 = arith.extui %31 : i1 to i64
    llvm.call @printI64(%93) : (i64) -> ()
    llvm.call @printNewline() : () -> ()
    %94 = arith.extui %32 : i1 to i64
    llvm.call @printI64(%94) : (i64) -> ()
    llvm.call @printNewline() : () -> ()
    %95 = llvm.bitcast %35 : f16 to i16
    llvm.call @printF16(%95) : (i16) -> ()
    llvm.call @printNewline() : () -> ()
    %96 = llvm.bitcast %36 : f16 to i16
    llvm.call @printF16(%96) : (i16) -> ()
    llvm.call @printNewline() : () -> ()
    %97 = arith.extui %37 : i1 to i64
    llvm.call @printI64(%97) : (i64) -> ()
    llvm.call @printNewline() : () -> ()
    llvm.call @printF32(%38) : (f32) -> ()
    llvm.call @printNewline() : () -> ()
    llvm.call @printI64(%39) : (i64) -> ()
    llvm.call @printNewline() : () -> ()
    %98 = arith.extui %40 : i1 to i64
    llvm.call @printI64(%98) : (i64) -> ()
    llvm.call @printNewline() : () -> ()
    llvm.call @printF32(%41) : (f32) -> ()
    llvm.call @printNewline() : () -> ()
    %99 = llvm.bitcast %42 : f16 to i16
    llvm.call @printF16(%99) : (i16) -> ()
    llvm.call @printNewline() : () -> ()
    llvm.call @printF32(%43) : (f32) -> ()
    llvm.call @printNewline() : () -> ()
    %100 = llvm.bitcast %44 : f16 to i16
    llvm.call @printF16(%100) : (i16) -> ()
    llvm.call @printNewline() : () -> ()
    %101 = llvm.bitcast %45 : f16 to i16
    llvm.call @printF16(%101) : (i16) -> ()
    llvm.call @printNewline() : () -> ()
    %102 = llvm.bitcast %46 : f16 to i16
    llvm.call @printF16(%102) : (i16) -> ()
    llvm.call @printNewline() : () -> ()
    %103 = llvm.bitcast %47 : f16 to i16
    llvm.call @printF16(%103) : (i16) -> ()
    llvm.call @printNewline() : () -> ()
    %104 = arith.extui %48 : i1 to i64
    llvm.call @printI64(%104) : (i64) -> ()
    llvm.call @printNewline() : () -> ()
    %105 = llvm.bitcast %49 : f16 to i16
    llvm.call @printF16(%105) : (i16) -> ()
    llvm.call @printNewline() : () -> ()
    %106 = arith.extsi %50 : i16 to i64
    llvm.call @printI64(%106) : (i64) -> ()
    llvm.call @printNewline() : () -> ()
    llvm.call @printI64(%51) : (i64) -> ()
    llvm.call @printNewline() : () -> ()
    %107 = arith.extui %52 : i1 to i64
    llvm.call @printI64(%107) : (i64) -> ()
    llvm.call @printNewline() : () -> ()
    llvm.call @printF32(%53) : (f32) -> ()
    llvm.call @printNewline() : () -> ()
    llvm.call @printF32(%54) : (f32) -> ()
    llvm.call @printNewline() : () -> ()
    %108 = arith.extui %55 : i1 to i64
    llvm.call @printI64(%108) : (i64) -> ()
    llvm.call @printNewline() : () -> ()
    llvm.call @printI64(%57) : (i64) -> ()
    llvm.call @printNewline() : () -> ()
    %109 = arith.extui %58 : i1 to i64
    llvm.call @printI64(%109) : (i64) -> ()
    llvm.call @printNewline() : () -> ()
    %110 = arith.extui %false : i1 to i64
    llvm.call @printI64(%110) : (i64) -> ()
    llvm.call @printNewline() : () -> ()
    %111 = llvm.bitcast %59 : f16 to i16
    llvm.call @printF16(%111) : (i16) -> ()
    llvm.call @printNewline() : () -> ()
    %112 = llvm.bitcast %60 : f16 to i16
    llvm.call @printF16(%112) : (i16) -> ()
    llvm.call @printNewline() : () -> ()
    %113 = arith.extui %66 : i1 to i64
    llvm.call @printI64(%113) : (i64) -> ()
    llvm.call @printNewline() : () -> ()
    return
  }
}


// -----// IR Dump After ConvertVectorToSCF (convert-vector-to-scf) //----- //
#map = affine_map<(d0) -> (d0 + 30)>
#map1 = affine_map<(d0) -> (d0 + 16)>
#set = affine_set<() : (80610 >= 0, 1340 >= 0, 81930 >= 0)>
#set1 = affine_set<() : (24 >= 0, 30 >= 0)>
module {
  llvm.func @printF16(i16)
  llvm.func @printF32(f32)
  llvm.func @printNewline()
  llvm.func @printI64(i64)
  func.func @func1(%arg0: vector<16xi32>, %arg1: memref<?xf32>, %arg2: i1) {
    %c0 = arith.constant 0 : index
    %c16 = arith.constant 16 : index
    %c1 = arith.constant 1 : index
    %c15 = arith.constant 15 : index
    %c3 = arith.constant 3 : index
    %c2 = arith.constant 2 : index
    %c24 = arith.constant 24 : index
    %c23 = arith.constant 23 : index
    %cst = arith.constant dense<[1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]> : vector<16xi8>
    %c0_i64 = arith.constant 0 : i64
    %c4623_i64 = arith.constant 4623 : i64
    %c22394_i64 = arith.constant 22394 : i64
    %c1941353413_i64 = arith.constant 1941353413 : i64
    %c-29278_i64 = arith.constant -29278 : i64
    %c771421837_i64 = arith.constant 771421837 : i64
    %c445093745_i64 = arith.constant 445093745 : i64
    %c1_i64 = arith.constant 1 : i64
    %0 = llvm.mlir.constant(3 : index) : i64
    %cst_0 = arith.constant dense<0.000000e+00> : vector<24x16xf32>
    %1 = llvm.mlir.constant(0 : i32) : i32
    %c30 = arith.constant 30 : index
    %c29 = arith.constant 29 : index
    %c26 = arith.constant 26 : index
    %c25 = arith.constant 25 : index
    %c22 = arith.constant 22 : index
    %c21 = arith.constant 21 : index
    %c17 = arith.constant 17 : index
    %c13 = arith.constant 13 : index
    %c12 = arith.constant 12 : index
    %c10 = arith.constant 10 : index
    %c9 = arith.constant 9 : index
    %c7 = arith.constant 7 : index
    %c6 = arith.constant 6 : index
    %c5 = arith.constant 5 : index
    %c4 = arith.constant 4 : index
    %cst_1 = arith.constant 1.731200e+04 : f16
    %cst_2 = arith.constant 0x4E228E1D : f32
    %c445093745_i32 = arith.constant 445093745 : i32
    %c771421837_i32 = arith.constant 771421837 : i32
    %cst_3 = arith.constant 5.033600e+04 : f16
    %cst_4 = arith.constant 3.350400e+04 : f16
    %cst_5 = arith.constant 0x4D08837C : f32
    %c281204932_i64 = arith.constant 281204932 : i64
    %c-29278_i16 = arith.constant -29278 : i16
    %c1941353413_i32 = arith.constant 1941353413 : i32
    %c22394_i16 = arith.constant 22394 : i16
    %c4623_i16 = arith.constant 4623 : i16
    %c265471212_i64 = arith.constant 265471212 : i64
    %false = arith.constant false
    %cst_6 = arith.constant dense<8> : vector<16xindex>
    %idx432 = index.constant 432
    %cst_7 = arith.constant dense<[true, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false]> : vector<16xi1>
    %cst_8 = arith.constant dense<0x4D08837C> : vector<24x16xf32>
    %2 = builtin.unrealized_conversion_cast %cst_8 : vector<24x16xf32> to !llvm.array<24 x vector<16xf32>>
    %3 = builtin.unrealized_conversion_cast %cst_6 : vector<16xindex> to vector<16xi64>
    %4 = builtin.unrealized_conversion_cast %c0 : index to i64
    %5 = builtin.unrealized_conversion_cast %c5 : index to i64
    %6 = builtin.unrealized_conversion_cast %c7 : index to i64
    %7 = builtin.unrealized_conversion_cast %c26 : index to i64
    %8 = tensor.empty(%c17) : tensor<?x3xi1>
    %9 = tensor.empty() : tensor<16xi64>
    %10 = tensor.empty() : tensor<16xi1>
    %alloc = memref.alloc(%c24) : memref<?xf16>
    %alloc_9 = memref.alloc() : memref<16xf32>
    %11 = builtin.unrealized_conversion_cast %alloc_9 : memref<16xf32> to !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>
    %alloc_10 = memref.alloc(%c12, %c26) : memref<?x?xi16>
    %alloc_11 = memref.alloc(%c12) : memref<?xf16>
    %alloc_12 = memref.alloc(%c9) : memref<?x16xi64>
    %alloc_13 = memref.alloc(%c21) : memref<?xf16>
    %alloc_14 = memref.alloc(%c6) : memref<?xi1>
    %12 = builtin.unrealized_conversion_cast %alloc_14 : memref<?xi1> to !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>
    %alloc_15 = memref.alloc(%c9) : memref<?xi32>
    %alloc_16 = memref.alloc(%c9) : memref<?xi16>
    %13 = spirv.CL.s_abs %c1941353413_i32 : i32
    %alloc_17 = memref.alloc() : memref<16xi1>
    %14 = llvm.extractvalue %12[1] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %15 = llvm.getelementptr %14[%4] : (!llvm.ptr, i64) -> !llvm.ptr, i1
    %16 = llvm.load %15 {alignment = 1 : i64} : !llvm.ptr -> vector<16xi1>
    %17 = affine.vector_load %alloc_16[%c25] : memref<?xi16>, vector<3xi16>
    memref.store %c22394_i16, %alloc_16[%c0] : memref<?xi16>
    %18 = spirv.GL.FMix %cst_1 : f16, %cst_3 : f16, %cst_3 : f16 -> f16
    %19 = spirv.CL.fabs %18 : f16
    %20 = spirv.GL.Log %cst_1 : f16
    %21 = spirv.GL.InverseSqrt %cst_3 : f16
    %22 = spirv.GL.Acos %cst_4 : f16
    %23 = spirv.CL.cos %cst_4 : f16
    %24 = spirv.FOrdNotEqual %cst_3, %cst_4 : f16
    %25 = spirv.CL.pow %21, %20 : f16
    %26 = spirv.CL.exp %cst_3 : f16
    %27 = spirv.FOrdLessThanEqual %20, %cst_4 : f16
    %28 = spirv.CL.log %23 : f16
    %29 = spirv.FUnordNotEqual %cst_2, %cst_5 : f32
    scf.parallel (%arg3, %arg4) = (%c6, %c10) to (%c5, %c29) step (%c22, %c26) {
      memref.copy %alloc_13, %alloc_11 : memref<?xf16> to memref<?xf16>
      %435 = affine.if #set() -> memref<16xi16> {
        %alloc_19 = memref.alloc() : memref<16xi16>
        affine.yield %alloc_19 : memref<16xi16>
      } else {
        affine.store %13, %alloc_15[%c4] : memref<?xi32>
        %alloc_19 = memref.alloc() : memref<16xi16>
        affine.yield %alloc_19 : memref<16xi16>
      }
      bufferization.dealloc_tensor %8 : tensor<?x3xi1>
      scf.yield
    }
    %30 = spirv.CL.rint %cst_2 : f32
    %31 = spirv.CL.rint %28 : f16
    affine.vector_store %16, %alloc_14[%c24] : memref<?xi1>, vector<16xi1>
    %32 = spirv.CL.cos %22 : f16
    %33 = spirv.IsNan %cst_2 : f32
    %34 = spirv.BitReverse %c445093745_i32 : i32
    memref.store %c281204932_i64, %alloc_12[%c0, %c0] : memref<?x16xi64>
    %35 = spirv.GL.FSign %30 : f32
    %36 = spirv.CL.ceil %20 : f16
    %37 = llvm.mlir.undef : vector<16xf32>
    %38 = llvm.insertelement %30, %37[%1 : i32] : vector<16xf32>
    %39 = llvm.shufflevector %38, %37 [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] : vector<16xf32> 
    %40 = llvm.intr.fmuladd(%39, %39, %39)  : (vector<16xf32>, vector<16xf32>, vector<16xf32>) -> vector<16xf32>
    %41 = spirv.CL.s_min %c771421837_i32, %13 : i32
    bufferization.dealloc_tensor %9 : tensor<16xi64>
    %42 = affine.vector_load %arg1[%c0] : memref<?xf32>, vector<24xf32>
    %43 = spirv.CL.erf %21 : f16
    %44 = spirv.UGreaterThanEqual %c265471212_i64, %c281204932_i64 : i64
    %45 = spirv.GL.Acos %20 : f16
    %46 = spirv.CL.rint %cst_4 : f16
    %47 = builtin.unrealized_conversion_cast %cst_0 : vector<24x16xf32> to !llvm.array<24 x vector<16xf32>>
    %48 = llvm.extractvalue %2[0] : !llvm.array<24 x vector<16xf32>> 
    %49 = llvm.extractvalue %2[0] : !llvm.array<24 x vector<16xf32>> 
    %50 = llvm.extractvalue %2[0] : !llvm.array<24 x vector<16xf32>> 
    %51 = llvm.intr.fmuladd(%48, %49, %50)  : (vector<16xf32>, vector<16xf32>, vector<16xf32>) -> vector<16xf32>
    %52 = llvm.insertvalue %51, %47[0] : !llvm.array<24 x vector<16xf32>> 
    %53 = llvm.extractvalue %2[1] : !llvm.array<24 x vector<16xf32>> 
    %54 = llvm.extractvalue %2[1] : !llvm.array<24 x vector<16xf32>> 
    %55 = llvm.extractvalue %2[1] : !llvm.array<24 x vector<16xf32>> 
    %56 = llvm.intr.fmuladd(%53, %54, %55)  : (vector<16xf32>, vector<16xf32>, vector<16xf32>) -> vector<16xf32>
    %57 = llvm.insertvalue %56, %52[1] : !llvm.array<24 x vector<16xf32>> 
    %58 = llvm.extractvalue %2[2] : !llvm.array<24 x vector<16xf32>> 
    %59 = llvm.extractvalue %2[2] : !llvm.array<24 x vector<16xf32>> 
    %60 = llvm.extractvalue %2[2] : !llvm.array<24 x vector<16xf32>> 
    %61 = llvm.intr.fmuladd(%58, %59, %60)  : (vector<16xf32>, vector<16xf32>, vector<16xf32>) -> vector<16xf32>
    %62 = llvm.insertvalue %61, %57[2] : !llvm.array<24 x vector<16xf32>> 
    %63 = llvm.extractvalue %2[3] : !llvm.array<24 x vector<16xf32>> 
    %64 = llvm.extractvalue %2[3] : !llvm.array<24 x vector<16xf32>> 
    %65 = llvm.extractvalue %2[3] : !llvm.array<24 x vector<16xf32>> 
    %66 = llvm.intr.fmuladd(%63, %64, %65)  : (vector<16xf32>, vector<16xf32>, vector<16xf32>) -> vector<16xf32>
    %67 = llvm.insertvalue %66, %62[3] : !llvm.array<24 x vector<16xf32>> 
    %68 = llvm.extractvalue %2[4] : !llvm.array<24 x vector<16xf32>> 
    %69 = llvm.extractvalue %2[4] : !llvm.array<24 x vector<16xf32>> 
    %70 = llvm.extractvalue %2[4] : !llvm.array<24 x vector<16xf32>> 
    %71 = llvm.intr.fmuladd(%68, %69, %70)  : (vector<16xf32>, vector<16xf32>, vector<16xf32>) -> vector<16xf32>
    %72 = llvm.insertvalue %71, %67[4] : !llvm.array<24 x vector<16xf32>> 
    %73 = llvm.extractvalue %2[5] : !llvm.array<24 x vector<16xf32>> 
    %74 = llvm.extractvalue %2[5] : !llvm.array<24 x vector<16xf32>> 
    %75 = llvm.extractvalue %2[5] : !llvm.array<24 x vector<16xf32>> 
    %76 = llvm.intr.fmuladd(%73, %74, %75)  : (vector<16xf32>, vector<16xf32>, vector<16xf32>) -> vector<16xf32>
    %77 = llvm.insertvalue %76, %72[5] : !llvm.array<24 x vector<16xf32>> 
    %78 = llvm.extractvalue %2[6] : !llvm.array<24 x vector<16xf32>> 
    %79 = llvm.extractvalue %2[6] : !llvm.array<24 x vector<16xf32>> 
    %80 = llvm.extractvalue %2[6] : !llvm.array<24 x vector<16xf32>> 
    %81 = llvm.intr.fmuladd(%78, %79, %80)  : (vector<16xf32>, vector<16xf32>, vector<16xf32>) -> vector<16xf32>
    %82 = llvm.insertvalue %81, %77[6] : !llvm.array<24 x vector<16xf32>> 
    %83 = llvm.extractvalue %2[7] : !llvm.array<24 x vector<16xf32>> 
    %84 = llvm.extractvalue %2[7] : !llvm.array<24 x vector<16xf32>> 
    %85 = llvm.extractvalue %2[7] : !llvm.array<24 x vector<16xf32>> 
    %86 = llvm.intr.fmuladd(%83, %84, %85)  : (vector<16xf32>, vector<16xf32>, vector<16xf32>) -> vector<16xf32>
    %87 = llvm.insertvalue %86, %82[7] : !llvm.array<24 x vector<16xf32>> 
    %88 = llvm.extractvalue %2[8] : !llvm.array<24 x vector<16xf32>> 
    %89 = llvm.extractvalue %2[8] : !llvm.array<24 x vector<16xf32>> 
    %90 = llvm.extractvalue %2[8] : !llvm.array<24 x vector<16xf32>> 
    %91 = llvm.intr.fmuladd(%88, %89, %90)  : (vector<16xf32>, vector<16xf32>, vector<16xf32>) -> vector<16xf32>
    %92 = llvm.insertvalue %91, %87[8] : !llvm.array<24 x vector<16xf32>> 
    %93 = llvm.extractvalue %2[9] : !llvm.array<24 x vector<16xf32>> 
    %94 = llvm.extractvalue %2[9] : !llvm.array<24 x vector<16xf32>> 
    %95 = llvm.extractvalue %2[9] : !llvm.array<24 x vector<16xf32>> 
    %96 = llvm.intr.fmuladd(%93, %94, %95)  : (vector<16xf32>, vector<16xf32>, vector<16xf32>) -> vector<16xf32>
    %97 = llvm.insertvalue %96, %92[9] : !llvm.array<24 x vector<16xf32>> 
    %98 = llvm.extractvalue %2[10] : !llvm.array<24 x vector<16xf32>> 
    %99 = llvm.extractvalue %2[10] : !llvm.array<24 x vector<16xf32>> 
    %100 = llvm.extractvalue %2[10] : !llvm.array<24 x vector<16xf32>> 
    %101 = llvm.intr.fmuladd(%98, %99, %100)  : (vector<16xf32>, vector<16xf32>, vector<16xf32>) -> vector<16xf32>
    %102 = llvm.insertvalue %101, %97[10] : !llvm.array<24 x vector<16xf32>> 
    %103 = llvm.extractvalue %2[11] : !llvm.array<24 x vector<16xf32>> 
    %104 = llvm.extractvalue %2[11] : !llvm.array<24 x vector<16xf32>> 
    %105 = llvm.extractvalue %2[11] : !llvm.array<24 x vector<16xf32>> 
    %106 = llvm.intr.fmuladd(%103, %104, %105)  : (vector<16xf32>, vector<16xf32>, vector<16xf32>) -> vector<16xf32>
    %107 = llvm.insertvalue %106, %102[11] : !llvm.array<24 x vector<16xf32>> 
    %108 = llvm.extractvalue %2[12] : !llvm.array<24 x vector<16xf32>> 
    %109 = llvm.extractvalue %2[12] : !llvm.array<24 x vector<16xf32>> 
    %110 = llvm.extractvalue %2[12] : !llvm.array<24 x vector<16xf32>> 
    %111 = llvm.intr.fmuladd(%108, %109, %110)  : (vector<16xf32>, vector<16xf32>, vector<16xf32>) -> vector<16xf32>
    %112 = llvm.insertvalue %111, %107[12] : !llvm.array<24 x vector<16xf32>> 
    %113 = llvm.extractvalue %2[13] : !llvm.array<24 x vector<16xf32>> 
    %114 = llvm.extractvalue %2[13] : !llvm.array<24 x vector<16xf32>> 
    %115 = llvm.extractvalue %2[13] : !llvm.array<24 x vector<16xf32>> 
    %116 = llvm.intr.fmuladd(%113, %114, %115)  : (vector<16xf32>, vector<16xf32>, vector<16xf32>) -> vector<16xf32>
    %117 = llvm.insertvalue %116, %112[13] : !llvm.array<24 x vector<16xf32>> 
    %118 = llvm.extractvalue %2[14] : !llvm.array<24 x vector<16xf32>> 
    %119 = llvm.extractvalue %2[14] : !llvm.array<24 x vector<16xf32>> 
    %120 = llvm.extractvalue %2[14] : !llvm.array<24 x vector<16xf32>> 
    %121 = llvm.intr.fmuladd(%118, %119, %120)  : (vector<16xf32>, vector<16xf32>, vector<16xf32>) -> vector<16xf32>
    %122 = llvm.insertvalue %121, %117[14] : !llvm.array<24 x vector<16xf32>> 
    %123 = llvm.extractvalue %2[15] : !llvm.array<24 x vector<16xf32>> 
    %124 = llvm.extractvalue %2[15] : !llvm.array<24 x vector<16xf32>> 
    %125 = llvm.extractvalue %2[15] : !llvm.array<24 x vector<16xf32>> 
    %126 = llvm.intr.fmuladd(%123, %124, %125)  : (vector<16xf32>, vector<16xf32>, vector<16xf32>) -> vector<16xf32>
    %127 = llvm.insertvalue %126, %122[15] : !llvm.array<24 x vector<16xf32>> 
    %128 = llvm.extractvalue %2[16] : !llvm.array<24 x vector<16xf32>> 
    %129 = llvm.extractvalue %2[16] : !llvm.array<24 x vector<16xf32>> 
    %130 = llvm.extractvalue %2[16] : !llvm.array<24 x vector<16xf32>> 
    %131 = llvm.intr.fmuladd(%128, %129, %130)  : (vector<16xf32>, vector<16xf32>, vector<16xf32>) -> vector<16xf32>
    %132 = llvm.insertvalue %131, %127[16] : !llvm.array<24 x vector<16xf32>> 
    %133 = llvm.extractvalue %2[17] : !llvm.array<24 x vector<16xf32>> 
    %134 = llvm.extractvalue %2[17] : !llvm.array<24 x vector<16xf32>> 
    %135 = llvm.extractvalue %2[17] : !llvm.array<24 x vector<16xf32>> 
    %136 = llvm.intr.fmuladd(%133, %134, %135)  : (vector<16xf32>, vector<16xf32>, vector<16xf32>) -> vector<16xf32>
    %137 = llvm.insertvalue %136, %132[17] : !llvm.array<24 x vector<16xf32>> 
    %138 = llvm.extractvalue %2[18] : !llvm.array<24 x vector<16xf32>> 
    %139 = llvm.extractvalue %2[18] : !llvm.array<24 x vector<16xf32>> 
    %140 = llvm.extractvalue %2[18] : !llvm.array<24 x vector<16xf32>> 
    %141 = llvm.intr.fmuladd(%138, %139, %140)  : (vector<16xf32>, vector<16xf32>, vector<16xf32>) -> vector<16xf32>
    %142 = llvm.insertvalue %141, %137[18] : !llvm.array<24 x vector<16xf32>> 
    %143 = llvm.extractvalue %2[19] : !llvm.array<24 x vector<16xf32>> 
    %144 = llvm.extractvalue %2[19] : !llvm.array<24 x vector<16xf32>> 
    %145 = llvm.extractvalue %2[19] : !llvm.array<24 x vector<16xf32>> 
    %146 = llvm.intr.fmuladd(%143, %144, %145)  : (vector<16xf32>, vector<16xf32>, vector<16xf32>) -> vector<16xf32>
    %147 = llvm.insertvalue %146, %142[19] : !llvm.array<24 x vector<16xf32>> 
    %148 = llvm.extractvalue %2[20] : !llvm.array<24 x vector<16xf32>> 
    %149 = llvm.extractvalue %2[20] : !llvm.array<24 x vector<16xf32>> 
    %150 = llvm.extractvalue %2[20] : !llvm.array<24 x vector<16xf32>> 
    %151 = llvm.intr.fmuladd(%148, %149, %150)  : (vector<16xf32>, vector<16xf32>, vector<16xf32>) -> vector<16xf32>
    %152 = llvm.insertvalue %151, %147[20] : !llvm.array<24 x vector<16xf32>> 
    %153 = llvm.extractvalue %2[21] : !llvm.array<24 x vector<16xf32>> 
    %154 = llvm.extractvalue %2[21] : !llvm.array<24 x vector<16xf32>> 
    %155 = llvm.extractvalue %2[21] : !llvm.array<24 x vector<16xf32>> 
    %156 = llvm.intr.fmuladd(%153, %154, %155)  : (vector<16xf32>, vector<16xf32>, vector<16xf32>) -> vector<16xf32>
    %157 = llvm.insertvalue %156, %152[21] : !llvm.array<24 x vector<16xf32>> 
    %158 = llvm.extractvalue %2[22] : !llvm.array<24 x vector<16xf32>> 
    %159 = llvm.extractvalue %2[22] : !llvm.array<24 x vector<16xf32>> 
    %160 = llvm.extractvalue %2[22] : !llvm.array<24 x vector<16xf32>> 
    %161 = llvm.intr.fmuladd(%158, %159, %160)  : (vector<16xf32>, vector<16xf32>, vector<16xf32>) -> vector<16xf32>
    %162 = llvm.insertvalue %161, %157[22] : !llvm.array<24 x vector<16xf32>> 
    %163 = llvm.extractvalue %2[23] : !llvm.array<24 x vector<16xf32>> 
    %164 = llvm.extractvalue %2[23] : !llvm.array<24 x vector<16xf32>> 
    %165 = llvm.extractvalue %2[23] : !llvm.array<24 x vector<16xf32>> 
    %166 = llvm.intr.fmuladd(%163, %164, %165)  : (vector<16xf32>, vector<16xf32>, vector<16xf32>) -> vector<16xf32>
    %167 = llvm.insertvalue %166, %162[23] : !llvm.array<24 x vector<16xf32>> 
    %168 = builtin.unrealized_conversion_cast %167 : !llvm.array<24 x vector<16xf32>> to vector<24x16xf32>
    %169 = spirv.CL.log %19 : f16
    %170 = spirv.CL.ceil %22 : f16
    %171 = spirv.CL.s_max %c771421837_i32, %c1941353413_i32 : i32
    %172 = spirv.GL.Asin %23 : f16
    %173 = llvm.bitcast %40 : vector<16xf32> to vector<16xi32>
    %174 = arith.extui %16 : vector<16xi1> to vector<16xi8>
    vector.print punctuation <open>
    scf.for %arg3 = %c0 to %c16 step %c1 {
      %435 = vector.extractelement %174[%arg3 : index] : vector<16xi8>
      vector.print %435 : i8 punctuation <no_punctuation>
      %436 = arith.cmpi ult, %arg3, %c15 : index
      scf.if %436 {
        vector.print punctuation <comma>
      }
    }
    vector.print punctuation <close>
    vector.print
    %175 = spirv.FOrdGreaterThan %cst_4, %26 : f16
    %176 = spirv.CL.exp %cst_1 : f16
    %177 = spirv.CL.round %23 : f16
    %178 = spirv.CL.floor %177 : f16
    %179 = spirv.IEqual %c-29278_i16, %c22394_i16 : i16
    %180 = spirv.CL.pow %46, %26 : f16
    %181 = affine.load %alloc_12[%c30, %c4] : memref<?x16xi64>
    %182 = spirv.CL.cos %19 : f16
    %183 = spirv.CL.rsqrt %21 : f16
    %184 = memref.realloc %alloc : memref<?xf16> to memref<3xf16>
    linalg.transpose ins(%alloc_13 : memref<?xf16>) outs(%alloc : memref<?xf16>) permutation = [0] 
    %185 = spirv.GL.Cosh %31 : f16
    %186 = spirv.UGreaterThan %c-29278_i16, %c22394_i16 : i16
    %187 = spirv.CL.ceil %32 : f16
    scf.parallel (%arg3) = (%c13) to (%idx432) step (%c7) {
      vector.warp_execute_on_lane_0(%c0)[32] {
        memref.copy %arg1, %arg1 : memref<?xf32> to memref<?xf32>
      }
      memref.copy %alloc_10, %alloc_10 : memref<?x?xi16> to memref<?x?xi16>
      %435 = memref.realloc %alloc_15 : memref<?xi32> to memref<3xi32>
      scf.yield
    }
    %188 = spirv.CL.erf %32 : f16
    %189 = spirv.GL.UMax %34, %c1941353413_i32 : i32
    %190 = spirv.GL.Floor %185 : f16
    %191 = spirv.GL.SSign %c4623_i16 : i16
    %192 = spirv.CL.tanh %20 : f16
    %193 = spirv.GL.FSign %19 : f16
    linalg.transpose ins(%10 : tensor<16xi1>) outs(%alloc_17 : memref<16xi1>) permutation = [0] 
    %194 = spirv.GL.FMax %26, %43 : f16
    %195 = spirv.GL.UClamp %c4623_i16, %c4623_i16, %c22394_i16 : i16
    %196 = spirv.CL.log %cst_1 : f16
    %197 = spirv.Unordered %20, %26 : f16
    %198 = llvm.extractvalue %11[1] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %199 = llvm.getelementptr %198[%5] : (!llvm.ptr, i64) -> !llvm.ptr, f32
    %200 = llvm.getelementptr %199[%3] : (!llvm.ptr, vector<16xi64>) -> !llvm.vec<16 x ptr>, f32
    llvm.intr.masked.scatter %39, %200, %cst_7 {alignment = 4 : i32} : vector<16xf32>, vector<16xi1> into !llvm.vec<16 x ptr>
    %201 = spirv.FUnordLessThanEqual %21, %182 : f16
    %alloc_18 = memref.alloc() : memref<16x3xi64>
    %202 = builtin.unrealized_conversion_cast %alloc_18 : memref<16x3xi64> to !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)>
    %203 = llvm.mlir.undef : !llvm.array<24 x vector<16xi64>>
    %204 = llvm.mlir.undef : vector<16xi64>
    %205 = llvm.insertelement %181, %204[%1 : i32] : vector<16xi64>
    %206 = llvm.shufflevector %205, %205 [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] : vector<16xi64> 
    %207 = llvm.insertvalue %206, %203[0] : !llvm.array<24 x vector<16xi64>> 
    %208 = llvm.insertvalue %206, %207[1] : !llvm.array<24 x vector<16xi64>> 
    %209 = llvm.insertvalue %206, %208[2] : !llvm.array<24 x vector<16xi64>> 
    %210 = llvm.insertvalue %206, %209[3] : !llvm.array<24 x vector<16xi64>> 
    %211 = llvm.insertvalue %206, %210[4] : !llvm.array<24 x vector<16xi64>> 
    %212 = llvm.insertvalue %206, %211[5] : !llvm.array<24 x vector<16xi64>> 
    %213 = llvm.insertvalue %206, %212[6] : !llvm.array<24 x vector<16xi64>> 
    %214 = llvm.insertvalue %206, %213[7] : !llvm.array<24 x vector<16xi64>> 
    %215 = llvm.insertvalue %206, %214[8] : !llvm.array<24 x vector<16xi64>> 
    %216 = llvm.insertvalue %206, %215[9] : !llvm.array<24 x vector<16xi64>> 
    %217 = llvm.insertvalue %206, %216[10] : !llvm.array<24 x vector<16xi64>> 
    %218 = llvm.insertvalue %206, %217[11] : !llvm.array<24 x vector<16xi64>> 
    %219 = llvm.insertvalue %206, %218[12] : !llvm.array<24 x vector<16xi64>> 
    %220 = llvm.insertvalue %206, %219[13] : !llvm.array<24 x vector<16xi64>> 
    %221 = llvm.insertvalue %206, %220[14] : !llvm.array<24 x vector<16xi64>> 
    %222 = llvm.insertvalue %206, %221[15] : !llvm.array<24 x vector<16xi64>> 
    %223 = llvm.insertvalue %206, %222[16] : !llvm.array<24 x vector<16xi64>> 
    %224 = llvm.insertvalue %206, %223[17] : !llvm.array<24 x vector<16xi64>> 
    %225 = llvm.insertvalue %206, %224[18] : !llvm.array<24 x vector<16xi64>> 
    %226 = llvm.insertvalue %206, %225[19] : !llvm.array<24 x vector<16xi64>> 
    %227 = llvm.insertvalue %206, %226[20] : !llvm.array<24 x vector<16xi64>> 
    %228 = llvm.insertvalue %206, %227[21] : !llvm.array<24 x vector<16xi64>> 
    %229 = llvm.insertvalue %206, %228[22] : !llvm.array<24 x vector<16xi64>> 
    %230 = llvm.insertvalue %206, %229[23] : !llvm.array<24 x vector<16xi64>> 
    %231 = builtin.unrealized_conversion_cast %230 : !llvm.array<24 x vector<16xi64>> to vector<24x16xi64>
    %232 = llvm.mlir.undef : !llvm.array<24 x vector<16xi1>>
    %233 = llvm.mlir.undef : vector<16xi1>
    %234 = llvm.insertelement %197, %233[%1 : i32] : vector<16xi1>
    %235 = llvm.shufflevector %234, %234 [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] : vector<16xi1> 
    %236 = llvm.insertvalue %235, %232[0] : !llvm.array<24 x vector<16xi1>> 
    %237 = llvm.insertvalue %235, %236[1] : !llvm.array<24 x vector<16xi1>> 
    %238 = llvm.insertvalue %235, %237[2] : !llvm.array<24 x vector<16xi1>> 
    %239 = llvm.insertvalue %235, %238[3] : !llvm.array<24 x vector<16xi1>> 
    %240 = llvm.insertvalue %235, %239[4] : !llvm.array<24 x vector<16xi1>> 
    %241 = llvm.insertvalue %235, %240[5] : !llvm.array<24 x vector<16xi1>> 
    %242 = llvm.insertvalue %235, %241[6] : !llvm.array<24 x vector<16xi1>> 
    %243 = llvm.insertvalue %235, %242[7] : !llvm.array<24 x vector<16xi1>> 
    %244 = llvm.insertvalue %235, %243[8] : !llvm.array<24 x vector<16xi1>> 
    %245 = llvm.insertvalue %235, %244[9] : !llvm.array<24 x vector<16xi1>> 
    %246 = llvm.insertvalue %235, %245[10] : !llvm.array<24 x vector<16xi1>> 
    %247 = llvm.insertvalue %235, %246[11] : !llvm.array<24 x vector<16xi1>> 
    %248 = llvm.insertvalue %235, %247[12] : !llvm.array<24 x vector<16xi1>> 
    %249 = llvm.insertvalue %235, %248[13] : !llvm.array<24 x vector<16xi1>> 
    %250 = llvm.insertvalue %235, %249[14] : !llvm.array<24 x vector<16xi1>> 
    %251 = llvm.insertvalue %235, %250[15] : !llvm.array<24 x vector<16xi1>> 
    %252 = llvm.insertvalue %235, %251[16] : !llvm.array<24 x vector<16xi1>> 
    %253 = llvm.insertvalue %235, %252[17] : !llvm.array<24 x vector<16xi1>> 
    %254 = llvm.insertvalue %235, %253[18] : !llvm.array<24 x vector<16xi1>> 
    %255 = llvm.insertvalue %235, %254[19] : !llvm.array<24 x vector<16xi1>> 
    %256 = llvm.insertvalue %235, %255[20] : !llvm.array<24 x vector<16xi1>> 
    %257 = llvm.insertvalue %235, %256[21] : !llvm.array<24 x vector<16xi1>> 
    %258 = llvm.insertvalue %235, %257[22] : !llvm.array<24 x vector<16xi1>> 
    %259 = llvm.insertvalue %235, %258[23] : !llvm.array<24 x vector<16xi1>> 
    %260 = builtin.unrealized_conversion_cast %259 : !llvm.array<24 x vector<16xi1>> to vector<24x16xi1>
    %261 = llvm.mlir.undef : !llvm.array<24 x vector<16xi32>>
    %262 = llvm.mlir.undef : vector<16xi32>
    %263 = llvm.insertelement %189, %262[%1 : i32] : vector<16xi32>
    %264 = llvm.shufflevector %263, %263 [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] : vector<16xi32> 
    %265 = llvm.insertvalue %264, %261[0] : !llvm.array<24 x vector<16xi32>> 
    %266 = llvm.insertvalue %264, %265[1] : !llvm.array<24 x vector<16xi32>> 
    %267 = llvm.insertvalue %264, %266[2] : !llvm.array<24 x vector<16xi32>> 
    %268 = llvm.insertvalue %264, %267[3] : !llvm.array<24 x vector<16xi32>> 
    %269 = llvm.insertvalue %264, %268[4] : !llvm.array<24 x vector<16xi32>> 
    %270 = llvm.insertvalue %264, %269[5] : !llvm.array<24 x vector<16xi32>> 
    %271 = llvm.insertvalue %264, %270[6] : !llvm.array<24 x vector<16xi32>> 
    %272 = llvm.insertvalue %264, %271[7] : !llvm.array<24 x vector<16xi32>> 
    %273 = llvm.insertvalue %264, %272[8] : !llvm.array<24 x vector<16xi32>> 
    %274 = llvm.insertvalue %264, %273[9] : !llvm.array<24 x vector<16xi32>> 
    %275 = llvm.insertvalue %264, %274[10] : !llvm.array<24 x vector<16xi32>> 
    %276 = llvm.insertvalue %264, %275[11] : !llvm.array<24 x vector<16xi32>> 
    %277 = llvm.insertvalue %264, %276[12] : !llvm.array<24 x vector<16xi32>> 
    %278 = llvm.insertvalue %264, %277[13] : !llvm.array<24 x vector<16xi32>> 
    %279 = llvm.insertvalue %264, %278[14] : !llvm.array<24 x vector<16xi32>> 
    %280 = llvm.insertvalue %264, %279[15] : !llvm.array<24 x vector<16xi32>> 
    %281 = llvm.insertvalue %264, %280[16] : !llvm.array<24 x vector<16xi32>> 
    %282 = llvm.insertvalue %264, %281[17] : !llvm.array<24 x vector<16xi32>> 
    %283 = llvm.insertvalue %264, %282[18] : !llvm.array<24 x vector<16xi32>> 
    %284 = llvm.insertvalue %264, %283[19] : !llvm.array<24 x vector<16xi32>> 
    %285 = llvm.insertvalue %264, %284[20] : !llvm.array<24 x vector<16xi32>> 
    %286 = llvm.insertvalue %264, %285[21] : !llvm.array<24 x vector<16xi32>> 
    %287 = llvm.insertvalue %264, %286[22] : !llvm.array<24 x vector<16xi32>> 
    %288 = llvm.insertvalue %264, %287[23] : !llvm.array<24 x vector<16xi32>> 
    %289 = builtin.unrealized_conversion_cast %288 : !llvm.array<24 x vector<16xi32>> to vector<24x16xi32>
    %290 = llvm.extractvalue %202[1] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %291 = llvm.mul %6, %0  : i64
    %292 = llvm.add %291, %7  : i64
    %293 = llvm.getelementptr %290[%292] : (!llvm.ptr, i64) -> !llvm.ptr, i64
    %294 = llvm.mlir.undef : !llvm.array<24 x vector<16xi64>>
    %295 = llvm.getelementptr %293[%264] : (!llvm.ptr, vector<16xi32>) -> !llvm.vec<16 x ptr>, i64
    %296 = llvm.intr.masked.gather %295, %235, %206 {alignment = 8 : i32} : (!llvm.vec<16 x ptr>, vector<16xi1>, vector<16xi64>) -> vector<16xi64>
    %297 = llvm.insertvalue %296, %294[0] : !llvm.array<24 x vector<16xi64>> 
    %298 = llvm.getelementptr %293[%264] : (!llvm.ptr, vector<16xi32>) -> !llvm.vec<16 x ptr>, i64
    %299 = llvm.intr.masked.gather %298, %235, %206 {alignment = 8 : i32} : (!llvm.vec<16 x ptr>, vector<16xi1>, vector<16xi64>) -> vector<16xi64>
    %300 = llvm.insertvalue %299, %297[1] : !llvm.array<24 x vector<16xi64>> 
    %301 = llvm.getelementptr %293[%264] : (!llvm.ptr, vector<16xi32>) -> !llvm.vec<16 x ptr>, i64
    %302 = llvm.intr.masked.gather %301, %235, %206 {alignment = 8 : i32} : (!llvm.vec<16 x ptr>, vector<16xi1>, vector<16xi64>) -> vector<16xi64>
    %303 = llvm.insertvalue %302, %300[2] : !llvm.array<24 x vector<16xi64>> 
    %304 = llvm.getelementptr %293[%264] : (!llvm.ptr, vector<16xi32>) -> !llvm.vec<16 x ptr>, i64
    %305 = llvm.intr.masked.gather %304, %235, %206 {alignment = 8 : i32} : (!llvm.vec<16 x ptr>, vector<16xi1>, vector<16xi64>) -> vector<16xi64>
    %306 = llvm.insertvalue %305, %303[3] : !llvm.array<24 x vector<16xi64>> 
    %307 = llvm.getelementptr %293[%264] : (!llvm.ptr, vector<16xi32>) -> !llvm.vec<16 x ptr>, i64
    %308 = llvm.intr.masked.gather %307, %235, %206 {alignment = 8 : i32} : (!llvm.vec<16 x ptr>, vector<16xi1>, vector<16xi64>) -> vector<16xi64>
    %309 = llvm.insertvalue %308, %306[4] : !llvm.array<24 x vector<16xi64>> 
    %310 = llvm.getelementptr %293[%264] : (!llvm.ptr, vector<16xi32>) -> !llvm.vec<16 x ptr>, i64
    %311 = llvm.intr.masked.gather %310, %235, %206 {alignment = 8 : i32} : (!llvm.vec<16 x ptr>, vector<16xi1>, vector<16xi64>) -> vector<16xi64>
    %312 = llvm.insertvalue %311, %309[5] : !llvm.array<24 x vector<16xi64>> 
    %313 = llvm.getelementptr %293[%264] : (!llvm.ptr, vector<16xi32>) -> !llvm.vec<16 x ptr>, i64
    %314 = llvm.intr.masked.gather %313, %235, %206 {alignment = 8 : i32} : (!llvm.vec<16 x ptr>, vector<16xi1>, vector<16xi64>) -> vector<16xi64>
    %315 = llvm.insertvalue %314, %312[6] : !llvm.array<24 x vector<16xi64>> 
    %316 = llvm.getelementptr %293[%264] : (!llvm.ptr, vector<16xi32>) -> !llvm.vec<16 x ptr>, i64
    %317 = llvm.intr.masked.gather %316, %235, %206 {alignment = 8 : i32} : (!llvm.vec<16 x ptr>, vector<16xi1>, vector<16xi64>) -> vector<16xi64>
    %318 = llvm.insertvalue %317, %315[7] : !llvm.array<24 x vector<16xi64>> 
    %319 = llvm.getelementptr %293[%264] : (!llvm.ptr, vector<16xi32>) -> !llvm.vec<16 x ptr>, i64
    %320 = llvm.intr.masked.gather %319, %235, %206 {alignment = 8 : i32} : (!llvm.vec<16 x ptr>, vector<16xi1>, vector<16xi64>) -> vector<16xi64>
    %321 = llvm.insertvalue %320, %318[8] : !llvm.array<24 x vector<16xi64>> 
    %322 = llvm.getelementptr %293[%264] : (!llvm.ptr, vector<16xi32>) -> !llvm.vec<16 x ptr>, i64
    %323 = llvm.intr.masked.gather %322, %235, %206 {alignment = 8 : i32} : (!llvm.vec<16 x ptr>, vector<16xi1>, vector<16xi64>) -> vector<16xi64>
    %324 = llvm.insertvalue %323, %321[9] : !llvm.array<24 x vector<16xi64>> 
    %325 = llvm.getelementptr %293[%264] : (!llvm.ptr, vector<16xi32>) -> !llvm.vec<16 x ptr>, i64
    %326 = llvm.intr.masked.gather %325, %235, %206 {alignment = 8 : i32} : (!llvm.vec<16 x ptr>, vector<16xi1>, vector<16xi64>) -> vector<16xi64>
    %327 = llvm.insertvalue %326, %324[10] : !llvm.array<24 x vector<16xi64>> 
    %328 = llvm.getelementptr %293[%264] : (!llvm.ptr, vector<16xi32>) -> !llvm.vec<16 x ptr>, i64
    %329 = llvm.intr.masked.gather %328, %235, %206 {alignment = 8 : i32} : (!llvm.vec<16 x ptr>, vector<16xi1>, vector<16xi64>) -> vector<16xi64>
    %330 = llvm.insertvalue %329, %327[11] : !llvm.array<24 x vector<16xi64>> 
    %331 = llvm.getelementptr %293[%264] : (!llvm.ptr, vector<16xi32>) -> !llvm.vec<16 x ptr>, i64
    %332 = llvm.intr.masked.gather %331, %235, %206 {alignment = 8 : i32} : (!llvm.vec<16 x ptr>, vector<16xi1>, vector<16xi64>) -> vector<16xi64>
    %333 = llvm.insertvalue %332, %330[12] : !llvm.array<24 x vector<16xi64>> 
    %334 = llvm.getelementptr %293[%264] : (!llvm.ptr, vector<16xi32>) -> !llvm.vec<16 x ptr>, i64
    %335 = llvm.intr.masked.gather %334, %235, %206 {alignment = 8 : i32} : (!llvm.vec<16 x ptr>, vector<16xi1>, vector<16xi64>) -> vector<16xi64>
    %336 = llvm.insertvalue %335, %333[13] : !llvm.array<24 x vector<16xi64>> 
    %337 = llvm.getelementptr %293[%264] : (!llvm.ptr, vector<16xi32>) -> !llvm.vec<16 x ptr>, i64
    %338 = llvm.intr.masked.gather %337, %235, %206 {alignment = 8 : i32} : (!llvm.vec<16 x ptr>, vector<16xi1>, vector<16xi64>) -> vector<16xi64>
    %339 = llvm.insertvalue %338, %336[14] : !llvm.array<24 x vector<16xi64>> 
    %340 = llvm.getelementptr %293[%264] : (!llvm.ptr, vector<16xi32>) -> !llvm.vec<16 x ptr>, i64
    %341 = llvm.intr.masked.gather %340, %235, %206 {alignment = 8 : i32} : (!llvm.vec<16 x ptr>, vector<16xi1>, vector<16xi64>) -> vector<16xi64>
    %342 = llvm.insertvalue %341, %339[15] : !llvm.array<24 x vector<16xi64>> 
    %343 = llvm.getelementptr %293[%264] : (!llvm.ptr, vector<16xi32>) -> !llvm.vec<16 x ptr>, i64
    %344 = llvm.intr.masked.gather %343, %235, %206 {alignment = 8 : i32} : (!llvm.vec<16 x ptr>, vector<16xi1>, vector<16xi64>) -> vector<16xi64>
    %345 = llvm.insertvalue %344, %342[16] : !llvm.array<24 x vector<16xi64>> 
    %346 = llvm.getelementptr %293[%264] : (!llvm.ptr, vector<16xi32>) -> !llvm.vec<16 x ptr>, i64
    %347 = llvm.intr.masked.gather %346, %235, %206 {alignment = 8 : i32} : (!llvm.vec<16 x ptr>, vector<16xi1>, vector<16xi64>) -> vector<16xi64>
    %348 = llvm.insertvalue %347, %345[17] : !llvm.array<24 x vector<16xi64>> 
    %349 = llvm.getelementptr %293[%264] : (!llvm.ptr, vector<16xi32>) -> !llvm.vec<16 x ptr>, i64
    %350 = llvm.intr.masked.gather %349, %235, %206 {alignment = 8 : i32} : (!llvm.vec<16 x ptr>, vector<16xi1>, vector<16xi64>) -> vector<16xi64>
    %351 = llvm.insertvalue %350, %348[18] : !llvm.array<24 x vector<16xi64>> 
    %352 = llvm.getelementptr %293[%264] : (!llvm.ptr, vector<16xi32>) -> !llvm.vec<16 x ptr>, i64
    %353 = llvm.intr.masked.gather %352, %235, %206 {alignment = 8 : i32} : (!llvm.vec<16 x ptr>, vector<16xi1>, vector<16xi64>) -> vector<16xi64>
    %354 = llvm.insertvalue %353, %351[19] : !llvm.array<24 x vector<16xi64>> 
    %355 = llvm.getelementptr %293[%264] : (!llvm.ptr, vector<16xi32>) -> !llvm.vec<16 x ptr>, i64
    %356 = llvm.intr.masked.gather %355, %235, %206 {alignment = 8 : i32} : (!llvm.vec<16 x ptr>, vector<16xi1>, vector<16xi64>) -> vector<16xi64>
    %357 = llvm.insertvalue %356, %354[20] : !llvm.array<24 x vector<16xi64>> 
    %358 = llvm.getelementptr %293[%264] : (!llvm.ptr, vector<16xi32>) -> !llvm.vec<16 x ptr>, i64
    %359 = llvm.intr.masked.gather %358, %235, %206 {alignment = 8 : i32} : (!llvm.vec<16 x ptr>, vector<16xi1>, vector<16xi64>) -> vector<16xi64>
    %360 = llvm.insertvalue %359, %357[21] : !llvm.array<24 x vector<16xi64>> 
    %361 = llvm.getelementptr %293[%264] : (!llvm.ptr, vector<16xi32>) -> !llvm.vec<16 x ptr>, i64
    %362 = llvm.intr.masked.gather %361, %235, %206 {alignment = 8 : i32} : (!llvm.vec<16 x ptr>, vector<16xi1>, vector<16xi64>) -> vector<16xi64>
    %363 = llvm.insertvalue %362, %360[22] : !llvm.array<24 x vector<16xi64>> 
    %364 = llvm.getelementptr %293[%264] : (!llvm.ptr, vector<16xi32>) -> !llvm.vec<16 x ptr>, i64
    %365 = llvm.intr.masked.gather %364, %235, %206 {alignment = 8 : i32} : (!llvm.vec<16 x ptr>, vector<16xi1>, vector<16xi64>) -> vector<16xi64>
    %366 = llvm.insertvalue %365, %363[23] : !llvm.array<24 x vector<16xi64>> 
    %367 = builtin.unrealized_conversion_cast %366 : !llvm.array<24 x vector<16xi64>> to vector<24x16xi64>
    %368 = llvm.mlir.undef : vector<1xf32>
    %369 = llvm.insertelement %30, %368[%1 : i32] : vector<1xf32>
    %370 = builtin.unrealized_conversion_cast %369 : vector<1xf32> to vector<f32>
    %371 = spirv.LogicalEqual %24, %false : i1
    %372 = arith.extui %16 : vector<16xi1> to vector<16xi8>
    vector.print punctuation <open>
    scf.for %arg3 = %c0 to %c16 step %c1 {
      %435 = vector.extractelement %372[%arg3 : index] : vector<16xi8>
      vector.print %435 : i8 punctuation <no_punctuation>
      %436 = arith.cmpi ult, %arg3, %c15 : index
      scf.if %436 {
        vector.print punctuation <comma>
      }
    }
    vector.print punctuation <close>
    vector.print
    vector.print punctuation <open>
    scf.for %arg3 = %c0 to %c3 step %c1 {
      %435 = vector.extractelement %17[%arg3 : index] : vector<3xi16>
      vector.print %435 : i16 punctuation <no_punctuation>
      %436 = arith.cmpi ult, %arg3, %c2 : index
      scf.if %436 {
        vector.print punctuation <comma>
      }
    }
    vector.print punctuation <close>
    vector.print
    vector.print punctuation <open>
    scf.for %arg3 = %c0 to %c3 step %c1 {
      %435 = vector.extractelement %17[%arg3 : index] : vector<3xi16>
      vector.print %435 : i16 punctuation <no_punctuation>
      %436 = arith.cmpi ult, %arg3, %c2 : index
      scf.if %436 {
        vector.print punctuation <comma>
      }
    }
    vector.print punctuation <close>
    vector.print
    vector.print punctuation <open>
    scf.for %arg3 = %c0 to %c16 step %c1 {
      %435 = vector.extractelement %39[%arg3 : index] : vector<16xf32>
      vector.print %435 : f32 punctuation <no_punctuation>
      %436 = arith.cmpi ult, %arg3, %c15 : index
      scf.if %436 {
        vector.print punctuation <comma>
      }
    }
    vector.print punctuation <close>
    vector.print
    vector.print punctuation <open>
    scf.for %arg3 = %c0 to %c16 step %c1 {
      %435 = vector.extractelement %40[%arg3 : index] : vector<16xf32>
      vector.print %435 : f32 punctuation <no_punctuation>
      %436 = arith.cmpi ult, %arg3, %c15 : index
      scf.if %436 {
        vector.print punctuation <comma>
      }
    }
    vector.print punctuation <close>
    vector.print
    vector.print punctuation <open>
    scf.for %arg3 = %c0 to %c24 step %c1 {
      %435 = vector.extractelement %42[%arg3 : index] : vector<24xf32>
      vector.print %435 : f32 punctuation <no_punctuation>
      %436 = arith.cmpi ult, %arg3, %c23 : index
      scf.if %436 {
        vector.print punctuation <comma>
      }
    }
    vector.print punctuation <close>
    vector.print
    %373 = vector.shape_cast %cst_8 : vector<24x16xf32> to vector<384xf32>
    vector.print punctuation <open>
    scf.for %arg3 = %c0 to %c24 step %c1 {
      vector.print punctuation <open>
      scf.for %arg4 = %c0 to %c16 step %c1 {
        %436 = arith.muli %arg3, %c16 : index
        %437 = arith.addi %arg4, %436 : index
        %438 = vector.extractelement %373[%437 : index] : vector<384xf32>
        vector.print %438 : f32 punctuation <no_punctuation>
        %439 = arith.cmpi ult, %arg4, %c15 : index
        scf.if %439 {
          vector.print punctuation <comma>
        }
      }
      vector.print punctuation <close>
      %435 = arith.cmpi ult, %arg3, %c23 : index
      scf.if %435 {
        vector.print punctuation <comma>
      }
    }
    vector.print punctuation <close>
    vector.print
    %374 = vector.shape_cast %168 : vector<24x16xf32> to vector<384xf32>
    vector.print punctuation <open>
    scf.for %arg3 = %c0 to %c24 step %c1 {
      vector.print punctuation <open>
      scf.for %arg4 = %c0 to %c16 step %c1 {
        %436 = arith.muli %arg3, %c16 : index
        %437 = arith.addi %arg4, %436 : index
        %438 = vector.extractelement %374[%437 : index] : vector<384xf32>
        vector.print %438 : f32 punctuation <no_punctuation>
        %439 = arith.cmpi ult, %arg4, %c15 : index
        scf.if %439 {
          vector.print punctuation <comma>
        }
      }
      vector.print punctuation <close>
      %435 = arith.cmpi ult, %arg3, %c23 : index
      scf.if %435 {
        vector.print punctuation <comma>
      }
    }
    vector.print punctuation <close>
    vector.print
    vector.print punctuation <open>
    scf.for %arg3 = %c0 to %c16 step %c1 {
      %435 = vector.extractelement %173[%arg3 : index] : vector<16xi32>
      vector.print %435 : i32 punctuation <no_punctuation>
      %436 = arith.cmpi ult, %arg3, %c15 : index
      scf.if %436 {
        vector.print punctuation <comma>
      }
    }
    vector.print punctuation <close>
    vector.print
    vector.print punctuation <open>
    scf.for %arg3 = %c0 to %c16 step %c1 {
      %435 = vector.extractelement %cst[%arg3 : index] : vector<16xi8>
      vector.print %435 : i8 punctuation <no_punctuation>
      %436 = arith.cmpi ult, %arg3, %c15 : index
      scf.if %436 {
        vector.print punctuation <comma>
      }
    }
    vector.print punctuation <close>
    vector.print
    %375 = vector.shape_cast %231 : vector<24x16xi64> to vector<384xi64>
    vector.print punctuation <open>
    scf.for %arg3 = %c0 to %c24 step %c1 {
      vector.print punctuation <open>
      scf.for %arg4 = %c0 to %c16 step %c1 {
        %436 = arith.muli %arg3, %c16 : index
        %437 = arith.addi %arg4, %436 : index
        %438 = vector.extractelement %375[%437 : index] : vector<384xi64>
        vector.print %438 : i64 punctuation <no_punctuation>
        %439 = arith.cmpi ult, %arg4, %c15 : index
        scf.if %439 {
          vector.print punctuation <comma>
        }
      }
      vector.print punctuation <close>
      %435 = arith.cmpi ult, %arg3, %c23 : index
      scf.if %435 {
        vector.print punctuation <comma>
      }
    }
    vector.print punctuation <close>
    vector.print
    %376 = arith.extui %260 : vector<24x16xi1> to vector<24x16xi8>
    %377 = vector.shape_cast %376 : vector<24x16xi8> to vector<384xi8>
    vector.print punctuation <open>
    scf.for %arg3 = %c0 to %c24 step %c1 {
      vector.print punctuation <open>
      scf.for %arg4 = %c0 to %c16 step %c1 {
        %436 = arith.muli %arg3, %c16 : index
        %437 = arith.addi %arg4, %436 : index
        %438 = vector.extractelement %377[%437 : index] : vector<384xi8>
        vector.print %438 : i8 punctuation <no_punctuation>
        %439 = arith.cmpi ult, %arg4, %c15 : index
        scf.if %439 {
          vector.print punctuation <comma>
        }
      }
      vector.print punctuation <close>
      %435 = arith.cmpi ult, %arg3, %c23 : index
      scf.if %435 {
        vector.print punctuation <comma>
      }
    }
    vector.print punctuation <close>
    vector.print
    %378 = vector.shape_cast %289 : vector<24x16xi32> to vector<384xi32>
    vector.print punctuation <open>
    scf.for %arg3 = %c0 to %c24 step %c1 {
      vector.print punctuation <open>
      scf.for %arg4 = %c0 to %c16 step %c1 {
        %436 = arith.muli %arg3, %c16 : index
        %437 = arith.addi %arg4, %436 : index
        %438 = vector.extractelement %378[%437 : index] : vector<384xi32>
        vector.print %438 : i32 punctuation <no_punctuation>
        %439 = arith.cmpi ult, %arg4, %c15 : index
        scf.if %439 {
          vector.print punctuation <comma>
        }
      }
      vector.print punctuation <close>
      %435 = arith.cmpi ult, %arg3, %c23 : index
      scf.if %435 {
        vector.print punctuation <comma>
      }
    }
    vector.print punctuation <close>
    vector.print
    %379 = vector.shape_cast %367 : vector<24x16xi64> to vector<384xi64>
    vector.print punctuation <open>
    scf.for %arg3 = %c0 to %c24 step %c1 {
      vector.print punctuation <open>
      scf.for %arg4 = %c0 to %c16 step %c1 {
        %436 = arith.muli %arg3, %c16 : index
        %437 = arith.addi %arg4, %436 : index
        %438 = vector.extractelement %379[%437 : index] : vector<384xi64>
        vector.print %438 : i64 punctuation <no_punctuation>
        %439 = arith.cmpi ult, %arg4, %c15 : index
        scf.if %439 {
          vector.print punctuation <comma>
        }
      }
      vector.print punctuation <close>
      %435 = arith.cmpi ult, %arg3, %c23 : index
      scf.if %435 {
        vector.print punctuation <comma>
      }
    }
    vector.print punctuation <close>
    vector.print
    %380 = vector.shape_cast %370 : vector<f32> to vector<1xf32>
    vector.print punctuation <open>
    scf.for %arg3 = %c0 to %c1 step %c1 {
      %435 = vector.extractelement %380[%arg3 : index] : vector<1xf32>
      vector.print %435 : f32 punctuation <no_punctuation>
      %436 = arith.cmpi ult, %arg3, %c0 : index
      scf.if %436 {
        vector.print punctuation <comma>
      }
    }
    vector.print punctuation <close>
    vector.print
    %381 = arith.extui %arg2 : i1 to i64
    llvm.call @printI64(%381) : (i64) -> ()
    llvm.call @printNewline() : () -> ()
    llvm.call @printI64(%c0_i64) : (i64) -> ()
    llvm.call @printNewline() : () -> ()
    llvm.call @printI64(%c265471212_i64) : (i64) -> ()
    llvm.call @printNewline() : () -> ()
    llvm.call @printI64(%c4623_i64) : (i64) -> ()
    llvm.call @printNewline() : () -> ()
    llvm.call @printI64(%c22394_i64) : (i64) -> ()
    llvm.call @printNewline() : () -> ()
    llvm.call @printI64(%c0_i64) : (i64) -> ()
    llvm.call @printNewline() : () -> ()
    llvm.call @printI64(%c1941353413_i64) : (i64) -> ()
    llvm.call @printNewline() : () -> ()
    llvm.call @printI64(%c-29278_i64) : (i64) -> ()
    llvm.call @printNewline() : () -> ()
    llvm.call @printI64(%c281204932_i64) : (i64) -> ()
    llvm.call @printNewline() : () -> ()
    llvm.call @printF32(%cst_5) : (f32) -> ()
    llvm.call @printNewline() : () -> ()
    %382 = llvm.bitcast %cst_4 : f16 to i16
    llvm.call @printF16(%382) : (i16) -> ()
    llvm.call @printNewline() : () -> ()
    %383 = llvm.bitcast %cst_3 : f16 to i16
    llvm.call @printF16(%383) : (i16) -> ()
    llvm.call @printNewline() : () -> ()
    llvm.call @printI64(%c771421837_i64) : (i64) -> ()
    llvm.call @printNewline() : () -> ()
    llvm.call @printI64(%c445093745_i64) : (i64) -> ()
    llvm.call @printNewline() : () -> ()
    llvm.call @printI64(%c1_i64) : (i64) -> ()
    llvm.call @printNewline() : () -> ()
    llvm.call @printF32(%cst_2) : (f32) -> ()
    llvm.call @printNewline() : () -> ()
    %384 = llvm.bitcast %cst_1 : f16 to i16
    llvm.call @printF16(%384) : (i16) -> ()
    llvm.call @printNewline() : () -> ()
    %385 = arith.extsi %13 : i32 to i64
    llvm.call @printI64(%385) : (i64) -> ()
    llvm.call @printNewline() : () -> ()
    %386 = llvm.bitcast %18 : f16 to i16
    llvm.call @printF16(%386) : (i16) -> ()
    llvm.call @printNewline() : () -> ()
    %387 = llvm.bitcast %19 : f16 to i16
    llvm.call @printF16(%387) : (i16) -> ()
    llvm.call @printNewline() : () -> ()
    %388 = llvm.bitcast %20 : f16 to i16
    llvm.call @printF16(%388) : (i16) -> ()
    llvm.call @printNewline() : () -> ()
    %389 = llvm.bitcast %21 : f16 to i16
    llvm.call @printF16(%389) : (i16) -> ()
    llvm.call @printNewline() : () -> ()
    %390 = llvm.bitcast %22 : f16 to i16
    llvm.call @printF16(%390) : (i16) -> ()
    llvm.call @printNewline() : () -> ()
    %391 = llvm.bitcast %23 : f16 to i16
    llvm.call @printF16(%391) : (i16) -> ()
    llvm.call @printNewline() : () -> ()
    %392 = arith.extui %24 : i1 to i64
    llvm.call @printI64(%392) : (i64) -> ()
    llvm.call @printNewline() : () -> ()
    %393 = llvm.bitcast %25 : f16 to i16
    llvm.call @printF16(%393) : (i16) -> ()
    llvm.call @printNewline() : () -> ()
    %394 = llvm.bitcast %26 : f16 to i16
    llvm.call @printF16(%394) : (i16) -> ()
    llvm.call @printNewline() : () -> ()
    %395 = arith.extui %27 : i1 to i64
    llvm.call @printI64(%395) : (i64) -> ()
    llvm.call @printNewline() : () -> ()
    %396 = llvm.bitcast %28 : f16 to i16
    llvm.call @printF16(%396) : (i16) -> ()
    llvm.call @printNewline() : () -> ()
    %397 = arith.extui %29 : i1 to i64
    llvm.call @printI64(%397) : (i64) -> ()
    llvm.call @printNewline() : () -> ()
    llvm.call @printF32(%30) : (f32) -> ()
    llvm.call @printNewline() : () -> ()
    %398 = llvm.bitcast %31 : f16 to i16
    llvm.call @printF16(%398) : (i16) -> ()
    llvm.call @printNewline() : () -> ()
    %399 = llvm.bitcast %32 : f16 to i16
    llvm.call @printF16(%399) : (i16) -> ()
    llvm.call @printNewline() : () -> ()
    %400 = arith.extui %33 : i1 to i64
    llvm.call @printI64(%400) : (i64) -> ()
    llvm.call @printNewline() : () -> ()
    %401 = arith.extsi %34 : i32 to i64
    llvm.call @printI64(%401) : (i64) -> ()
    llvm.call @printNewline() : () -> ()
    llvm.call @printF32(%35) : (f32) -> ()
    llvm.call @printNewline() : () -> ()
    %402 = llvm.bitcast %36 : f16 to i16
    llvm.call @printF16(%402) : (i16) -> ()
    llvm.call @printNewline() : () -> ()
    %403 = arith.extsi %41 : i32 to i64
    llvm.call @printI64(%403) : (i64) -> ()
    llvm.call @printNewline() : () -> ()
    %404 = llvm.bitcast %43 : f16 to i16
    llvm.call @printF16(%404) : (i16) -> ()
    llvm.call @printNewline() : () -> ()
    %405 = arith.extui %44 : i1 to i64
    llvm.call @printI64(%405) : (i64) -> ()
    llvm.call @printNewline() : () -> ()
    %406 = llvm.bitcast %45 : f16 to i16
    llvm.call @printF16(%406) : (i16) -> ()
    llvm.call @printNewline() : () -> ()
    %407 = llvm.bitcast %46 : f16 to i16
    llvm.call @printF16(%407) : (i16) -> ()
    llvm.call @printNewline() : () -> ()
    %408 = llvm.bitcast %169 : f16 to i16
    llvm.call @printF16(%408) : (i16) -> ()
    llvm.call @printNewline() : () -> ()
    %409 = llvm.bitcast %170 : f16 to i16
    llvm.call @printF16(%409) : (i16) -> ()
    llvm.call @printNewline() : () -> ()
    %410 = arith.extsi %171 : i32 to i64
    llvm.call @printI64(%410) : (i64) -> ()
    llvm.call @printNewline() : () -> ()
    %411 = llvm.bitcast %172 : f16 to i16
    llvm.call @printF16(%411) : (i16) -> ()
    llvm.call @printNewline() : () -> ()
    %412 = arith.extui %175 : i1 to i64
    llvm.call @printI64(%412) : (i64) -> ()
    llvm.call @printNewline() : () -> ()
    %413 = llvm.bitcast %176 : f16 to i16
    llvm.call @printF16(%413) : (i16) -> ()
    llvm.call @printNewline() : () -> ()
    %414 = llvm.bitcast %177 : f16 to i16
    llvm.call @printF16(%414) : (i16) -> ()
    llvm.call @printNewline() : () -> ()
    %415 = llvm.bitcast %178 : f16 to i16
    llvm.call @printF16(%415) : (i16) -> ()
    llvm.call @printNewline() : () -> ()
    %416 = arith.extui %179 : i1 to i64
    llvm.call @printI64(%416) : (i64) -> ()
    llvm.call @printNewline() : () -> ()
    %417 = llvm.bitcast %180 : f16 to i16
    llvm.call @printF16(%417) : (i16) -> ()
    llvm.call @printNewline() : () -> ()
    llvm.call @printI64(%181) : (i64) -> ()
    llvm.call @printNewline() : () -> ()
    %418 = llvm.bitcast %182 : f16 to i16
    llvm.call @printF16(%418) : (i16) -> ()
    llvm.call @printNewline() : () -> ()
    %419 = llvm.bitcast %183 : f16 to i16
    llvm.call @printF16(%419) : (i16) -> ()
    llvm.call @printNewline() : () -> ()
    %420 = llvm.bitcast %185 : f16 to i16
    llvm.call @printF16(%420) : (i16) -> ()
    llvm.call @printNewline() : () -> ()
    %421 = arith.extui %186 : i1 to i64
    llvm.call @printI64(%421) : (i64) -> ()
    llvm.call @printNewline() : () -> ()
    %422 = llvm.bitcast %187 : f16 to i16
    llvm.call @printF16(%422) : (i16) -> ()
    llvm.call @printNewline() : () -> ()
    %423 = llvm.bitcast %188 : f16 to i16
    llvm.call @printF16(%423) : (i16) -> ()
    llvm.call @printNewline() : () -> ()
    %424 = arith.extsi %189 : i32 to i64
    llvm.call @printI64(%424) : (i64) -> ()
    llvm.call @printNewline() : () -> ()
    %425 = llvm.bitcast %190 : f16 to i16
    llvm.call @printF16(%425) : (i16) -> ()
    llvm.call @printNewline() : () -> ()
    %426 = arith.extsi %191 : i16 to i64
    llvm.call @printI64(%426) : (i64) -> ()
    llvm.call @printNewline() : () -> ()
    %427 = llvm.bitcast %192 : f16 to i16
    llvm.call @printF16(%427) : (i16) -> ()
    llvm.call @printNewline() : () -> ()
    %428 = llvm.bitcast %193 : f16 to i16
    llvm.call @printF16(%428) : (i16) -> ()
    llvm.call @printNewline() : () -> ()
    %429 = llvm.bitcast %194 : f16 to i16
    llvm.call @printF16(%429) : (i16) -> ()
    llvm.call @printNewline() : () -> ()
    %430 = arith.extsi %195 : i16 to i64
    llvm.call @printI64(%430) : (i64) -> ()
    llvm.call @printNewline() : () -> ()
    %431 = llvm.bitcast %196 : f16 to i16
    llvm.call @printF16(%431) : (i16) -> ()
    llvm.call @printNewline() : () -> ()
    %432 = arith.extui %197 : i1 to i64
    llvm.call @printI64(%432) : (i64) -> ()
    llvm.call @printNewline() : () -> ()
    %433 = arith.extui %201 : i1 to i64
    llvm.call @printI64(%433) : (i64) -> ()
    llvm.call @printNewline() : () -> ()
    %434 = arith.extui %371 : i1 to i64
    llvm.call @printI64(%434) : (i64) -> ()
    llvm.call @printNewline() : () -> ()
    return
  }
  func.func @func2() {
    %cst = arith.constant dense<22394> : vector<i16>
    %cst_0 = arith.constant dense<4623> : vector<3xi16>
    %cst_1 = arith.constant dense<771421837> : vector<2xi32>
    %c29 = arith.constant 29 : index
    %false = arith.constant false
    %c265471212_i64 = arith.constant 265471212 : i64
    %c4623_i16 = arith.constant 4623 : i16
    %c-29278_i16 = arith.constant -29278 : i16
    %c281204932_i64 = arith.constant 281204932 : i64
    %cst_2 = arith.constant 0x4D08837C : f32
    %cst_3 = arith.constant 3.350400e+04 : f16
    %cst_4 = arith.constant 5.033600e+04 : f16
    %c771421837_i32 = arith.constant 771421837 : i32
    %c445093745_i32 = arith.constant 445093745 : i32
    %true = arith.constant true
    %cst_5 = arith.constant 0x4E228E1D : f32
    %cst_6 = arith.constant 1.731200e+04 : f16
    %c5 = arith.constant 5 : index
    %c6 = arith.constant 6 : index
    %c7 = arith.constant 7 : index
    %c9 = arith.constant 9 : index
    %c10 = arith.constant 10 : index
    %c11 = arith.constant 11 : index
    %c12 = arith.constant 12 : index
    %c13 = arith.constant 13 : index
    %c14 = arith.constant 14 : index
    %c17 = arith.constant 17 : index
    %c22 = arith.constant 22 : index
    %c23 = arith.constant 23 : index
    %c25 = arith.constant 25 : index
    %c26 = arith.constant 26 : index
    %c27 = arith.constant 27 : index
    %c30 = arith.constant 30 : index
    %0 = llvm.mlir.constant(0 : i32) : i32
    %1 = llvm.mlir.constant(0 : index) : i64
    %c1_i64 = arith.constant 1 : i64
    %c445093745_i64 = arith.constant 445093745 : i64
    %c771421837_i64 = arith.constant 771421837 : i64
    %c-29278_i64 = arith.constant -29278 : i64
    %c1941353413_i64 = arith.constant 1941353413 : i64
    %c22394_i64 = arith.constant 22394 : i64
    %c4623_i64 = arith.constant 4623 : i64
    %c0_i64 = arith.constant 0 : i64
    %cst_7 = arith.constant dense<4623> : vector<3x1xi16>
    %c15 = arith.constant 15 : index
    %c1 = arith.constant 1 : index
    %c3 = arith.constant 3 : index
    %c16 = arith.constant 16 : index
    %c2 = arith.constant 2 : index
    %c0 = arith.constant 0 : index
    %c24 = arith.constant 24 : index
    %alloca = memref.alloca() : memref<vector<24x1xf16>>
    %alloca_8 = memref.alloca() : memref<vector<3x1xi16>>
    %2 = builtin.unrealized_conversion_cast %cst : vector<i16> to vector<1xi16>
    %3 = tensor.empty(%c23, %c25) : tensor<?x?xi16>
    %4 = tensor.empty(%c5, %c15) : tensor<?x?xf16>
    %5 = tensor.empty(%c17) : tensor<?x3xi1>
    %alloc = memref.alloc() : memref<16xf32>
    %alloc_9 = memref.alloc(%c12, %c26) : memref<?x?xi16>
    %alloc_10 = memref.alloc(%c10) : memref<?xi16>
    %alloc_11 = memref.alloc(%c27) : memref<?xf32>
    %alloc_12 = memref.alloc(%c22, %c11) : memref<?x?xf32>
    %alloc_13 = memref.alloc() : memref<16x3xi16>
    %alloc_14 = memref.alloc() : memref<16x3xf16>
    %alloc_15 = memref.alloc() : memref<16xf16>
    %alloc_16 = memref.alloc(%c9) : memref<?xi32>
    %alloc_17 = memref.alloc(%c9) : memref<?xi16>
    %alloc_18 = memref.alloc() : memref<24x16xi16>
    %6 = tensor.empty() : tensor<48xi64>
    %7 = spirv.GL.FMix %cst_3 : f16, %cst_4 : f16, %cst_3 : f16 -> f16
    %8 = spirv.FOrdEqual %7, %cst_3 : f16
    %9 = spirv.IsInf %cst_4 : f16
    %10 = spirv.GL.Cosh %cst_6 : f16
    %11 = spirv.CL.sin %10 : f16
    %12 = scf.while (%arg0 = %6) : (tensor<48xi64>) -> tensor<48xi64> {
      scf.condition(%false) %arg0 : tensor<48xi64>
    } do {
    ^bb0(%arg0: tensor<48xi64>):
      %106 = memref.realloc %alloc_17 : memref<?xi16> to memref<24xi16>
      %alloc_21 = memref.alloc(%c14, %c23) : memref<?x?xf16>
      memref.tensor_store %4, %alloc_21 : memref<?x?xf16>
      memref.alloca_scope  {
        memref.assume_alignment %alloc_12, 16 : memref<?x?xf32>
        %alloc_22 = memref.alloc(%c16) : memref<?x3xi1>
        memref.tensor_store %5, %alloc_22 : memref<?x3xi1>
      }
      vector.print punctuation <open>
      scf.for %arg1 = %c0 to %c2 step %c1 {
        %107 = vector.extractelement %cst_1[%arg1 : index] : vector<2xi32>
        vector.print %107 : i32 punctuation <no_punctuation>
        %108 = arith.cmpi ult, %arg1, %c1 : index
        scf.if %108 {
          vector.print punctuation <comma>
        }
      }
      vector.print punctuation <close>
      vector.print
      memref.assume_alignment %alloc_15, 4 : memref<16xf16>
      scf.yield %arg0 : tensor<48xi64>
    }
    %13 = spirv.CL.fabs %cst_3 : f16
    %14 = spirv.GL.Cosh %cst_2 : f32
    %15 = spirv.CL.rsqrt %13 : f16
    %16 = spirv.CL.cos %14 : f32
    %17 = spirv.GL.Cos %13 : f16
    vector.warp_execute_on_lane_0(%c0)[32] {
      scf.execute_region {
        %106 = memref.realloc %alloc_11 : memref<?xf32> to memref<14xf32>
        %107 = llvm.mlir.undef : vector<24xf16>
        %108 = llvm.insertelement %11, %107[%0 : i32] : vector<24xf16>
        %109 = llvm.shufflevector %108, %107 [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] : vector<24xf16> 
        %110 = vector.broadcast %109 : vector<24xf16> to vector<1x24xf16>
        %111 = vector.transpose %110, [1, 0] : vector<1x24xf16> to vector<24x1xf16>
        memref.store %111, %alloca[] : memref<vector<24x1xf16>>
        %112 = vector.type_cast %alloca : memref<vector<24x1xf16>> to memref<24xvector<1xf16>>
        scf.for %arg0 = %c0 to %c24 step %c1 {
          %113 = affine.apply #map(%arg0)
          %114 = memref.load %112[%arg0] : memref<24xvector<1xf16>>
          vector.transfer_write %114, %alloc_14[%113, %c9] {in_bounds = [true]} : vector<1xf16>, memref<16x3xf16>
        }
        scf.yield
      }
    }
    %18 = affine.if #set1() -> memref<24x16xi64> {
      memref.alloca_scope  {
        memref.copy %alloc_15, %alloc_15 : memref<16xf16> to memref<16xf16>
      }
      %alloc_21 = memref.alloc() : memref<24x16xi64>
      affine.yield %alloc_21 : memref<24x16xi64>
    } else {
      %alloc_21 = memref.alloc() : memref<24x16xi64>
      affine.yield %alloc_21 : memref<24x16xi64>
    }
    %19 = spirv.FUnordLessThan %cst_4, %13 : f16
    %20 = llvm.mlir.undef : vector<2xi1>
    %21 = llvm.insertelement %19, %20[%0 : i32] : vector<2xi1>
    %22 = llvm.shufflevector %21, %20 [0, 0] : vector<2xi1> 
    memref.store %cst_7, %alloca_8[] : memref<vector<3x1xi16>>
    %23 = vector.type_cast %alloca_8 : memref<vector<3x1xi16>> to memref<3xvector<1xi16>>
    scf.for %arg0 = %c0 to %c3 step %c1 {
      %106 = affine.apply #map1(%arg0)
      %107 = memref.load %23[%arg0] : memref<3xvector<1xi16>>
      vector.transfer_write %107, %alloc_13[%106, %c29] {in_bounds = [true]} : vector<1xi16>, memref<16x3xi16>
    }
    %24 = spirv.CL.rsqrt %cst_2 : f32
    %25 = spirv.FUnordLessThan %7, %10 : f16
    %26 = spirv.FUnordEqual %16, %14 : f32
    %27 = spirv.GL.UMax %c-29278_i16, %c-29278_i16 : i16
    %28 = spirv.FUnordGreaterThan %7, %cst_6 : f16
    %29 = llvm.extractelement %2[%1 : i64] : vector<1xi16>
    memref.store %29, %alloc_18[%c30, %c10] : memref<24x16xi16>
    %30 = spirv.CL.rsqrt %cst_6 : f16
    %31 = spirv.CL.ceil %16 : f32
    %32 = spirv.UGreaterThanEqual %c4623_i16, %27 : i16
    %33 = spirv.UGreaterThanEqual %c771421837_i32, %c771421837_i32 : i32
    %alloc_19 = memref.alloc() : memref<i32>
    %34 = scf.while (%arg0 = %26) : (i1) -> i1 {
      scf.condition(%true) %32 : i1
    } do {
    ^bb0(%arg0: i1):
      memref.copy %alloc_16, %alloc_16 : memref<?xi32> to memref<?xi32>
      memref.store %c4623_i16, %alloc_13[%c7, %c1] : memref<16x3xi16>
      memref.copy %alloc_12, %alloc_12 : memref<?x?xf32> to memref<?x?xf32>
      scf.yield %19 : i1
    }
    %35 = scf.parallel (%arg0, %arg1) = (%c10, %c9) to (%c29, %c14) step (%c13, %c6) init (%cst_2) -> f32 {
      vector.print punctuation <open>
      scf.for %arg2 = %c0 to %c3 step %c1 {
        %106 = vector.extractelement %cst_0[%arg2 : index] : vector<3xi16>
        vector.print %106 : i16 punctuation <no_punctuation>
        %107 = arith.cmpi ult, %arg2, %c2 : index
        scf.if %107 {
          vector.print punctuation <comma>
        }
      }
      vector.print punctuation <close>
      vector.print
      scf.reduce(%cst_2)  : f32 {
      ^bb0(%arg2: f32, %arg3: f32):
        scf.reduce.return %cst_5 : f32
      }
      scf.yield
    }
    %36 = spirv.GL.Atan %7 : f16
    %37 = spirv.CL.rsqrt %30 : f16
    linalg.transpose ins(%3 : tensor<?x?xi16>) outs(%alloc_9 : memref<?x?xi16>) permutation = [1, 0] 
    %38 = spirv.FUnordLessThanEqual %14, %16 : f32
    memref.copy %alloc_12, %alloc_12 : memref<?x?xf32> to memref<?x?xf32>
    %39 = spirv.CL.ceil %24 : f32
    %40 = spirv.GL.SAbs %c265471212_i64 : i64
    %41 = spirv.ULessThan %40, %c265471212_i64 : i64
    scf.parallel (%arg0) = (%c2) to (%c10) step (%c11) {
      %106 = memref.realloc %alloc_10 : memref<?xi16> to memref<16xi16>
      scf.yield
    }
    %42 = spirv.GL.FSign %39 : f32
    %43 = spirv.GL.FMix %10 : f16, %15 : f16, %7 : f16 -> f16
    %44 = spirv.GL.Log %cst_5 : f32
    %45 = spirv.GL.Atan %cst_4 : f16
    %46 = spirv.GL.FMax %7, %43 : f16
    %47 = spirv.CL.tanh %46 : f16
    vector.print punctuation <open>
    scf.for %arg0 = %c0 to %c3 step %c1 {
      %106 = vector.extractelement %cst_0[%arg0 : index] : vector<3xi16>
      vector.print %106 : i16 punctuation <no_punctuation>
      %107 = arith.cmpi ult, %arg0, %c2 : index
      scf.if %107 {
        vector.print punctuation <comma>
      }
    }
    vector.print punctuation <close>
    vector.print
    %48 = spirv.GL.Exp %46 : f16
    %49 = spirv.FUnordLessThan %7, %15 : f16
    %50 = spirv.CL.round %10 : f16
    %51 = spirv.CL.u_min %c-29278_i16, %c-29278_i16 : i16
    %52 = spirv.CL.u_max %c265471212_i64, %c281204932_i64 : i64
    memref.store %c445093745_i32, %alloc_19[] : memref<i32>
    %53 = spirv.Unordered %16, %cst_2 : f32
    %54 = spirv.CL.tanh %44 : f32
    %alloc_20 = memref.alloc() : memref<f16>
    affine.vector_store %cst_1, %alloc_19[] : memref<i32>, vector<2xi32>
    %55 = spirv.GL.Log %31 : f32
    %56 = spirv.IsNan %44 : f32
    %57 = scf.while (%arg0 = %cst) : (vector<i16>) -> vector<i16> {
      scf.condition(%56) %cst : vector<i16>
    } do {
    ^bb0(%arg0: vector<i16>):
      %106 = memref.atomic_rmw assign %31, %alloc[%c1] : (f32, memref<16xf32>) -> f32
      memref.copy %alloc_20, %alloc_20 : memref<f16> to memref<f16>
      scf.yield %cst : vector<i16>
    }
    %58 = spirv.GL.UClamp %40, %40, %40 : i64
    %59 = spirv.FOrdLessThanEqual %55, %14 : f32
    %60 = spirv.GL.Asin %36 : f16
    %61 = spirv.GL.Sqrt %cst_6 : f16
    %62 = llvm.mlir.undef : vector<16xf32>
    %63 = llvm.insertelement %42, %62[%0 : i32] : vector<16xf32>
    %64 = llvm.shufflevector %63, %62 [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] : vector<16xf32> 
    %65 = llvm.intr.fmuladd(%64, %64, %64)  : (vector<16xf32>, vector<16xf32>, vector<16xf32>) -> vector<16xf32>
    %66 = spirv.LogicalOr %33, %56 : i1
    vector.print punctuation <open>
    scf.for %arg0 = %c0 to %c2 step %c1 {
      %106 = vector.extractelement %cst_1[%arg0 : index] : vector<2xi32>
      vector.print %106 : i32 punctuation <no_punctuation>
      %107 = arith.cmpi ult, %arg0, %c1 : index
      scf.if %107 {
        vector.print punctuation <comma>
      }
    }
    vector.print punctuation <close>
    vector.print
    %67 = arith.extui %22 : vector<2xi1> to vector<2xi8>
    vector.print punctuation <open>
    scf.for %arg0 = %c0 to %c2 step %c1 {
      %106 = vector.extractelement %67[%arg0 : index] : vector<2xi8>
      vector.print %106 : i8 punctuation <no_punctuation>
      %107 = arith.cmpi ult, %arg0, %c1 : index
      scf.if %107 {
        vector.print punctuation <comma>
      }
    }
    vector.print punctuation <close>
    vector.print
    vector.print punctuation <open>
    scf.for %arg0 = %c0 to %c3 step %c1 {
      %106 = vector.extractelement %cst_0[%arg0 : index] : vector<3xi16>
      vector.print %106 : i16 punctuation <no_punctuation>
      %107 = arith.cmpi ult, %arg0, %c2 : index
      scf.if %107 {
        vector.print punctuation <comma>
      }
    }
    vector.print punctuation <close>
    vector.print
    %68 = vector.shape_cast %cst : vector<i16> to vector<1xi16>
    vector.print punctuation <open>
    scf.for %arg0 = %c0 to %c1 step %c1 {
      %106 = vector.extractelement %68[%arg0 : index] : vector<1xi16>
      vector.print %106 : i16 punctuation <no_punctuation>
      %107 = arith.cmpi ult, %arg0, %c0 : index
      scf.if %107 {
        vector.print punctuation <comma>
      }
    }
    vector.print punctuation <close>
    vector.print
    vector.print punctuation <open>
    scf.for %arg0 = %c0 to %c2 step %c1 {
      %106 = vector.extractelement %cst_1[%arg0 : index] : vector<2xi32>
      vector.print %106 : i32 punctuation <no_punctuation>
      %107 = arith.cmpi ult, %arg0, %c1 : index
      scf.if %107 {
        vector.print punctuation <comma>
      }
    }
    vector.print punctuation <close>
    vector.print
    vector.print punctuation <open>
    scf.for %arg0 = %c0 to %c16 step %c1 {
      %106 = vector.extractelement %64[%arg0 : index] : vector<16xf32>
      vector.print %106 : f32 punctuation <no_punctuation>
      %107 = arith.cmpi ult, %arg0, %c15 : index
      scf.if %107 {
        vector.print punctuation <comma>
      }
    }
    vector.print punctuation <close>
    vector.print
    vector.print punctuation <open>
    scf.for %arg0 = %c0 to %c16 step %c1 {
      %106 = vector.extractelement %65[%arg0 : index] : vector<16xf32>
      vector.print %106 : f32 punctuation <no_punctuation>
      %107 = arith.cmpi ult, %arg0, %c15 : index
      scf.if %107 {
        vector.print punctuation <comma>
      }
    }
    vector.print punctuation <close>
    vector.print
    llvm.call @printI64(%c0_i64) : (i64) -> ()
    llvm.call @printNewline() : () -> ()
    llvm.call @printI64(%c265471212_i64) : (i64) -> ()
    llvm.call @printNewline() : () -> ()
    llvm.call @printI64(%c4623_i64) : (i64) -> ()
    llvm.call @printNewline() : () -> ()
    llvm.call @printI64(%c22394_i64) : (i64) -> ()
    llvm.call @printNewline() : () -> ()
    llvm.call @printI64(%c0_i64) : (i64) -> ()
    llvm.call @printNewline() : () -> ()
    llvm.call @printI64(%c1941353413_i64) : (i64) -> ()
    llvm.call @printNewline() : () -> ()
    llvm.call @printI64(%c-29278_i64) : (i64) -> ()
    llvm.call @printNewline() : () -> ()
    llvm.call @printI64(%c281204932_i64) : (i64) -> ()
    llvm.call @printNewline() : () -> ()
    llvm.call @printF32(%cst_2) : (f32) -> ()
    llvm.call @printNewline() : () -> ()
    %69 = llvm.bitcast %cst_3 : f16 to i16
    llvm.call @printF16(%69) : (i16) -> ()
    llvm.call @printNewline() : () -> ()
    %70 = llvm.bitcast %cst_4 : f16 to i16
    llvm.call @printF16(%70) : (i16) -> ()
    llvm.call @printNewline() : () -> ()
    llvm.call @printI64(%c771421837_i64) : (i64) -> ()
    llvm.call @printNewline() : () -> ()
    llvm.call @printI64(%c445093745_i64) : (i64) -> ()
    llvm.call @printNewline() : () -> ()
    llvm.call @printI64(%c1_i64) : (i64) -> ()
    llvm.call @printNewline() : () -> ()
    llvm.call @printF32(%cst_5) : (f32) -> ()
    llvm.call @printNewline() : () -> ()
    %71 = llvm.bitcast %cst_6 : f16 to i16
    llvm.call @printF16(%71) : (i16) -> ()
    llvm.call @printNewline() : () -> ()
    %72 = llvm.bitcast %7 : f16 to i16
    llvm.call @printF16(%72) : (i16) -> ()
    llvm.call @printNewline() : () -> ()
    %73 = arith.extui %8 : i1 to i64
    llvm.call @printI64(%73) : (i64) -> ()
    llvm.call @printNewline() : () -> ()
    %74 = arith.extui %9 : i1 to i64
    llvm.call @printI64(%74) : (i64) -> ()
    llvm.call @printNewline() : () -> ()
    %75 = llvm.bitcast %10 : f16 to i16
    llvm.call @printF16(%75) : (i16) -> ()
    llvm.call @printNewline() : () -> ()
    %76 = llvm.bitcast %11 : f16 to i16
    llvm.call @printF16(%76) : (i16) -> ()
    llvm.call @printNewline() : () -> ()
    %77 = llvm.bitcast %13 : f16 to i16
    llvm.call @printF16(%77) : (i16) -> ()
    llvm.call @printNewline() : () -> ()
    llvm.call @printF32(%14) : (f32) -> ()
    llvm.call @printNewline() : () -> ()
    %78 = llvm.bitcast %15 : f16 to i16
    llvm.call @printF16(%78) : (i16) -> ()
    llvm.call @printNewline() : () -> ()
    llvm.call @printF32(%16) : (f32) -> ()
    llvm.call @printNewline() : () -> ()
    %79 = llvm.bitcast %17 : f16 to i16
    llvm.call @printF16(%79) : (i16) -> ()
    llvm.call @printNewline() : () -> ()
    %80 = arith.extui %19 : i1 to i64
    llvm.call @printI64(%80) : (i64) -> ()
    llvm.call @printNewline() : () -> ()
    llvm.call @printF32(%24) : (f32) -> ()
    llvm.call @printNewline() : () -> ()
    %81 = arith.extui %25 : i1 to i64
    llvm.call @printI64(%81) : (i64) -> ()
    llvm.call @printNewline() : () -> ()
    %82 = arith.extui %26 : i1 to i64
    llvm.call @printI64(%82) : (i64) -> ()
    llvm.call @printNewline() : () -> ()
    %83 = arith.extsi %27 : i16 to i64
    llvm.call @printI64(%83) : (i64) -> ()
    llvm.call @printNewline() : () -> ()
    %84 = arith.extui %28 : i1 to i64
    llvm.call @printI64(%84) : (i64) -> ()
    llvm.call @printNewline() : () -> ()
    %85 = llvm.bitcast %30 : f16 to i16
    llvm.call @printF16(%85) : (i16) -> ()
    llvm.call @printNewline() : () -> ()
    llvm.call @printF32(%31) : (f32) -> ()
    llvm.call @printNewline() : () -> ()
    %86 = arith.extui %32 : i1 to i64
    llvm.call @printI64(%86) : (i64) -> ()
    llvm.call @printNewline() : () -> ()
    %87 = arith.extui %33 : i1 to i64
    llvm.call @printI64(%87) : (i64) -> ()
    llvm.call @printNewline() : () -> ()
    %88 = llvm.bitcast %36 : f16 to i16
    llvm.call @printF16(%88) : (i16) -> ()
    llvm.call @printNewline() : () -> ()
    %89 = llvm.bitcast %37 : f16 to i16
    llvm.call @printF16(%89) : (i16) -> ()
    llvm.call @printNewline() : () -> ()
    %90 = arith.extui %38 : i1 to i64
    llvm.call @printI64(%90) : (i64) -> ()
    llvm.call @printNewline() : () -> ()
    llvm.call @printF32(%39) : (f32) -> ()
    llvm.call @printNewline() : () -> ()
    llvm.call @printI64(%40) : (i64) -> ()
    llvm.call @printNewline() : () -> ()
    %91 = arith.extui %41 : i1 to i64
    llvm.call @printI64(%91) : (i64) -> ()
    llvm.call @printNewline() : () -> ()
    llvm.call @printF32(%42) : (f32) -> ()
    llvm.call @printNewline() : () -> ()
    %92 = llvm.bitcast %43 : f16 to i16
    llvm.call @printF16(%92) : (i16) -> ()
    llvm.call @printNewline() : () -> ()
    llvm.call @printF32(%44) : (f32) -> ()
    llvm.call @printNewline() : () -> ()
    %93 = llvm.bitcast %45 : f16 to i16
    llvm.call @printF16(%93) : (i16) -> ()
    llvm.call @printNewline() : () -> ()
    %94 = llvm.bitcast %46 : f16 to i16
    llvm.call @printF16(%94) : (i16) -> ()
    llvm.call @printNewline() : () -> ()
    %95 = llvm.bitcast %47 : f16 to i16
    llvm.call @printF16(%95) : (i16) -> ()
    llvm.call @printNewline() : () -> ()
    %96 = llvm.bitcast %48 : f16 to i16
    llvm.call @printF16(%96) : (i16) -> ()
    llvm.call @printNewline() : () -> ()
    %97 = arith.extui %49 : i1 to i64
    llvm.call @printI64(%97) : (i64) -> ()
    llvm.call @printNewline() : () -> ()
    %98 = llvm.bitcast %50 : f16 to i16
    llvm.call @printF16(%98) : (i16) -> ()
    llvm.call @printNewline() : () -> ()
    %99 = arith.extsi %51 : i16 to i64
    llvm.call @printI64(%99) : (i64) -> ()
    llvm.call @printNewline() : () -> ()
    llvm.call @printI64(%52) : (i64) -> ()
    llvm.call @printNewline() : () -> ()
    %100 = arith.extui %53 : i1 to i64
    llvm.call @printI64(%100) : (i64) -> ()
    llvm.call @printNewline() : () -> ()
    llvm.call @printF32(%54) : (f32) -> ()
    llvm.call @printNewline() : () -> ()
    llvm.call @printF32(%55) : (f32) -> ()
    llvm.call @printNewline() : () -> ()
    %101 = arith.extui %56 : i1 to i64
    llvm.call @printI64(%101) : (i64) -> ()
    llvm.call @printNewline() : () -> ()
    llvm.call @printI64(%58) : (i64) -> ()
    llvm.call @printNewline() : () -> ()
    %102 = arith.extui %59 : i1 to i64
    llvm.call @printI64(%102) : (i64) -> ()
    llvm.call @printNewline() : () -> ()
    llvm.call @printI64(%c0_i64) : (i64) -> ()
    llvm.call @printNewline() : () -> ()
    %103 = llvm.bitcast %60 : f16 to i16
    llvm.call @printF16(%103) : (i16) -> ()
    llvm.call @printNewline() : () -> ()
    %104 = llvm.bitcast %61 : f16 to i16
    llvm.call @printF16(%104) : (i16) -> ()
    llvm.call @printNewline() : () -> ()
    %105 = arith.extui %66 : i1 to i64
    llvm.call @printI64(%105) : (i64) -> ()
    llvm.call @printNewline() : () -> ()
    return
  }
}


// -----// IR Dump After {anonymous}::TestConstantFold (test-constant-fold) //----- //
#map = affine_map<(d0) -> (d0 + 30)>
#map1 = affine_map<(d0) -> (d0 + 16)>
#set = affine_set<() : (80610 >= 0, 1340 >= 0, 81930 >= 0)>
#set1 = affine_set<() : (24 >= 0, 30 >= 0)>
module {
  llvm.func @printF16(i16)
  llvm.func @printF32(f32)
  llvm.func @printNewline()
  llvm.func @printI64(i64)
  func.func @func1(%arg0: vector<16xi32>, %arg1: memref<?xf32>, %arg2: i1) {
    %c0 = arith.constant 0 : index
    %c16 = arith.constant 16 : index
    %c1 = arith.constant 1 : index
    %c15 = arith.constant 15 : index
    %c3 = arith.constant 3 : index
    %c2 = arith.constant 2 : index
    %c24 = arith.constant 24 : index
    %c23 = arith.constant 23 : index
    %cst = arith.constant dense<[1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]> : vector<16xi8>
    %c0_i64 = arith.constant 0 : i64
    %c4623_i64 = arith.constant 4623 : i64
    %c22394_i64 = arith.constant 22394 : i64
    %c1941353413_i64 = arith.constant 1941353413 : i64
    %c-29278_i64 = arith.constant -29278 : i64
    %c771421837_i64 = arith.constant 771421837 : i64
    %c445093745_i64 = arith.constant 445093745 : i64
    %c1_i64 = arith.constant 1 : i64
    %cst_0 = arith.constant dense<0.000000e+00> : vector<24x16xf32>
    %0 = llvm.mlir.constant(0 : i32) : i32
    %c30 = arith.constant 30 : index
    %c29 = arith.constant 29 : index
    %c26 = arith.constant 26 : index
    %c25 = arith.constant 25 : index
    %c22 = arith.constant 22 : index
    %c21 = arith.constant 21 : index
    %c17 = arith.constant 17 : index
    %c13 = arith.constant 13 : index
    %c12 = arith.constant 12 : index
    %c10 = arith.constant 10 : index
    %c9 = arith.constant 9 : index
    %c7 = arith.constant 7 : index
    %c6 = arith.constant 6 : index
    %c5 = arith.constant 5 : index
    %c4 = arith.constant 4 : index
    %cst_1 = arith.constant 1.731200e+04 : f16
    %cst_2 = arith.constant 0x4E228E1D : f32
    %c445093745_i32 = arith.constant 445093745 : i32
    %c771421837_i32 = arith.constant 771421837 : i32
    %cst_3 = arith.constant 5.033600e+04 : f16
    %cst_4 = arith.constant 3.350400e+04 : f16
    %cst_5 = arith.constant 0x4D08837C : f32
    %c281204932_i64 = arith.constant 281204932 : i64
    %c-29278_i16 = arith.constant -29278 : i16
    %c1941353413_i32 = arith.constant 1941353413 : i32
    %c22394_i16 = arith.constant 22394 : i16
    %c4623_i16 = arith.constant 4623 : i16
    %c265471212_i64 = arith.constant 265471212 : i64
    %false = arith.constant false
    %cst_6 = arith.constant dense<8> : vector<16xindex>
    %idx432 = index.constant 432
    %cst_7 = arith.constant dense<[true, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false]> : vector<16xi1>
    %cst_8 = arith.constant dense<0x4D08837C> : vector<24x16xf32>
    %1 = llvm.mlir.constant(3 : index) : i64
    %2 = builtin.unrealized_conversion_cast %cst_8 : vector<24x16xf32> to !llvm.array<24 x vector<16xf32>>
    %3 = builtin.unrealized_conversion_cast %cst_6 : vector<16xindex> to vector<16xi64>
    %4 = builtin.unrealized_conversion_cast %c0 : index to i64
    %5 = builtin.unrealized_conversion_cast %c5 : index to i64
    %6 = builtin.unrealized_conversion_cast %c7 : index to i64
    %7 = builtin.unrealized_conversion_cast %c26 : index to i64
    %8 = tensor.empty(%c17) : tensor<?x3xi1>
    %9 = tensor.empty() : tensor<16xi64>
    %10 = tensor.empty() : tensor<16xi1>
    %alloc = memref.alloc(%c24) : memref<?xf16>
    %alloc_9 = memref.alloc() : memref<16xf32>
    %11 = builtin.unrealized_conversion_cast %alloc_9 : memref<16xf32> to !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>
    %alloc_10 = memref.alloc(%c12, %c26) : memref<?x?xi16>
    %alloc_11 = memref.alloc(%c12) : memref<?xf16>
    %alloc_12 = memref.alloc(%c9) : memref<?x16xi64>
    %alloc_13 = memref.alloc(%c21) : memref<?xf16>
    %alloc_14 = memref.alloc(%c6) : memref<?xi1>
    %12 = builtin.unrealized_conversion_cast %alloc_14 : memref<?xi1> to !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>
    %alloc_15 = memref.alloc(%c9) : memref<?xi32>
    %alloc_16 = memref.alloc(%c9) : memref<?xi16>
    %13 = spirv.CL.s_abs %c1941353413_i32 : i32
    %alloc_17 = memref.alloc() : memref<16xi1>
    %14 = llvm.extractvalue %12[1] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %15 = llvm.getelementptr %14[%4] : (!llvm.ptr, i64) -> !llvm.ptr, i1
    %16 = llvm.load %15 {alignment = 1 : i64} : !llvm.ptr -> vector<16xi1>
    %17 = affine.vector_load %alloc_16[%c25] : memref<?xi16>, vector<3xi16>
    memref.store %c22394_i16, %alloc_16[%c0] : memref<?xi16>
    %18 = spirv.GL.FMix %cst_1 : f16, %cst_3 : f16, %cst_3 : f16 -> f16
    %19 = spirv.CL.fabs %18 : f16
    %20 = spirv.GL.Log %cst_1 : f16
    %21 = spirv.GL.InverseSqrt %cst_3 : f16
    %22 = spirv.GL.Acos %cst_4 : f16
    %23 = spirv.CL.cos %cst_4 : f16
    %24 = spirv.FOrdNotEqual %cst_3, %cst_4 : f16
    %25 = spirv.CL.pow %21, %20 : f16
    %26 = spirv.CL.exp %cst_3 : f16
    %27 = spirv.FOrdLessThanEqual %20, %cst_4 : f16
    %28 = spirv.CL.log %23 : f16
    %29 = spirv.FUnordNotEqual %cst_2, %cst_5 : f32
    scf.parallel (%arg3, %arg4) = (%c6, %c10) to (%c5, %c29) step (%c22, %c26) {
      memref.copy %alloc_13, %alloc_11 : memref<?xf16> to memref<?xf16>
      %435 = affine.if #set() -> memref<16xi16> {
        %alloc_19 = memref.alloc() : memref<16xi16>
        affine.yield %alloc_19 : memref<16xi16>
      } else {
        affine.store %13, %alloc_15[%c4] : memref<?xi32>
        %alloc_19 = memref.alloc() : memref<16xi16>
        affine.yield %alloc_19 : memref<16xi16>
      }
      bufferization.dealloc_tensor %8 : tensor<?x3xi1>
      scf.yield
    }
    %30 = spirv.CL.rint %cst_2 : f32
    %31 = spirv.CL.rint %28 : f16
    affine.vector_store %16, %alloc_14[%c24] : memref<?xi1>, vector<16xi1>
    %32 = spirv.CL.cos %22 : f16
    %33 = spirv.IsNan %cst_2 : f32
    %34 = spirv.BitReverse %c445093745_i32 : i32
    memref.store %c281204932_i64, %alloc_12[%c0, %c0] : memref<?x16xi64>
    %35 = spirv.GL.FSign %30 : f32
    %36 = spirv.CL.ceil %20 : f16
    %37 = llvm.mlir.undef : vector<16xf32>
    %38 = llvm.insertelement %30, %37[%0 : i32] : vector<16xf32>
    %39 = llvm.shufflevector %38, %37 [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] : vector<16xf32> 
    %40 = llvm.intr.fmuladd(%39, %39, %39)  : (vector<16xf32>, vector<16xf32>, vector<16xf32>) -> vector<16xf32>
    %41 = spirv.CL.s_min %c771421837_i32, %13 : i32
    bufferization.dealloc_tensor %9 : tensor<16xi64>
    %42 = affine.vector_load %arg1[%c0] : memref<?xf32>, vector<24xf32>
    %43 = spirv.CL.erf %21 : f16
    %44 = spirv.UGreaterThanEqual %c265471212_i64, %c281204932_i64 : i64
    %45 = spirv.GL.Acos %20 : f16
    %46 = spirv.CL.rint %cst_4 : f16
    %47 = builtin.unrealized_conversion_cast %cst_0 : vector<24x16xf32> to !llvm.array<24 x vector<16xf32>>
    %48 = llvm.extractvalue %2[0] : !llvm.array<24 x vector<16xf32>> 
    %49 = llvm.extractvalue %2[0] : !llvm.array<24 x vector<16xf32>> 
    %50 = llvm.extractvalue %2[0] : !llvm.array<24 x vector<16xf32>> 
    %51 = llvm.intr.fmuladd(%48, %49, %50)  : (vector<16xf32>, vector<16xf32>, vector<16xf32>) -> vector<16xf32>
    %52 = llvm.insertvalue %51, %47[0] : !llvm.array<24 x vector<16xf32>> 
    %53 = llvm.extractvalue %2[1] : !llvm.array<24 x vector<16xf32>> 
    %54 = llvm.extractvalue %2[1] : !llvm.array<24 x vector<16xf32>> 
    %55 = llvm.extractvalue %2[1] : !llvm.array<24 x vector<16xf32>> 
    %56 = llvm.intr.fmuladd(%53, %54, %55)  : (vector<16xf32>, vector<16xf32>, vector<16xf32>) -> vector<16xf32>
    %57 = llvm.insertvalue %56, %52[1] : !llvm.array<24 x vector<16xf32>> 
    %58 = llvm.extractvalue %2[2] : !llvm.array<24 x vector<16xf32>> 
    %59 = llvm.extractvalue %2[2] : !llvm.array<24 x vector<16xf32>> 
    %60 = llvm.extractvalue %2[2] : !llvm.array<24 x vector<16xf32>> 
    %61 = llvm.intr.fmuladd(%58, %59, %60)  : (vector<16xf32>, vector<16xf32>, vector<16xf32>) -> vector<16xf32>
    %62 = llvm.insertvalue %61, %57[2] : !llvm.array<24 x vector<16xf32>> 
    %63 = llvm.extractvalue %2[3] : !llvm.array<24 x vector<16xf32>> 
    %64 = llvm.extractvalue %2[3] : !llvm.array<24 x vector<16xf32>> 
    %65 = llvm.extractvalue %2[3] : !llvm.array<24 x vector<16xf32>> 
    %66 = llvm.intr.fmuladd(%63, %64, %65)  : (vector<16xf32>, vector<16xf32>, vector<16xf32>) -> vector<16xf32>
    %67 = llvm.insertvalue %66, %62[3] : !llvm.array<24 x vector<16xf32>> 
    %68 = llvm.extractvalue %2[4] : !llvm.array<24 x vector<16xf32>> 
    %69 = llvm.extractvalue %2[4] : !llvm.array<24 x vector<16xf32>> 
    %70 = llvm.extractvalue %2[4] : !llvm.array<24 x vector<16xf32>> 
    %71 = llvm.intr.fmuladd(%68, %69, %70)  : (vector<16xf32>, vector<16xf32>, vector<16xf32>) -> vector<16xf32>
    %72 = llvm.insertvalue %71, %67[4] : !llvm.array<24 x vector<16xf32>> 
    %73 = llvm.extractvalue %2[5] : !llvm.array<24 x vector<16xf32>> 
    %74 = llvm.extractvalue %2[5] : !llvm.array<24 x vector<16xf32>> 
    %75 = llvm.extractvalue %2[5] : !llvm.array<24 x vector<16xf32>> 
    %76 = llvm.intr.fmuladd(%73, %74, %75)  : (vector<16xf32>, vector<16xf32>, vector<16xf32>) -> vector<16xf32>
    %77 = llvm.insertvalue %76, %72[5] : !llvm.array<24 x vector<16xf32>> 
    %78 = llvm.extractvalue %2[6] : !llvm.array<24 x vector<16xf32>> 
    %79 = llvm.extractvalue %2[6] : !llvm.array<24 x vector<16xf32>> 
    %80 = llvm.extractvalue %2[6] : !llvm.array<24 x vector<16xf32>> 
    %81 = llvm.intr.fmuladd(%78, %79, %80)  : (vector<16xf32>, vector<16xf32>, vector<16xf32>) -> vector<16xf32>
    %82 = llvm.insertvalue %81, %77[6] : !llvm.array<24 x vector<16xf32>> 
    %83 = llvm.extractvalue %2[7] : !llvm.array<24 x vector<16xf32>> 
    %84 = llvm.extractvalue %2[7] : !llvm.array<24 x vector<16xf32>> 
    %85 = llvm.extractvalue %2[7] : !llvm.array<24 x vector<16xf32>> 
    %86 = llvm.intr.fmuladd(%83, %84, %85)  : (vector<16xf32>, vector<16xf32>, vector<16xf32>) -> vector<16xf32>
    %87 = llvm.insertvalue %86, %82[7] : !llvm.array<24 x vector<16xf32>> 
    %88 = llvm.extractvalue %2[8] : !llvm.array<24 x vector<16xf32>> 
    %89 = llvm.extractvalue %2[8] : !llvm.array<24 x vector<16xf32>> 
    %90 = llvm.extractvalue %2[8] : !llvm.array<24 x vector<16xf32>> 
    %91 = llvm.intr.fmuladd(%88, %89, %90)  : (vector<16xf32>, vector<16xf32>, vector<16xf32>) -> vector<16xf32>
    %92 = llvm.insertvalue %91, %87[8] : !llvm.array<24 x vector<16xf32>> 
    %93 = llvm.extractvalue %2[9] : !llvm.array<24 x vector<16xf32>> 
    %94 = llvm.extractvalue %2[9] : !llvm.array<24 x vector<16xf32>> 
    %95 = llvm.extractvalue %2[9] : !llvm.array<24 x vector<16xf32>> 
    %96 = llvm.intr.fmuladd(%93, %94, %95)  : (vector<16xf32>, vector<16xf32>, vector<16xf32>) -> vector<16xf32>
    %97 = llvm.insertvalue %96, %92[9] : !llvm.array<24 x vector<16xf32>> 
    %98 = llvm.extractvalue %2[10] : !llvm.array<24 x vector<16xf32>> 
    %99 = llvm.extractvalue %2[10] : !llvm.array<24 x vector<16xf32>> 
    %100 = llvm.extractvalue %2[10] : !llvm.array<24 x vector<16xf32>> 
    %101 = llvm.intr.fmuladd(%98, %99, %100)  : (vector<16xf32>, vector<16xf32>, vector<16xf32>) -> vector<16xf32>
    %102 = llvm.insertvalue %101, %97[10] : !llvm.array<24 x vector<16xf32>> 
    %103 = llvm.extractvalue %2[11] : !llvm.array<24 x vector<16xf32>> 
    %104 = llvm.extractvalue %2[11] : !llvm.array<24 x vector<16xf32>> 
    %105 = llvm.extractvalue %2[11] : !llvm.array<24 x vector<16xf32>> 
    %106 = llvm.intr.fmuladd(%103, %104, %105)  : (vector<16xf32>, vector<16xf32>, vector<16xf32>) -> vector<16xf32>
    %107 = llvm.insertvalue %106, %102[11] : !llvm.array<24 x vector<16xf32>> 
    %108 = llvm.extractvalue %2[12] : !llvm.array<24 x vector<16xf32>> 
    %109 = llvm.extractvalue %2[12] : !llvm.array<24 x vector<16xf32>> 
    %110 = llvm.extractvalue %2[12] : !llvm.array<24 x vector<16xf32>> 
    %111 = llvm.intr.fmuladd(%108, %109, %110)  : (vector<16xf32>, vector<16xf32>, vector<16xf32>) -> vector<16xf32>
    %112 = llvm.insertvalue %111, %107[12] : !llvm.array<24 x vector<16xf32>> 
    %113 = llvm.extractvalue %2[13] : !llvm.array<24 x vector<16xf32>> 
    %114 = llvm.extractvalue %2[13] : !llvm.array<24 x vector<16xf32>> 
    %115 = llvm.extractvalue %2[13] : !llvm.array<24 x vector<16xf32>> 
    %116 = llvm.intr.fmuladd(%113, %114, %115)  : (vector<16xf32>, vector<16xf32>, vector<16xf32>) -> vector<16xf32>
    %117 = llvm.insertvalue %116, %112[13] : !llvm.array<24 x vector<16xf32>> 
    %118 = llvm.extractvalue %2[14] : !llvm.array<24 x vector<16xf32>> 
    %119 = llvm.extractvalue %2[14] : !llvm.array<24 x vector<16xf32>> 
    %120 = llvm.extractvalue %2[14] : !llvm.array<24 x vector<16xf32>> 
    %121 = llvm.intr.fmuladd(%118, %119, %120)  : (vector<16xf32>, vector<16xf32>, vector<16xf32>) -> vector<16xf32>
    %122 = llvm.insertvalue %121, %117[14] : !llvm.array<24 x vector<16xf32>> 
    %123 = llvm.extractvalue %2[15] : !llvm.array<24 x vector<16xf32>> 
    %124 = llvm.extractvalue %2[15] : !llvm.array<24 x vector<16xf32>> 
    %125 = llvm.extractvalue %2[15] : !llvm.array<24 x vector<16xf32>> 
    %126 = llvm.intr.fmuladd(%123, %124, %125)  : (vector<16xf32>, vector<16xf32>, vector<16xf32>) -> vector<16xf32>
    %127 = llvm.insertvalue %126, %122[15] : !llvm.array<24 x vector<16xf32>> 
    %128 = llvm.extractvalue %2[16] : !llvm.array<24 x vector<16xf32>> 
    %129 = llvm.extractvalue %2[16] : !llvm.array<24 x vector<16xf32>> 
    %130 = llvm.extractvalue %2[16] : !llvm.array<24 x vector<16xf32>> 
    %131 = llvm.intr.fmuladd(%128, %129, %130)  : (vector<16xf32>, vector<16xf32>, vector<16xf32>) -> vector<16xf32>
    %132 = llvm.insertvalue %131, %127[16] : !llvm.array<24 x vector<16xf32>> 
    %133 = llvm.extractvalue %2[17] : !llvm.array<24 x vector<16xf32>> 
    %134 = llvm.extractvalue %2[17] : !llvm.array<24 x vector<16xf32>> 
    %135 = llvm.extractvalue %2[17] : !llvm.array<24 x vector<16xf32>> 
    %136 = llvm.intr.fmuladd(%133, %134, %135)  : (vector<16xf32>, vector<16xf32>, vector<16xf32>) -> vector<16xf32>
    %137 = llvm.insertvalue %136, %132[17] : !llvm.array<24 x vector<16xf32>> 
    %138 = llvm.extractvalue %2[18] : !llvm.array<24 x vector<16xf32>> 
    %139 = llvm.extractvalue %2[18] : !llvm.array<24 x vector<16xf32>> 
    %140 = llvm.extractvalue %2[18] : !llvm.array<24 x vector<16xf32>> 
    %141 = llvm.intr.fmuladd(%138, %139, %140)  : (vector<16xf32>, vector<16xf32>, vector<16xf32>) -> vector<16xf32>
    %142 = llvm.insertvalue %141, %137[18] : !llvm.array<24 x vector<16xf32>> 
    %143 = llvm.extractvalue %2[19] : !llvm.array<24 x vector<16xf32>> 
    %144 = llvm.extractvalue %2[19] : !llvm.array<24 x vector<16xf32>> 
    %145 = llvm.extractvalue %2[19] : !llvm.array<24 x vector<16xf32>> 
    %146 = llvm.intr.fmuladd(%143, %144, %145)  : (vector<16xf32>, vector<16xf32>, vector<16xf32>) -> vector<16xf32>
    %147 = llvm.insertvalue %146, %142[19] : !llvm.array<24 x vector<16xf32>> 
    %148 = llvm.extractvalue %2[20] : !llvm.array<24 x vector<16xf32>> 
    %149 = llvm.extractvalue %2[20] : !llvm.array<24 x vector<16xf32>> 
    %150 = llvm.extractvalue %2[20] : !llvm.array<24 x vector<16xf32>> 
    %151 = llvm.intr.fmuladd(%148, %149, %150)  : (vector<16xf32>, vector<16xf32>, vector<16xf32>) -> vector<16xf32>
    %152 = llvm.insertvalue %151, %147[20] : !llvm.array<24 x vector<16xf32>> 
    %153 = llvm.extractvalue %2[21] : !llvm.array<24 x vector<16xf32>> 
    %154 = llvm.extractvalue %2[21] : !llvm.array<24 x vector<16xf32>> 
    %155 = llvm.extractvalue %2[21] : !llvm.array<24 x vector<16xf32>> 
    %156 = llvm.intr.fmuladd(%153, %154, %155)  : (vector<16xf32>, vector<16xf32>, vector<16xf32>) -> vector<16xf32>
    %157 = llvm.insertvalue %156, %152[21] : !llvm.array<24 x vector<16xf32>> 
    %158 = llvm.extractvalue %2[22] : !llvm.array<24 x vector<16xf32>> 
    %159 = llvm.extractvalue %2[22] : !llvm.array<24 x vector<16xf32>> 
    %160 = llvm.extractvalue %2[22] : !llvm.array<24 x vector<16xf32>> 
    %161 = llvm.intr.fmuladd(%158, %159, %160)  : (vector<16xf32>, vector<16xf32>, vector<16xf32>) -> vector<16xf32>
    %162 = llvm.insertvalue %161, %157[22] : !llvm.array<24 x vector<16xf32>> 
    %163 = llvm.extractvalue %2[23] : !llvm.array<24 x vector<16xf32>> 
    %164 = llvm.extractvalue %2[23] : !llvm.array<24 x vector<16xf32>> 
    %165 = llvm.extractvalue %2[23] : !llvm.array<24 x vector<16xf32>> 
    %166 = llvm.intr.fmuladd(%163, %164, %165)  : (vector<16xf32>, vector<16xf32>, vector<16xf32>) -> vector<16xf32>
    %167 = llvm.insertvalue %166, %162[23] : !llvm.array<24 x vector<16xf32>> 
    %168 = builtin.unrealized_conversion_cast %167 : !llvm.array<24 x vector<16xf32>> to vector<24x16xf32>
    %169 = spirv.CL.log %19 : f16
    %170 = spirv.CL.ceil %22 : f16
    %171 = spirv.CL.s_max %c771421837_i32, %c1941353413_i32 : i32
    %172 = spirv.GL.Asin %23 : f16
    %173 = llvm.bitcast %40 : vector<16xf32> to vector<16xi32>
    %174 = arith.extui %16 : vector<16xi1> to vector<16xi8>
    vector.print punctuation <open>
    scf.for %arg3 = %c0 to %c16 step %c1 {
      %435 = vector.extractelement %174[%arg3 : index] : vector<16xi8>
      vector.print %435 : i8 punctuation <no_punctuation>
      %436 = arith.cmpi ult, %arg3, %c15 : index
      scf.if %436 {
        vector.print punctuation <comma>
      }
    }
    vector.print punctuation <close>
    vector.print
    %175 = spirv.FOrdGreaterThan %cst_4, %26 : f16
    %176 = spirv.CL.exp %cst_1 : f16
    %177 = spirv.CL.round %23 : f16
    %178 = spirv.CL.floor %177 : f16
    %179 = spirv.IEqual %c-29278_i16, %c22394_i16 : i16
    %180 = spirv.CL.pow %46, %26 : f16
    %181 = affine.load %alloc_12[%c30, %c4] : memref<?x16xi64>
    %182 = spirv.CL.cos %19 : f16
    %183 = spirv.CL.rsqrt %21 : f16
    %184 = memref.realloc %alloc : memref<?xf16> to memref<3xf16>
    linalg.transpose ins(%alloc_13 : memref<?xf16>) outs(%alloc : memref<?xf16>) permutation = [0] 
    %185 = spirv.GL.Cosh %31 : f16
    %186 = spirv.UGreaterThan %c-29278_i16, %c22394_i16 : i16
    %187 = spirv.CL.ceil %32 : f16
    scf.parallel (%arg3) = (%c13) to (%idx432) step (%c7) {
      vector.warp_execute_on_lane_0(%c0)[32] {
        memref.copy %arg1, %arg1 : memref<?xf32> to memref<?xf32>
      }
      memref.copy %alloc_10, %alloc_10 : memref<?x?xi16> to memref<?x?xi16>
      %435 = memref.realloc %alloc_15 : memref<?xi32> to memref<3xi32>
      scf.yield
    }
    %188 = spirv.CL.erf %32 : f16
    %189 = spirv.GL.UMax %34, %c1941353413_i32 : i32
    %190 = spirv.GL.Floor %185 : f16
    %191 = spirv.GL.SSign %c4623_i16 : i16
    %192 = spirv.CL.tanh %20 : f16
    %193 = spirv.GL.FSign %19 : f16
    linalg.transpose ins(%10 : tensor<16xi1>) outs(%alloc_17 : memref<16xi1>) permutation = [0] 
    %194 = spirv.GL.FMax %26, %43 : f16
    %195 = spirv.GL.UClamp %c4623_i16, %c4623_i16, %c22394_i16 : i16
    %196 = spirv.CL.log %cst_1 : f16
    %197 = spirv.Unordered %20, %26 : f16
    %198 = llvm.extractvalue %11[1] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %199 = llvm.getelementptr %198[%5] : (!llvm.ptr, i64) -> !llvm.ptr, f32
    %200 = llvm.getelementptr %199[%3] : (!llvm.ptr, vector<16xi64>) -> !llvm.vec<16 x ptr>, f32
    llvm.intr.masked.scatter %39, %200, %cst_7 {alignment = 4 : i32} : vector<16xf32>, vector<16xi1> into !llvm.vec<16 x ptr>
    %201 = spirv.FUnordLessThanEqual %21, %182 : f16
    %alloc_18 = memref.alloc() : memref<16x3xi64>
    %202 = builtin.unrealized_conversion_cast %alloc_18 : memref<16x3xi64> to !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)>
    %203 = llvm.mlir.undef : !llvm.array<24 x vector<16xi64>>
    %204 = llvm.mlir.undef : vector<16xi64>
    %205 = llvm.insertelement %181, %204[%0 : i32] : vector<16xi64>
    %206 = llvm.shufflevector %205, %205 [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] : vector<16xi64> 
    %207 = llvm.insertvalue %206, %203[0] : !llvm.array<24 x vector<16xi64>> 
    %208 = llvm.insertvalue %206, %207[1] : !llvm.array<24 x vector<16xi64>> 
    %209 = llvm.insertvalue %206, %208[2] : !llvm.array<24 x vector<16xi64>> 
    %210 = llvm.insertvalue %206, %209[3] : !llvm.array<24 x vector<16xi64>> 
    %211 = llvm.insertvalue %206, %210[4] : !llvm.array<24 x vector<16xi64>> 
    %212 = llvm.insertvalue %206, %211[5] : !llvm.array<24 x vector<16xi64>> 
    %213 = llvm.insertvalue %206, %212[6] : !llvm.array<24 x vector<16xi64>> 
    %214 = llvm.insertvalue %206, %213[7] : !llvm.array<24 x vector<16xi64>> 
    %215 = llvm.insertvalue %206, %214[8] : !llvm.array<24 x vector<16xi64>> 
    %216 = llvm.insertvalue %206, %215[9] : !llvm.array<24 x vector<16xi64>> 
    %217 = llvm.insertvalue %206, %216[10] : !llvm.array<24 x vector<16xi64>> 
    %218 = llvm.insertvalue %206, %217[11] : !llvm.array<24 x vector<16xi64>> 
    %219 = llvm.insertvalue %206, %218[12] : !llvm.array<24 x vector<16xi64>> 
    %220 = llvm.insertvalue %206, %219[13] : !llvm.array<24 x vector<16xi64>> 
    %221 = llvm.insertvalue %206, %220[14] : !llvm.array<24 x vector<16xi64>> 
    %222 = llvm.insertvalue %206, %221[15] : !llvm.array<24 x vector<16xi64>> 
    %223 = llvm.insertvalue %206, %222[16] : !llvm.array<24 x vector<16xi64>> 
    %224 = llvm.insertvalue %206, %223[17] : !llvm.array<24 x vector<16xi64>> 
    %225 = llvm.insertvalue %206, %224[18] : !llvm.array<24 x vector<16xi64>> 
    %226 = llvm.insertvalue %206, %225[19] : !llvm.array<24 x vector<16xi64>> 
    %227 = llvm.insertvalue %206, %226[20] : !llvm.array<24 x vector<16xi64>> 
    %228 = llvm.insertvalue %206, %227[21] : !llvm.array<24 x vector<16xi64>> 
    %229 = llvm.insertvalue %206, %228[22] : !llvm.array<24 x vector<16xi64>> 
    %230 = llvm.insertvalue %206, %229[23] : !llvm.array<24 x vector<16xi64>> 
    %231 = builtin.unrealized_conversion_cast %230 : !llvm.array<24 x vector<16xi64>> to vector<24x16xi64>
    %232 = llvm.mlir.undef : !llvm.array<24 x vector<16xi1>>
    %233 = llvm.mlir.undef : vector<16xi1>
    %234 = llvm.insertelement %197, %233[%0 : i32] : vector<16xi1>
    %235 = llvm.shufflevector %234, %234 [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] : vector<16xi1> 
    %236 = llvm.insertvalue %235, %232[0] : !llvm.array<24 x vector<16xi1>> 
    %237 = llvm.insertvalue %235, %236[1] : !llvm.array<24 x vector<16xi1>> 
    %238 = llvm.insertvalue %235, %237[2] : !llvm.array<24 x vector<16xi1>> 
    %239 = llvm.insertvalue %235, %238[3] : !llvm.array<24 x vector<16xi1>> 
    %240 = llvm.insertvalue %235, %239[4] : !llvm.array<24 x vector<16xi1>> 
    %241 = llvm.insertvalue %235, %240[5] : !llvm.array<24 x vector<16xi1>> 
    %242 = llvm.insertvalue %235, %241[6] : !llvm.array<24 x vector<16xi1>> 
    %243 = llvm.insertvalue %235, %242[7] : !llvm.array<24 x vector<16xi1>> 
    %244 = llvm.insertvalue %235, %243[8] : !llvm.array<24 x vector<16xi1>> 
    %245 = llvm.insertvalue %235, %244[9] : !llvm.array<24 x vector<16xi1>> 
    %246 = llvm.insertvalue %235, %245[10] : !llvm.array<24 x vector<16xi1>> 
    %247 = llvm.insertvalue %235, %246[11] : !llvm.array<24 x vector<16xi1>> 
    %248 = llvm.insertvalue %235, %247[12] : !llvm.array<24 x vector<16xi1>> 
    %249 = llvm.insertvalue %235, %248[13] : !llvm.array<24 x vector<16xi1>> 
    %250 = llvm.insertvalue %235, %249[14] : !llvm.array<24 x vector<16xi1>> 
    %251 = llvm.insertvalue %235, %250[15] : !llvm.array<24 x vector<16xi1>> 
    %252 = llvm.insertvalue %235, %251[16] : !llvm.array<24 x vector<16xi1>> 
    %253 = llvm.insertvalue %235, %252[17] : !llvm.array<24 x vector<16xi1>> 
    %254 = llvm.insertvalue %235, %253[18] : !llvm.array<24 x vector<16xi1>> 
    %255 = llvm.insertvalue %235, %254[19] : !llvm.array<24 x vector<16xi1>> 
    %256 = llvm.insertvalue %235, %255[20] : !llvm.array<24 x vector<16xi1>> 
    %257 = llvm.insertvalue %235, %256[21] : !llvm.array<24 x vector<16xi1>> 
    %258 = llvm.insertvalue %235, %257[22] : !llvm.array<24 x vector<16xi1>> 
    %259 = llvm.insertvalue %235, %258[23] : !llvm.array<24 x vector<16xi1>> 
    %260 = builtin.unrealized_conversion_cast %259 : !llvm.array<24 x vector<16xi1>> to vector<24x16xi1>
    %261 = llvm.mlir.undef : !llvm.array<24 x vector<16xi32>>
    %262 = llvm.mlir.undef : vector<16xi32>
    %263 = llvm.insertelement %189, %262[%0 : i32] : vector<16xi32>
    %264 = llvm.shufflevector %263, %263 [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] : vector<16xi32> 
    %265 = llvm.insertvalue %264, %261[0] : !llvm.array<24 x vector<16xi32>> 
    %266 = llvm.insertvalue %264, %265[1] : !llvm.array<24 x vector<16xi32>> 
    %267 = llvm.insertvalue %264, %266[2] : !llvm.array<24 x vector<16xi32>> 
    %268 = llvm.insertvalue %264, %267[3] : !llvm.array<24 x vector<16xi32>> 
    %269 = llvm.insertvalue %264, %268[4] : !llvm.array<24 x vector<16xi32>> 
    %270 = llvm.insertvalue %264, %269[5] : !llvm.array<24 x vector<16xi32>> 
    %271 = llvm.insertvalue %264, %270[6] : !llvm.array<24 x vector<16xi32>> 
    %272 = llvm.insertvalue %264, %271[7] : !llvm.array<24 x vector<16xi32>> 
    %273 = llvm.insertvalue %264, %272[8] : !llvm.array<24 x vector<16xi32>> 
    %274 = llvm.insertvalue %264, %273[9] : !llvm.array<24 x vector<16xi32>> 
    %275 = llvm.insertvalue %264, %274[10] : !llvm.array<24 x vector<16xi32>> 
    %276 = llvm.insertvalue %264, %275[11] : !llvm.array<24 x vector<16xi32>> 
    %277 = llvm.insertvalue %264, %276[12] : !llvm.array<24 x vector<16xi32>> 
    %278 = llvm.insertvalue %264, %277[13] : !llvm.array<24 x vector<16xi32>> 
    %279 = llvm.insertvalue %264, %278[14] : !llvm.array<24 x vector<16xi32>> 
    %280 = llvm.insertvalue %264, %279[15] : !llvm.array<24 x vector<16xi32>> 
    %281 = llvm.insertvalue %264, %280[16] : !llvm.array<24 x vector<16xi32>> 
    %282 = llvm.insertvalue %264, %281[17] : !llvm.array<24 x vector<16xi32>> 
    %283 = llvm.insertvalue %264, %282[18] : !llvm.array<24 x vector<16xi32>> 
    %284 = llvm.insertvalue %264, %283[19] : !llvm.array<24 x vector<16xi32>> 
    %285 = llvm.insertvalue %264, %284[20] : !llvm.array<24 x vector<16xi32>> 
    %286 = llvm.insertvalue %264, %285[21] : !llvm.array<24 x vector<16xi32>> 
    %287 = llvm.insertvalue %264, %286[22] : !llvm.array<24 x vector<16xi32>> 
    %288 = llvm.insertvalue %264, %287[23] : !llvm.array<24 x vector<16xi32>> 
    %289 = builtin.unrealized_conversion_cast %288 : !llvm.array<24 x vector<16xi32>> to vector<24x16xi32>
    %290 = llvm.extractvalue %202[1] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %291 = llvm.mul %6, %1  : i64
    %292 = llvm.add %291, %7  : i64
    %293 = llvm.getelementptr %290[%292] : (!llvm.ptr, i64) -> !llvm.ptr, i64
    %294 = llvm.mlir.undef : !llvm.array<24 x vector<16xi64>>
    %295 = llvm.getelementptr %293[%264] : (!llvm.ptr, vector<16xi32>) -> !llvm.vec<16 x ptr>, i64
    %296 = llvm.intr.masked.gather %295, %235, %206 {alignment = 8 : i32} : (!llvm.vec<16 x ptr>, vector<16xi1>, vector<16xi64>) -> vector<16xi64>
    %297 = llvm.insertvalue %296, %294[0] : !llvm.array<24 x vector<16xi64>> 
    %298 = llvm.getelementptr %293[%264] : (!llvm.ptr, vector<16xi32>) -> !llvm.vec<16 x ptr>, i64
    %299 = llvm.intr.masked.gather %298, %235, %206 {alignment = 8 : i32} : (!llvm.vec<16 x ptr>, vector<16xi1>, vector<16xi64>) -> vector<16xi64>
    %300 = llvm.insertvalue %299, %297[1] : !llvm.array<24 x vector<16xi64>> 
    %301 = llvm.getelementptr %293[%264] : (!llvm.ptr, vector<16xi32>) -> !llvm.vec<16 x ptr>, i64
    %302 = llvm.intr.masked.gather %301, %235, %206 {alignment = 8 : i32} : (!llvm.vec<16 x ptr>, vector<16xi1>, vector<16xi64>) -> vector<16xi64>
    %303 = llvm.insertvalue %302, %300[2] : !llvm.array<24 x vector<16xi64>> 
    %304 = llvm.getelementptr %293[%264] : (!llvm.ptr, vector<16xi32>) -> !llvm.vec<16 x ptr>, i64
    %305 = llvm.intr.masked.gather %304, %235, %206 {alignment = 8 : i32} : (!llvm.vec<16 x ptr>, vector<16xi1>, vector<16xi64>) -> vector<16xi64>
    %306 = llvm.insertvalue %305, %303[3] : !llvm.array<24 x vector<16xi64>> 
    %307 = llvm.getelementptr %293[%264] : (!llvm.ptr, vector<16xi32>) -> !llvm.vec<16 x ptr>, i64
    %308 = llvm.intr.masked.gather %307, %235, %206 {alignment = 8 : i32} : (!llvm.vec<16 x ptr>, vector<16xi1>, vector<16xi64>) -> vector<16xi64>
    %309 = llvm.insertvalue %308, %306[4] : !llvm.array<24 x vector<16xi64>> 
    %310 = llvm.getelementptr %293[%264] : (!llvm.ptr, vector<16xi32>) -> !llvm.vec<16 x ptr>, i64
    %311 = llvm.intr.masked.gather %310, %235, %206 {alignment = 8 : i32} : (!llvm.vec<16 x ptr>, vector<16xi1>, vector<16xi64>) -> vector<16xi64>
    %312 = llvm.insertvalue %311, %309[5] : !llvm.array<24 x vector<16xi64>> 
    %313 = llvm.getelementptr %293[%264] : (!llvm.ptr, vector<16xi32>) -> !llvm.vec<16 x ptr>, i64
    %314 = llvm.intr.masked.gather %313, %235, %206 {alignment = 8 : i32} : (!llvm.vec<16 x ptr>, vector<16xi1>, vector<16xi64>) -> vector<16xi64>
    %315 = llvm.insertvalue %314, %312[6] : !llvm.array<24 x vector<16xi64>> 
    %316 = llvm.getelementptr %293[%264] : (!llvm.ptr, vector<16xi32>) -> !llvm.vec<16 x ptr>, i64
    %317 = llvm.intr.masked.gather %316, %235, %206 {alignment = 8 : i32} : (!llvm.vec<16 x ptr>, vector<16xi1>, vector<16xi64>) -> vector<16xi64>
    %318 = llvm.insertvalue %317, %315[7] : !llvm.array<24 x vector<16xi64>> 
    %319 = llvm.getelementptr %293[%264] : (!llvm.ptr, vector<16xi32>) -> !llvm.vec<16 x ptr>, i64
    %320 = llvm.intr.masked.gather %319, %235, %206 {alignment = 8 : i32} : (!llvm.vec<16 x ptr>, vector<16xi1>, vector<16xi64>) -> vector<16xi64>
    %321 = llvm.insertvalue %320, %318[8] : !llvm.array<24 x vector<16xi64>> 
    %322 = llvm.getelementptr %293[%264] : (!llvm.ptr, vector<16xi32>) -> !llvm.vec<16 x ptr>, i64
    %323 = llvm.intr.masked.gather %322, %235, %206 {alignment = 8 : i32} : (!llvm.vec<16 x ptr>, vector<16xi1>, vector<16xi64>) -> vector<16xi64>
    %324 = llvm.insertvalue %323, %321[9] : !llvm.array<24 x vector<16xi64>> 
    %325 = llvm.getelementptr %293[%264] : (!llvm.ptr, vector<16xi32>) -> !llvm.vec<16 x ptr>, i64
    %326 = llvm.intr.masked.gather %325, %235, %206 {alignment = 8 : i32} : (!llvm.vec<16 x ptr>, vector<16xi1>, vector<16xi64>) -> vector<16xi64>
    %327 = llvm.insertvalue %326, %324[10] : !llvm.array<24 x vector<16xi64>> 
    %328 = llvm.getelementptr %293[%264] : (!llvm.ptr, vector<16xi32>) -> !llvm.vec<16 x ptr>, i64
    %329 = llvm.intr.masked.gather %328, %235, %206 {alignment = 8 : i32} : (!llvm.vec<16 x ptr>, vector<16xi1>, vector<16xi64>) -> vector<16xi64>
    %330 = llvm.insertvalue %329, %327[11] : !llvm.array<24 x vector<16xi64>> 
    %331 = llvm.getelementptr %293[%264] : (!llvm.ptr, vector<16xi32>) -> !llvm.vec<16 x ptr>, i64
    %332 = llvm.intr.masked.gather %331, %235, %206 {alignment = 8 : i32} : (!llvm.vec<16 x ptr>, vector<16xi1>, vector<16xi64>) -> vector<16xi64>
    %333 = llvm.insertvalue %332, %330[12] : !llvm.array<24 x vector<16xi64>> 
    %334 = llvm.getelementptr %293[%264] : (!llvm.ptr, vector<16xi32>) -> !llvm.vec<16 x ptr>, i64
    %335 = llvm.intr.masked.gather %334, %235, %206 {alignment = 8 : i32} : (!llvm.vec<16 x ptr>, vector<16xi1>, vector<16xi64>) -> vector<16xi64>
    %336 = llvm.insertvalue %335, %333[13] : !llvm.array<24 x vector<16xi64>> 
    %337 = llvm.getelementptr %293[%264] : (!llvm.ptr, vector<16xi32>) -> !llvm.vec<16 x ptr>, i64
    %338 = llvm.intr.masked.gather %337, %235, %206 {alignment = 8 : i32} : (!llvm.vec<16 x ptr>, vector<16xi1>, vector<16xi64>) -> vector<16xi64>
    %339 = llvm.insertvalue %338, %336[14] : !llvm.array<24 x vector<16xi64>> 
    %340 = llvm.getelementptr %293[%264] : (!llvm.ptr, vector<16xi32>) -> !llvm.vec<16 x ptr>, i64
    %341 = llvm.intr.masked.gather %340, %235, %206 {alignment = 8 : i32} : (!llvm.vec<16 x ptr>, vector<16xi1>, vector<16xi64>) -> vector<16xi64>
    %342 = llvm.insertvalue %341, %339[15] : !llvm.array<24 x vector<16xi64>> 
    %343 = llvm.getelementptr %293[%264] : (!llvm.ptr, vector<16xi32>) -> !llvm.vec<16 x ptr>, i64
    %344 = llvm.intr.masked.gather %343, %235, %206 {alignment = 8 : i32} : (!llvm.vec<16 x ptr>, vector<16xi1>, vector<16xi64>) -> vector<16xi64>
    %345 = llvm.insertvalue %344, %342[16] : !llvm.array<24 x vector<16xi64>> 
    %346 = llvm.getelementptr %293[%264] : (!llvm.ptr, vector<16xi32>) -> !llvm.vec<16 x ptr>, i64
    %347 = llvm.intr.masked.gather %346, %235, %206 {alignment = 8 : i32} : (!llvm.vec<16 x ptr>, vector<16xi1>, vector<16xi64>) -> vector<16xi64>
    %348 = llvm.insertvalue %347, %345[17] : !llvm.array<24 x vector<16xi64>> 
    %349 = llvm.getelementptr %293[%264] : (!llvm.ptr, vector<16xi32>) -> !llvm.vec<16 x ptr>, i64
    %350 = llvm.intr.masked.gather %349, %235, %206 {alignment = 8 : i32} : (!llvm.vec<16 x ptr>, vector<16xi1>, vector<16xi64>) -> vector<16xi64>
    %351 = llvm.insertvalue %350, %348[18] : !llvm.array<24 x vector<16xi64>> 
    %352 = llvm.getelementptr %293[%264] : (!llvm.ptr, vector<16xi32>) -> !llvm.vec<16 x ptr>, i64
    %353 = llvm.intr.masked.gather %352, %235, %206 {alignment = 8 : i32} : (!llvm.vec<16 x ptr>, vector<16xi1>, vector<16xi64>) -> vector<16xi64>
    %354 = llvm.insertvalue %353, %351[19] : !llvm.array<24 x vector<16xi64>> 
    %355 = llvm.getelementptr %293[%264] : (!llvm.ptr, vector<16xi32>) -> !llvm.vec<16 x ptr>, i64
    %356 = llvm.intr.masked.gather %355, %235, %206 {alignment = 8 : i32} : (!llvm.vec<16 x ptr>, vector<16xi1>, vector<16xi64>) -> vector<16xi64>
    %357 = llvm.insertvalue %356, %354[20] : !llvm.array<24 x vector<16xi64>> 
    %358 = llvm.getelementptr %293[%264] : (!llvm.ptr, vector<16xi32>) -> !llvm.vec<16 x ptr>, i64
    %359 = llvm.intr.masked.gather %358, %235, %206 {alignment = 8 : i32} : (!llvm.vec<16 x ptr>, vector<16xi1>, vector<16xi64>) -> vector<16xi64>
    %360 = llvm.insertvalue %359, %357[21] : !llvm.array<24 x vector<16xi64>> 
    %361 = llvm.getelementptr %293[%264] : (!llvm.ptr, vector<16xi32>) -> !llvm.vec<16 x ptr>, i64
    %362 = llvm.intr.masked.gather %361, %235, %206 {alignment = 8 : i32} : (!llvm.vec<16 x ptr>, vector<16xi1>, vector<16xi64>) -> vector<16xi64>
    %363 = llvm.insertvalue %362, %360[22] : !llvm.array<24 x vector<16xi64>> 
    %364 = llvm.getelementptr %293[%264] : (!llvm.ptr, vector<16xi32>) -> !llvm.vec<16 x ptr>, i64
    %365 = llvm.intr.masked.gather %364, %235, %206 {alignment = 8 : i32} : (!llvm.vec<16 x ptr>, vector<16xi1>, vector<16xi64>) -> vector<16xi64>
    %366 = llvm.insertvalue %365, %363[23] : !llvm.array<24 x vector<16xi64>> 
    %367 = builtin.unrealized_conversion_cast %366 : !llvm.array<24 x vector<16xi64>> to vector<24x16xi64>
    %368 = llvm.mlir.undef : vector<1xf32>
    %369 = llvm.insertelement %30, %368[%0 : i32] : vector<1xf32>
    %370 = builtin.unrealized_conversion_cast %369 : vector<1xf32> to vector<f32>
    %371 = spirv.LogicalEqual %24, %false : i1
    %372 = arith.extui %16 : vector<16xi1> to vector<16xi8>
    vector.print punctuation <open>
    scf.for %arg3 = %c0 to %c16 step %c1 {
      %435 = vector.extractelement %372[%arg3 : index] : vector<16xi8>
      vector.print %435 : i8 punctuation <no_punctuation>
      %436 = arith.cmpi ult, %arg3, %c15 : index
      scf.if %436 {
        vector.print punctuation <comma>
      }
    }
    vector.print punctuation <close>
    vector.print
    vector.print punctuation <open>
    scf.for %arg3 = %c0 to %c3 step %c1 {
      %435 = vector.extractelement %17[%arg3 : index] : vector<3xi16>
      vector.print %435 : i16 punctuation <no_punctuation>
      %436 = arith.cmpi ult, %arg3, %c2 : index
      scf.if %436 {
        vector.print punctuation <comma>
      }
    }
    vector.print punctuation <close>
    vector.print
    vector.print punctuation <open>
    scf.for %arg3 = %c0 to %c3 step %c1 {
      %435 = vector.extractelement %17[%arg3 : index] : vector<3xi16>
      vector.print %435 : i16 punctuation <no_punctuation>
      %436 = arith.cmpi ult, %arg3, %c2 : index
      scf.if %436 {
        vector.print punctuation <comma>
      }
    }
    vector.print punctuation <close>
    vector.print
    vector.print punctuation <open>
    scf.for %arg3 = %c0 to %c16 step %c1 {
      %435 = vector.extractelement %39[%arg3 : index] : vector<16xf32>
      vector.print %435 : f32 punctuation <no_punctuation>
      %436 = arith.cmpi ult, %arg3, %c15 : index
      scf.if %436 {
        vector.print punctuation <comma>
      }
    }
    vector.print punctuation <close>
    vector.print
    vector.print punctuation <open>
    scf.for %arg3 = %c0 to %c16 step %c1 {
      %435 = vector.extractelement %40[%arg3 : index] : vector<16xf32>
      vector.print %435 : f32 punctuation <no_punctuation>
      %436 = arith.cmpi ult, %arg3, %c15 : index
      scf.if %436 {
        vector.print punctuation <comma>
      }
    }
    vector.print punctuation <close>
    vector.print
    vector.print punctuation <open>
    scf.for %arg3 = %c0 to %c24 step %c1 {
      %435 = vector.extractelement %42[%arg3 : index] : vector<24xf32>
      vector.print %435 : f32 punctuation <no_punctuation>
      %436 = arith.cmpi ult, %arg3, %c23 : index
      scf.if %436 {
        vector.print punctuation <comma>
      }
    }
    vector.print punctuation <close>
    vector.print
    %373 = vector.shape_cast %cst_8 : vector<24x16xf32> to vector<384xf32>
    vector.print punctuation <open>
    scf.for %arg3 = %c0 to %c24 step %c1 {
      vector.print punctuation <open>
      scf.for %arg4 = %c0 to %c16 step %c1 {
        %436 = arith.muli %arg3, %c16 : index
        %437 = arith.addi %arg4, %436 : index
        %438 = vector.extractelement %373[%437 : index] : vector<384xf32>
        vector.print %438 : f32 punctuation <no_punctuation>
        %439 = arith.cmpi ult, %arg4, %c15 : index
        scf.if %439 {
          vector.print punctuation <comma>
        }
      }
      vector.print punctuation <close>
      %435 = arith.cmpi ult, %arg3, %c23 : index
      scf.if %435 {
        vector.print punctuation <comma>
      }
    }
    vector.print punctuation <close>
    vector.print
    %374 = vector.shape_cast %168 : vector<24x16xf32> to vector<384xf32>
    vector.print punctuation <open>
    scf.for %arg3 = %c0 to %c24 step %c1 {
      vector.print punctuation <open>
      scf.for %arg4 = %c0 to %c16 step %c1 {
        %436 = arith.muli %arg3, %c16 : index
        %437 = arith.addi %arg4, %436 : index
        %438 = vector.extractelement %374[%437 : index] : vector<384xf32>
        vector.print %438 : f32 punctuation <no_punctuation>
        %439 = arith.cmpi ult, %arg4, %c15 : index
        scf.if %439 {
          vector.print punctuation <comma>
        }
      }
      vector.print punctuation <close>
      %435 = arith.cmpi ult, %arg3, %c23 : index
      scf.if %435 {
        vector.print punctuation <comma>
      }
    }
    vector.print punctuation <close>
    vector.print
    vector.print punctuation <open>
    scf.for %arg3 = %c0 to %c16 step %c1 {
      %435 = vector.extractelement %173[%arg3 : index] : vector<16xi32>
      vector.print %435 : i32 punctuation <no_punctuation>
      %436 = arith.cmpi ult, %arg3, %c15 : index
      scf.if %436 {
        vector.print punctuation <comma>
      }
    }
    vector.print punctuation <close>
    vector.print
    vector.print punctuation <open>
    scf.for %arg3 = %c0 to %c16 step %c1 {
      %435 = vector.extractelement %cst[%arg3 : index] : vector<16xi8>
      vector.print %435 : i8 punctuation <no_punctuation>
      %436 = arith.cmpi ult, %arg3, %c15 : index
      scf.if %436 {
        vector.print punctuation <comma>
      }
    }
    vector.print punctuation <close>
    vector.print
    %375 = vector.shape_cast %231 : vector<24x16xi64> to vector<384xi64>
    vector.print punctuation <open>
    scf.for %arg3 = %c0 to %c24 step %c1 {
      vector.print punctuation <open>
      scf.for %arg4 = %c0 to %c16 step %c1 {
        %436 = arith.muli %arg3, %c16 : index
        %437 = arith.addi %arg4, %436 : index
        %438 = vector.extractelement %375[%437 : index] : vector<384xi64>
        vector.print %438 : i64 punctuation <no_punctuation>
        %439 = arith.cmpi ult, %arg4, %c15 : index
        scf.if %439 {
          vector.print punctuation <comma>
        }
      }
      vector.print punctuation <close>
      %435 = arith.cmpi ult, %arg3, %c23 : index
      scf.if %435 {
        vector.print punctuation <comma>
      }
    }
    vector.print punctuation <close>
    vector.print
    %376 = arith.extui %260 : vector<24x16xi1> to vector<24x16xi8>
    %377 = vector.shape_cast %376 : vector<24x16xi8> to vector<384xi8>
    vector.print punctuation <open>
    scf.for %arg3 = %c0 to %c24 step %c1 {
      vector.print punctuation <open>
      scf.for %arg4 = %c0 to %c16 step %c1 {
        %436 = arith.muli %arg3, %c16 : index
        %437 = arith.addi %arg4, %436 : index
        %438 = vector.extractelement %377[%437 : index] : vector<384xi8>
        vector.print %438 : i8 punctuation <no_punctuation>
        %439 = arith.cmpi ult, %arg4, %c15 : index
        scf.if %439 {
          vector.print punctuation <comma>
        }
      }
      vector.print punctuation <close>
      %435 = arith.cmpi ult, %arg3, %c23 : index
      scf.if %435 {
        vector.print punctuation <comma>
      }
    }
    vector.print punctuation <close>
    vector.print
    %378 = vector.shape_cast %289 : vector<24x16xi32> to vector<384xi32>
    vector.print punctuation <open>
    scf.for %arg3 = %c0 to %c24 step %c1 {
      vector.print punctuation <open>
      scf.for %arg4 = %c0 to %c16 step %c1 {
        %436 = arith.muli %arg3, %c16 : index
        %437 = arith.addi %arg4, %436 : index
        %438 = vector.extractelement %378[%437 : index] : vector<384xi32>
        vector.print %438 : i32 punctuation <no_punctuation>
        %439 = arith.cmpi ult, %arg4, %c15 : index
        scf.if %439 {
          vector.print punctuation <comma>
        }
      }
      vector.print punctuation <close>
      %435 = arith.cmpi ult, %arg3, %c23 : index
      scf.if %435 {
        vector.print punctuation <comma>
      }
    }
    vector.print punctuation <close>
    vector.print
    %379 = vector.shape_cast %367 : vector<24x16xi64> to vector<384xi64>
    vector.print punctuation <open>
    scf.for %arg3 = %c0 to %c24 step %c1 {
      vector.print punctuation <open>
      scf.for %arg4 = %c0 to %c16 step %c1 {
        %436 = arith.muli %arg3, %c16 : index
        %437 = arith.addi %arg4, %436 : index
        %438 = vector.extractelement %379[%437 : index] : vector<384xi64>
        vector.print %438 : i64 punctuation <no_punctuation>
        %439 = arith.cmpi ult, %arg4, %c15 : index
        scf.if %439 {
          vector.print punctuation <comma>
        }
      }
      vector.print punctuation <close>
      %435 = arith.cmpi ult, %arg3, %c23 : index
      scf.if %435 {
        vector.print punctuation <comma>
      }
    }
    vector.print punctuation <close>
    vector.print
    %380 = vector.shape_cast %370 : vector<f32> to vector<1xf32>
    vector.print punctuation <open>
    scf.for %arg3 = %c0 to %c1 step %c1 {
      %435 = vector.extractelement %380[%arg3 : index] : vector<1xf32>
      vector.print %435 : f32 punctuation <no_punctuation>
      %436 = arith.cmpi ult, %arg3, %c0 : index
      scf.if %436 {
        vector.print punctuation <comma>
      }
    }
    vector.print punctuation <close>
    vector.print
    %381 = arith.extui %arg2 : i1 to i64
    llvm.call @printI64(%381) : (i64) -> ()
    llvm.call @printNewline() : () -> ()
    llvm.call @printI64(%c0_i64) : (i64) -> ()
    llvm.call @printNewline() : () -> ()
    llvm.call @printI64(%c265471212_i64) : (i64) -> ()
    llvm.call @printNewline() : () -> ()
    llvm.call @printI64(%c4623_i64) : (i64) -> ()
    llvm.call @printNewline() : () -> ()
    llvm.call @printI64(%c22394_i64) : (i64) -> ()
    llvm.call @printNewline() : () -> ()
    llvm.call @printI64(%c0_i64) : (i64) -> ()
    llvm.call @printNewline() : () -> ()
    llvm.call @printI64(%c1941353413_i64) : (i64) -> ()
    llvm.call @printNewline() : () -> ()
    llvm.call @printI64(%c-29278_i64) : (i64) -> ()
    llvm.call @printNewline() : () -> ()
    llvm.call @printI64(%c281204932_i64) : (i64) -> ()
    llvm.call @printNewline() : () -> ()
    llvm.call @printF32(%cst_5) : (f32) -> ()
    llvm.call @printNewline() : () -> ()
    %382 = llvm.bitcast %cst_4 : f16 to i16
    llvm.call @printF16(%382) : (i16) -> ()
    llvm.call @printNewline() : () -> ()
    %383 = llvm.bitcast %cst_3 : f16 to i16
    llvm.call @printF16(%383) : (i16) -> ()
    llvm.call @printNewline() : () -> ()
    llvm.call @printI64(%c771421837_i64) : (i64) -> ()
    llvm.call @printNewline() : () -> ()
    llvm.call @printI64(%c445093745_i64) : (i64) -> ()
    llvm.call @printNewline() : () -> ()
    llvm.call @printI64(%c1_i64) : (i64) -> ()
    llvm.call @printNewline() : () -> ()
    llvm.call @printF32(%cst_2) : (f32) -> ()
    llvm.call @printNewline() : () -> ()
    %384 = llvm.bitcast %cst_1 : f16 to i16
    llvm.call @printF16(%384) : (i16) -> ()
    llvm.call @printNewline() : () -> ()
    %385 = arith.extsi %13 : i32 to i64
    llvm.call @printI64(%385) : (i64) -> ()
    llvm.call @printNewline() : () -> ()
    %386 = llvm.bitcast %18 : f16 to i16
    llvm.call @printF16(%386) : (i16) -> ()
    llvm.call @printNewline() : () -> ()
    %387 = llvm.bitcast %19 : f16 to i16
    llvm.call @printF16(%387) : (i16) -> ()
    llvm.call @printNewline() : () -> ()
    %388 = llvm.bitcast %20 : f16 to i16
    llvm.call @printF16(%388) : (i16) -> ()
    llvm.call @printNewline() : () -> ()
    %389 = llvm.bitcast %21 : f16 to i16
    llvm.call @printF16(%389) : (i16) -> ()
    llvm.call @printNewline() : () -> ()
    %390 = llvm.bitcast %22 : f16 to i16
    llvm.call @printF16(%390) : (i16) -> ()
    llvm.call @printNewline() : () -> ()
    %391 = llvm.bitcast %23 : f16 to i16
    llvm.call @printF16(%391) : (i16) -> ()
    llvm.call @printNewline() : () -> ()
    %392 = arith.extui %24 : i1 to i64
    llvm.call @printI64(%392) : (i64) -> ()
    llvm.call @printNewline() : () -> ()
    %393 = llvm.bitcast %25 : f16 to i16
    llvm.call @printF16(%393) : (i16) -> ()
    llvm.call @printNewline() : () -> ()
    %394 = llvm.bitcast %26 : f16 to i16
    llvm.call @printF16(%394) : (i16) -> ()
    llvm.call @printNewline() : () -> ()
    %395 = arith.extui %27 : i1 to i64
    llvm.call @printI64(%395) : (i64) -> ()
    llvm.call @printNewline() : () -> ()
    %396 = llvm.bitcast %28 : f16 to i16
    llvm.call @printF16(%396) : (i16) -> ()
    llvm.call @printNewline() : () -> ()
    %397 = arith.extui %29 : i1 to i64
    llvm.call @printI64(%397) : (i64) -> ()
    llvm.call @printNewline() : () -> ()
    llvm.call @printF32(%30) : (f32) -> ()
    llvm.call @printNewline() : () -> ()
    %398 = llvm.bitcast %31 : f16 to i16
    llvm.call @printF16(%398) : (i16) -> ()
    llvm.call @printNewline() : () -> ()
    %399 = llvm.bitcast %32 : f16 to i16
    llvm.call @printF16(%399) : (i16) -> ()
    llvm.call @printNewline() : () -> ()
    %400 = arith.extui %33 : i1 to i64
    llvm.call @printI64(%400) : (i64) -> ()
    llvm.call @printNewline() : () -> ()
    %401 = arith.extsi %34 : i32 to i64
    llvm.call @printI64(%401) : (i64) -> ()
    llvm.call @printNewline() : () -> ()
    llvm.call @printF32(%35) : (f32) -> ()
    llvm.call @printNewline() : () -> ()
    %402 = llvm.bitcast %36 : f16 to i16
    llvm.call @printF16(%402) : (i16) -> ()
    llvm.call @printNewline() : () -> ()
    %403 = arith.extsi %41 : i32 to i64
    llvm.call @printI64(%403) : (i64) -> ()
    llvm.call @printNewline() : () -> ()
    %404 = llvm.bitcast %43 : f16 to i16
    llvm.call @printF16(%404) : (i16) -> ()
    llvm.call @printNewline() : () -> ()
    %405 = arith.extui %44 : i1 to i64
    llvm.call @printI64(%405) : (i64) -> ()
    llvm.call @printNewline() : () -> ()
    %406 = llvm.bitcast %45 : f16 to i16
    llvm.call @printF16(%406) : (i16) -> ()
    llvm.call @printNewline() : () -> ()
    %407 = llvm.bitcast %46 : f16 to i16
    llvm.call @printF16(%407) : (i16) -> ()
    llvm.call @printNewline() : () -> ()
    %408 = llvm.bitcast %169 : f16 to i16
    llvm.call @printF16(%408) : (i16) -> ()
    llvm.call @printNewline() : () -> ()
    %409 = llvm.bitcast %170 : f16 to i16
    llvm.call @printF16(%409) : (i16) -> ()
    llvm.call @printNewline() : () -> ()
    %410 = arith.extsi %171 : i32 to i64
    llvm.call @printI64(%410) : (i64) -> ()
    llvm.call @printNewline() : () -> ()
    %411 = llvm.bitcast %172 : f16 to i16
    llvm.call @printF16(%411) : (i16) -> ()
    llvm.call @printNewline() : () -> ()
    %412 = arith.extui %175 : i1 to i64
    llvm.call @printI64(%412) : (i64) -> ()
    llvm.call @printNewline() : () -> ()
    %413 = llvm.bitcast %176 : f16 to i16
    llvm.call @printF16(%413) : (i16) -> ()
    llvm.call @printNewline() : () -> ()
    %414 = llvm.bitcast %177 : f16 to i16
    llvm.call @printF16(%414) : (i16) -> ()
    llvm.call @printNewline() : () -> ()
    %415 = llvm.bitcast %178 : f16 to i16
    llvm.call @printF16(%415) : (i16) -> ()
    llvm.call @printNewline() : () -> ()
    %416 = arith.extui %179 : i1 to i64
    llvm.call @printI64(%416) : (i64) -> ()
    llvm.call @printNewline() : () -> ()
    %417 = llvm.bitcast %180 : f16 to i16
    llvm.call @printF16(%417) : (i16) -> ()
    llvm.call @printNewline() : () -> ()
    llvm.call @printI64(%181) : (i64) -> ()
    llvm.call @printNewline() : () -> ()
    %418 = llvm.bitcast %182 : f16 to i16
    llvm.call @printF16(%418) : (i16) -> ()
    llvm.call @printNewline() : () -> ()
    %419 = llvm.bitcast %183 : f16 to i16
    llvm.call @printF16(%419) : (i16) -> ()
    llvm.call @printNewline() : () -> ()
    %420 = llvm.bitcast %185 : f16 to i16
    llvm.call @printF16(%420) : (i16) -> ()
    llvm.call @printNewline() : () -> ()
    %421 = arith.extui %186 : i1 to i64
    llvm.call @printI64(%421) : (i64) -> ()
    llvm.call @printNewline() : () -> ()
    %422 = llvm.bitcast %187 : f16 to i16
    llvm.call @printF16(%422) : (i16) -> ()
    llvm.call @printNewline() : () -> ()
    %423 = llvm.bitcast %188 : f16 to i16
    llvm.call @printF16(%423) : (i16) -> ()
    llvm.call @printNewline() : () -> ()
    %424 = arith.extsi %189 : i32 to i64
    llvm.call @printI64(%424) : (i64) -> ()
    llvm.call @printNewline() : () -> ()
    %425 = llvm.bitcast %190 : f16 to i16
    llvm.call @printF16(%425) : (i16) -> ()
    llvm.call @printNewline() : () -> ()
    %426 = arith.extsi %191 : i16 to i64
    llvm.call @printI64(%426) : (i64) -> ()
    llvm.call @printNewline() : () -> ()
    %427 = llvm.bitcast %192 : f16 to i16
    llvm.call @printF16(%427) : (i16) -> ()
    llvm.call @printNewline() : () -> ()
    %428 = llvm.bitcast %193 : f16 to i16
    llvm.call @printF16(%428) : (i16) -> ()
    llvm.call @printNewline() : () -> ()
    %429 = llvm.bitcast %194 : f16 to i16
    llvm.call @printF16(%429) : (i16) -> ()
    llvm.call @printNewline() : () -> ()
    %430 = arith.extsi %195 : i16 to i64
    llvm.call @printI64(%430) : (i64) -> ()
    llvm.call @printNewline() : () -> ()
    %431 = llvm.bitcast %196 : f16 to i16
    llvm.call @printF16(%431) : (i16) -> ()
    llvm.call @printNewline() : () -> ()
    %432 = arith.extui %197 : i1 to i64
    llvm.call @printI64(%432) : (i64) -> ()
    llvm.call @printNewline() : () -> ()
    %433 = arith.extui %201 : i1 to i64
    llvm.call @printI64(%433) : (i64) -> ()
    llvm.call @printNewline() : () -> ()
    %434 = arith.extui %371 : i1 to i64
    llvm.call @printI64(%434) : (i64) -> ()
    llvm.call @printNewline() : () -> ()
    return
  }
  func.func @func2() {
    %cst = arith.constant dense<22394> : vector<i16>
    %cst_0 = arith.constant dense<4623> : vector<3xi16>
    %cst_1 = arith.constant dense<771421837> : vector<2xi32>
    %c29 = arith.constant 29 : index
    %false = arith.constant false
    %c265471212_i64 = arith.constant 265471212 : i64
    %c4623_i16 = arith.constant 4623 : i16
    %c-29278_i16 = arith.constant -29278 : i16
    %c281204932_i64 = arith.constant 281204932 : i64
    %cst_2 = arith.constant 0x4D08837C : f32
    %cst_3 = arith.constant 3.350400e+04 : f16
    %cst_4 = arith.constant 5.033600e+04 : f16
    %c771421837_i32 = arith.constant 771421837 : i32
    %c445093745_i32 = arith.constant 445093745 : i32
    %true = arith.constant true
    %cst_5 = arith.constant 0x4E228E1D : f32
    %cst_6 = arith.constant 1.731200e+04 : f16
    %c5 = arith.constant 5 : index
    %c6 = arith.constant 6 : index
    %c7 = arith.constant 7 : index
    %c9 = arith.constant 9 : index
    %c10 = arith.constant 10 : index
    %c11 = arith.constant 11 : index
    %c12 = arith.constant 12 : index
    %c13 = arith.constant 13 : index
    %c14 = arith.constant 14 : index
    %c17 = arith.constant 17 : index
    %c22 = arith.constant 22 : index
    %c23 = arith.constant 23 : index
    %c25 = arith.constant 25 : index
    %c26 = arith.constant 26 : index
    %c27 = arith.constant 27 : index
    %c30 = arith.constant 30 : index
    %0 = llvm.mlir.constant(0 : i32) : i32
    %c1_i64 = arith.constant 1 : i64
    %c445093745_i64 = arith.constant 445093745 : i64
    %c771421837_i64 = arith.constant 771421837 : i64
    %c-29278_i64 = arith.constant -29278 : i64
    %c1941353413_i64 = arith.constant 1941353413 : i64
    %c22394_i64 = arith.constant 22394 : i64
    %c4623_i64 = arith.constant 4623 : i64
    %c0_i64 = arith.constant 0 : i64
    %cst_7 = arith.constant dense<4623> : vector<3x1xi16>
    %c15 = arith.constant 15 : index
    %c1 = arith.constant 1 : index
    %c3 = arith.constant 3 : index
    %c16 = arith.constant 16 : index
    %c2 = arith.constant 2 : index
    %c0 = arith.constant 0 : index
    %c24 = arith.constant 24 : index
    %1 = llvm.mlir.constant(0 : index) : i64
    %alloca = memref.alloca() : memref<vector<24x1xf16>>
    %alloca_8 = memref.alloca() : memref<vector<3x1xi16>>
    %2 = builtin.unrealized_conversion_cast %cst : vector<i16> to vector<1xi16>
    %3 = tensor.empty(%c23, %c25) : tensor<?x?xi16>
    %4 = tensor.empty(%c5, %c15) : tensor<?x?xf16>
    %5 = tensor.empty(%c17) : tensor<?x3xi1>
    %alloc = memref.alloc() : memref<16xf32>
    %alloc_9 = memref.alloc(%c12, %c26) : memref<?x?xi16>
    %alloc_10 = memref.alloc(%c10) : memref<?xi16>
    %alloc_11 = memref.alloc(%c27) : memref<?xf32>
    %alloc_12 = memref.alloc(%c22, %c11) : memref<?x?xf32>
    %alloc_13 = memref.alloc() : memref<16x3xi16>
    %alloc_14 = memref.alloc() : memref<16x3xf16>
    %alloc_15 = memref.alloc() : memref<16xf16>
    %alloc_16 = memref.alloc(%c9) : memref<?xi32>
    %alloc_17 = memref.alloc(%c9) : memref<?xi16>
    %alloc_18 = memref.alloc() : memref<24x16xi16>
    %6 = tensor.empty() : tensor<48xi64>
    %7 = spirv.GL.FMix %cst_3 : f16, %cst_4 : f16, %cst_3 : f16 -> f16
    %8 = spirv.FOrdEqual %7, %cst_3 : f16
    %9 = spirv.IsInf %cst_4 : f16
    %10 = spirv.GL.Cosh %cst_6 : f16
    %11 = spirv.CL.sin %10 : f16
    %12 = scf.while (%arg0 = %6) : (tensor<48xi64>) -> tensor<48xi64> {
      scf.condition(%false) %arg0 : tensor<48xi64>
    } do {
    ^bb0(%arg0: tensor<48xi64>):
      %106 = memref.realloc %alloc_17 : memref<?xi16> to memref<24xi16>
      %alloc_21 = memref.alloc(%c14, %c23) : memref<?x?xf16>
      memref.tensor_store %4, %alloc_21 : memref<?x?xf16>
      memref.alloca_scope  {
        memref.assume_alignment %alloc_12, 16 : memref<?x?xf32>
        %alloc_22 = memref.alloc(%c16) : memref<?x3xi1>
        memref.tensor_store %5, %alloc_22 : memref<?x3xi1>
      }
      vector.print punctuation <open>
      scf.for %arg1 = %c0 to %c2 step %c1 {
        %107 = vector.extractelement %cst_1[%arg1 : index] : vector<2xi32>
        vector.print %107 : i32 punctuation <no_punctuation>
        %108 = arith.cmpi ult, %arg1, %c1 : index
        scf.if %108 {
          vector.print punctuation <comma>
        }
      }
      vector.print punctuation <close>
      vector.print
      memref.assume_alignment %alloc_15, 4 : memref<16xf16>
      scf.yield %arg0 : tensor<48xi64>
    }
    %13 = spirv.CL.fabs %cst_3 : f16
    %14 = spirv.GL.Cosh %cst_2 : f32
    %15 = spirv.CL.rsqrt %13 : f16
    %16 = spirv.CL.cos %14 : f32
    %17 = spirv.GL.Cos %13 : f16
    vector.warp_execute_on_lane_0(%c0)[32] {
      scf.execute_region {
        %106 = memref.realloc %alloc_11 : memref<?xf32> to memref<14xf32>
        %107 = llvm.mlir.undef : vector<24xf16>
        %108 = llvm.insertelement %11, %107[%0 : i32] : vector<24xf16>
        %109 = llvm.shufflevector %108, %107 [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] : vector<24xf16> 
        %110 = vector.broadcast %109 : vector<24xf16> to vector<1x24xf16>
        %111 = vector.transpose %110, [1, 0] : vector<1x24xf16> to vector<24x1xf16>
        memref.store %111, %alloca[] : memref<vector<24x1xf16>>
        %112 = vector.type_cast %alloca : memref<vector<24x1xf16>> to memref<24xvector<1xf16>>
        scf.for %arg0 = %c0 to %c24 step %c1 {
          %113 = affine.apply #map(%arg0)
          %114 = memref.load %112[%arg0] : memref<24xvector<1xf16>>
          vector.transfer_write %114, %alloc_14[%113, %c9] {in_bounds = [true]} : vector<1xf16>, memref<16x3xf16>
        }
        scf.yield
      }
    }
    %18 = affine.if #set1() -> memref<24x16xi64> {
      memref.alloca_scope  {
        memref.copy %alloc_15, %alloc_15 : memref<16xf16> to memref<16xf16>
      }
      %alloc_21 = memref.alloc() : memref<24x16xi64>
      affine.yield %alloc_21 : memref<24x16xi64>
    } else {
      %alloc_21 = memref.alloc() : memref<24x16xi64>
      affine.yield %alloc_21 : memref<24x16xi64>
    }
    %19 = spirv.FUnordLessThan %cst_4, %13 : f16
    %20 = llvm.mlir.undef : vector<2xi1>
    %21 = llvm.insertelement %19, %20[%0 : i32] : vector<2xi1>
    %22 = llvm.shufflevector %21, %20 [0, 0] : vector<2xi1> 
    memref.store %cst_7, %alloca_8[] : memref<vector<3x1xi16>>
    %23 = vector.type_cast %alloca_8 : memref<vector<3x1xi16>> to memref<3xvector<1xi16>>
    scf.for %arg0 = %c0 to %c3 step %c1 {
      %106 = affine.apply #map1(%arg0)
      %107 = memref.load %23[%arg0] : memref<3xvector<1xi16>>
      vector.transfer_write %107, %alloc_13[%106, %c29] {in_bounds = [true]} : vector<1xi16>, memref<16x3xi16>
    }
    %24 = spirv.CL.rsqrt %cst_2 : f32
    %25 = spirv.FUnordLessThan %7, %10 : f16
    %26 = spirv.FUnordEqual %16, %14 : f32
    %27 = spirv.GL.UMax %c-29278_i16, %c-29278_i16 : i16
    %28 = spirv.FUnordGreaterThan %7, %cst_6 : f16
    %29 = llvm.extractelement %2[%1 : i64] : vector<1xi16>
    memref.store %29, %alloc_18[%c30, %c10] : memref<24x16xi16>
    %30 = spirv.CL.rsqrt %cst_6 : f16
    %31 = spirv.CL.ceil %16 : f32
    %32 = spirv.UGreaterThanEqual %c4623_i16, %27 : i16
    %33 = spirv.UGreaterThanEqual %c771421837_i32, %c771421837_i32 : i32
    %alloc_19 = memref.alloc() : memref<i32>
    %34 = scf.while (%arg0 = %26) : (i1) -> i1 {
      scf.condition(%true) %32 : i1
    } do {
    ^bb0(%arg0: i1):
      memref.copy %alloc_16, %alloc_16 : memref<?xi32> to memref<?xi32>
      memref.store %c4623_i16, %alloc_13[%c7, %c1] : memref<16x3xi16>
      memref.copy %alloc_12, %alloc_12 : memref<?x?xf32> to memref<?x?xf32>
      scf.yield %19 : i1
    }
    %35 = scf.parallel (%arg0, %arg1) = (%c10, %c9) to (%c29, %c14) step (%c13, %c6) init (%cst_2) -> f32 {
      vector.print punctuation <open>
      scf.for %arg2 = %c0 to %c3 step %c1 {
        %106 = vector.extractelement %cst_0[%arg2 : index] : vector<3xi16>
        vector.print %106 : i16 punctuation <no_punctuation>
        %107 = arith.cmpi ult, %arg2, %c2 : index
        scf.if %107 {
          vector.print punctuation <comma>
        }
      }
      vector.print punctuation <close>
      vector.print
      scf.reduce(%cst_2)  : f32 {
      ^bb0(%arg2: f32, %arg3: f32):
        scf.reduce.return %cst_5 : f32
      }
      scf.yield
    }
    %36 = spirv.GL.Atan %7 : f16
    %37 = spirv.CL.rsqrt %30 : f16
    linalg.transpose ins(%3 : tensor<?x?xi16>) outs(%alloc_9 : memref<?x?xi16>) permutation = [1, 0] 
    %38 = spirv.FUnordLessThanEqual %14, %16 : f32
    memref.copy %alloc_12, %alloc_12 : memref<?x?xf32> to memref<?x?xf32>
    %39 = spirv.CL.ceil %24 : f32
    %40 = spirv.GL.SAbs %c265471212_i64 : i64
    %41 = spirv.ULessThan %40, %c265471212_i64 : i64
    scf.parallel (%arg0) = (%c2) to (%c10) step (%c11) {
      %106 = memref.realloc %alloc_10 : memref<?xi16> to memref<16xi16>
      scf.yield
    }
    %42 = spirv.GL.FSign %39 : f32
    %43 = spirv.GL.FMix %10 : f16, %15 : f16, %7 : f16 -> f16
    %44 = spirv.GL.Log %cst_5 : f32
    %45 = spirv.GL.Atan %cst_4 : f16
    %46 = spirv.GL.FMax %7, %43 : f16
    %47 = spirv.CL.tanh %46 : f16
    vector.print punctuation <open>
    scf.for %arg0 = %c0 to %c3 step %c1 {
      %106 = vector.extractelement %cst_0[%arg0 : index] : vector<3xi16>
      vector.print %106 : i16 punctuation <no_punctuation>
      %107 = arith.cmpi ult, %arg0, %c2 : index
      scf.if %107 {
        vector.print punctuation <comma>
      }
    }
    vector.print punctuation <close>
    vector.print
    %48 = spirv.GL.Exp %46 : f16
    %49 = spirv.FUnordLessThan %7, %15 : f16
    %50 = spirv.CL.round %10 : f16
    %51 = spirv.CL.u_min %c-29278_i16, %c-29278_i16 : i16
    %52 = spirv.CL.u_max %c265471212_i64, %c281204932_i64 : i64
    memref.store %c445093745_i32, %alloc_19[] : memref<i32>
    %53 = spirv.Unordered %16, %cst_2 : f32
    %54 = spirv.CL.tanh %44 : f32
    %alloc_20 = memref.alloc() : memref<f16>
    affine.vector_store %cst_1, %alloc_19[] : memref<i32>, vector<2xi32>
    %55 = spirv.GL.Log %31 : f32
    %56 = spirv.IsNan %44 : f32
    %57 = scf.while (%arg0 = %cst) : (vector<i16>) -> vector<i16> {
      scf.condition(%56) %cst : vector<i16>
    } do {
    ^bb0(%arg0: vector<i16>):
      %106 = memref.atomic_rmw assign %31, %alloc[%c1] : (f32, memref<16xf32>) -> f32
      memref.copy %alloc_20, %alloc_20 : memref<f16> to memref<f16>
      scf.yield %cst : vector<i16>
    }
    %58 = spirv.GL.UClamp %40, %40, %40 : i64
    %59 = spirv.FOrdLessThanEqual %55, %14 : f32
    %60 = spirv.GL.Asin %36 : f16
    %61 = spirv.GL.Sqrt %cst_6 : f16
    %62 = llvm.mlir.undef : vector<16xf32>
    %63 = llvm.insertelement %42, %62[%0 : i32] : vector<16xf32>
    %64 = llvm.shufflevector %63, %62 [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] : vector<16xf32> 
    %65 = llvm.intr.fmuladd(%64, %64, %64)  : (vector<16xf32>, vector<16xf32>, vector<16xf32>) -> vector<16xf32>
    %66 = spirv.LogicalOr %33, %56 : i1
    vector.print punctuation <open>
    scf.for %arg0 = %c0 to %c2 step %c1 {
      %106 = vector.extractelement %cst_1[%arg0 : index] : vector<2xi32>
      vector.print %106 : i32 punctuation <no_punctuation>
      %107 = arith.cmpi ult, %arg0, %c1 : index
      scf.if %107 {
        vector.print punctuation <comma>
      }
    }
    vector.print punctuation <close>
    vector.print
    %67 = arith.extui %22 : vector<2xi1> to vector<2xi8>
    vector.print punctuation <open>
    scf.for %arg0 = %c0 to %c2 step %c1 {
      %106 = vector.extractelement %67[%arg0 : index] : vector<2xi8>
      vector.print %106 : i8 punctuation <no_punctuation>
      %107 = arith.cmpi ult, %arg0, %c1 : index
      scf.if %107 {
        vector.print punctuation <comma>
      }
    }
    vector.print punctuation <close>
    vector.print
    vector.print punctuation <open>
    scf.for %arg0 = %c0 to %c3 step %c1 {
      %106 = vector.extractelement %cst_0[%arg0 : index] : vector<3xi16>
      vector.print %106 : i16 punctuation <no_punctuation>
      %107 = arith.cmpi ult, %arg0, %c2 : index
      scf.if %107 {
        vector.print punctuation <comma>
      }
    }
    vector.print punctuation <close>
    vector.print
    %68 = vector.shape_cast %cst : vector<i16> to vector<1xi16>
    vector.print punctuation <open>
    scf.for %arg0 = %c0 to %c1 step %c1 {
      %106 = vector.extractelement %68[%arg0 : index] : vector<1xi16>
      vector.print %106 : i16 punctuation <no_punctuation>
      %107 = arith.cmpi ult, %arg0, %c0 : index
      scf.if %107 {
        vector.print punctuation <comma>
      }
    }
    vector.print punctuation <close>
    vector.print
    vector.print punctuation <open>
    scf.for %arg0 = %c0 to %c2 step %c1 {
      %106 = vector.extractelement %cst_1[%arg0 : index] : vector<2xi32>
      vector.print %106 : i32 punctuation <no_punctuation>
      %107 = arith.cmpi ult, %arg0, %c1 : index
      scf.if %107 {
        vector.print punctuation <comma>
      }
    }
    vector.print punctuation <close>
    vector.print
    vector.print punctuation <open>
    scf.for %arg0 = %c0 to %c16 step %c1 {
      %106 = vector.extractelement %64[%arg0 : index] : vector<16xf32>
      vector.print %106 : f32 punctuation <no_punctuation>
      %107 = arith.cmpi ult, %arg0, %c15 : index
      scf.if %107 {
        vector.print punctuation <comma>
      }
    }
    vector.print punctuation <close>
    vector.print
    vector.print punctuation <open>
    scf.for %arg0 = %c0 to %c16 step %c1 {
      %106 = vector.extractelement %65[%arg0 : index] : vector<16xf32>
      vector.print %106 : f32 punctuation <no_punctuation>
      %107 = arith.cmpi ult, %arg0, %c15 : index
      scf.if %107 {
        vector.print punctuation <comma>
      }
    }
    vector.print punctuation <close>
    vector.print
    llvm.call @printI64(%c0_i64) : (i64) -> ()
    llvm.call @printNewline() : () -> ()
    llvm.call @printI64(%c265471212_i64) : (i64) -> ()
    llvm.call @printNewline() : () -> ()
    llvm.call @printI64(%c4623_i64) : (i64) -> ()
    llvm.call @printNewline() : () -> ()
    llvm.call @printI64(%c22394_i64) : (i64) -> ()
    llvm.call @printNewline() : () -> ()
    llvm.call @printI64(%c0_i64) : (i64) -> ()
    llvm.call @printNewline() : () -> ()
    llvm.call @printI64(%c1941353413_i64) : (i64) -> ()
    llvm.call @printNewline() : () -> ()
    llvm.call @printI64(%c-29278_i64) : (i64) -> ()
    llvm.call @printNewline() : () -> ()
    llvm.call @printI64(%c281204932_i64) : (i64) -> ()
    llvm.call @printNewline() : () -> ()
    llvm.call @printF32(%cst_2) : (f32) -> ()
    llvm.call @printNewline() : () -> ()
    %69 = llvm.bitcast %cst_3 : f16 to i16
    llvm.call @printF16(%69) : (i16) -> ()
    llvm.call @printNewline() : () -> ()
    %70 = llvm.bitcast %cst_4 : f16 to i16
    llvm.call @printF16(%70) : (i16) -> ()
    llvm.call @printNewline() : () -> ()
    llvm.call @printI64(%c771421837_i64) : (i64) -> ()
    llvm.call @printNewline() : () -> ()
    llvm.call @printI64(%c445093745_i64) : (i64) -> ()
    llvm.call @printNewline() : () -> ()
    llvm.call @printI64(%c1_i64) : (i64) -> ()
    llvm.call @printNewline() : () -> ()
    llvm.call @printF32(%cst_5) : (f32) -> ()
    llvm.call @printNewline() : () -> ()
    %71 = llvm.bitcast %cst_6 : f16 to i16
    llvm.call @printF16(%71) : (i16) -> ()
    llvm.call @printNewline() : () -> ()
    %72 = llvm.bitcast %7 : f16 to i16
    llvm.call @printF16(%72) : (i16) -> ()
    llvm.call @printNewline() : () -> ()
    %73 = arith.extui %8 : i1 to i64
    llvm.call @printI64(%73) : (i64) -> ()
    llvm.call @printNewline() : () -> ()
    %74 = arith.extui %9 : i1 to i64
    llvm.call @printI64(%74) : (i64) -> ()
    llvm.call @printNewline() : () -> ()
    %75 = llvm.bitcast %10 : f16 to i16
    llvm.call @printF16(%75) : (i16) -> ()
    llvm.call @printNewline() : () -> ()
    %76 = llvm.bitcast %11 : f16 to i16
    llvm.call @printF16(%76) : (i16) -> ()
    llvm.call @printNewline() : () -> ()
    %77 = llvm.bitcast %13 : f16 to i16
    llvm.call @printF16(%77) : (i16) -> ()
    llvm.call @printNewline() : () -> ()
    llvm.call @printF32(%14) : (f32) -> ()
    llvm.call @printNewline() : () -> ()
    %78 = llvm.bitcast %15 : f16 to i16
    llvm.call @printF16(%78) : (i16) -> ()
    llvm.call @printNewline() : () -> ()
    llvm.call @printF32(%16) : (f32) -> ()
    llvm.call @printNewline() : () -> ()
    %79 = llvm.bitcast %17 : f16 to i16
    llvm.call @printF16(%79) : (i16) -> ()
    llvm.call @printNewline() : () -> ()
    %80 = arith.extui %19 : i1 to i64
    llvm.call @printI64(%80) : (i64) -> ()
    llvm.call @printNewline() : () -> ()
    llvm.call @printF32(%24) : (f32) -> ()
    llvm.call @printNewline() : () -> ()
    %81 = arith.extui %25 : i1 to i64
    llvm.call @printI64(%81) : (i64) -> ()
    llvm.call @printNewline() : () -> ()
    %82 = arith.extui %26 : i1 to i64
    llvm.call @printI64(%82) : (i64) -> ()
    llvm.call @printNewline() : () -> ()
    %83 = arith.extsi %27 : i16 to i64
    llvm.call @printI64(%83) : (i64) -> ()
    llvm.call @printNewline() : () -> ()
    %84 = arith.extui %28 : i1 to i64
    llvm.call @printI64(%84) : (i64) -> ()
    llvm.call @printNewline() : () -> ()
    %85 = llvm.bitcast %30 : f16 to i16
    llvm.call @printF16(%85) : (i16) -> ()
    llvm.call @printNewline() : () -> ()
    llvm.call @printF32(%31) : (f32) -> ()
    llvm.call @printNewline() : () -> ()
    %86 = arith.extui %32 : i1 to i64
    llvm.call @printI64(%86) : (i64) -> ()
    llvm.call @printNewline() : () -> ()
    %87 = arith.extui %33 : i1 to i64
    llvm.call @printI64(%87) : (i64) -> ()
    llvm.call @printNewline() : () -> ()
    %88 = llvm.bitcast %36 : f16 to i16
    llvm.call @printF16(%88) : (i16) -> ()
    llvm.call @printNewline() : () -> ()
    %89 = llvm.bitcast %37 : f16 to i16
    llvm.call @printF16(%89) : (i16) -> ()
    llvm.call @printNewline() : () -> ()
    %90 = arith.extui %38 : i1 to i64
    llvm.call @printI64(%90) : (i64) -> ()
    llvm.call @printNewline() : () -> ()
    llvm.call @printF32(%39) : (f32) -> ()
    llvm.call @printNewline() : () -> ()
    llvm.call @printI64(%40) : (i64) -> ()
    llvm.call @printNewline() : () -> ()
    %91 = arith.extui %41 : i1 to i64
    llvm.call @printI64(%91) : (i64) -> ()
    llvm.call @printNewline() : () -> ()
    llvm.call @printF32(%42) : (f32) -> ()
    llvm.call @printNewline() : () -> ()
    %92 = llvm.bitcast %43 : f16 to i16
    llvm.call @printF16(%92) : (i16) -> ()
    llvm.call @printNewline() : () -> ()
    llvm.call @printF32(%44) : (f32) -> ()
    llvm.call @printNewline() : () -> ()
    %93 = llvm.bitcast %45 : f16 to i16
    llvm.call @printF16(%93) : (i16) -> ()
    llvm.call @printNewline() : () -> ()
    %94 = llvm.bitcast %46 : f16 to i16
    llvm.call @printF16(%94) : (i16) -> ()
    llvm.call @printNewline() : () -> ()
    %95 = llvm.bitcast %47 : f16 to i16
    llvm.call @printF16(%95) : (i16) -> ()
    llvm.call @printNewline() : () -> ()
    %96 = llvm.bitcast %48 : f16 to i16
    llvm.call @printF16(%96) : (i16) -> ()
    llvm.call @printNewline() : () -> ()
    %97 = arith.extui %49 : i1 to i64
    llvm.call @printI64(%97) : (i64) -> ()
    llvm.call @printNewline() : () -> ()
    %98 = llvm.bitcast %50 : f16 to i16
    llvm.call @printF16(%98) : (i16) -> ()
    llvm.call @printNewline() : () -> ()
    %99 = arith.extsi %51 : i16 to i64
    llvm.call @printI64(%99) : (i64) -> ()
    llvm.call @printNewline() : () -> ()
    llvm.call @printI64(%52) : (i64) -> ()
    llvm.call @printNewline() : () -> ()
    %100 = arith.extui %53 : i1 to i64
    llvm.call @printI64(%100) : (i64) -> ()
    llvm.call @printNewline() : () -> ()
    llvm.call @printF32(%54) : (f32) -> ()
    llvm.call @printNewline() : () -> ()
    llvm.call @printF32(%55) : (f32) -> ()
    llvm.call @printNewline() : () -> ()
    %101 = arith.extui %56 : i1 to i64
    llvm.call @printI64(%101) : (i64) -> ()
    llvm.call @printNewline() : () -> ()
    llvm.call @printI64(%58) : (i64) -> ()
    llvm.call @printNewline() : () -> ()
    %102 = arith.extui %59 : i1 to i64
    llvm.call @printI64(%102) : (i64) -> ()
    llvm.call @printNewline() : () -> ()
    llvm.call @printI64(%c0_i64) : (i64) -> ()
    llvm.call @printNewline() : () -> ()
    %103 = llvm.bitcast %60 : f16 to i16
    llvm.call @printF16(%103) : (i16) -> ()
    llvm.call @printNewline() : () -> ()
    %104 = llvm.bitcast %61 : f16 to i16
    llvm.call @printF16(%104) : (i16) -> ()
    llvm.call @printNewline() : () -> ()
    %105 = arith.extui %66 : i1 to i64
    llvm.call @printI64(%105) : (i64) -> ()
    llvm.call @printNewline() : () -> ()
    return
  }
}


mlir-opt: /home/jacob/projects/MLIRSmith/mlir/lib/Dialect/LLVMIR/IR/LLVMTypes.cpp:267: mlir::LLVM::LLVMFunctionType mlir::LLVM::LLVMFunctionType::clone(mlir::TypeRange, mlir::TypeRange) const: Assertion `results.size() == 1 && "expected a single result type"' failed.
PLEASE submit a bug report to https://github.com/llvm/llvm-project/issues/ and include the crash backtrace.
Stack dump:
0.	Program arguments: ../build/bin/mlir-opt --split-input-file --convert-vector-to-llvm --convert-vector-to-scf --test-constant-fold --test-func-erase-result --mlir-print-ir-after-all --fold-memref-alias-ops --test-loop-permutation --buffer-results-to-out-params --test-remapped-value generated/temp6424929491774958848.mlir
Stack dump without symbol names (ensure you have llvm-symbolizer in your PATH or set the environment var `LLVM_SYMBOLIZER_PATH` to point to it):
0  mlir-opt        0x000055718b057bdb llvm::sys::PrintStackTrace(llvm::raw_ostream&, int) + 59
1  mlir-opt        0x000055718b0549cc
2  libpthread.so.0 0x00007f72f5336980
3  libc.so.6       0x00007f72f3f63e87 gsignal + 199
4  libc.so.6       0x00007f72f3f657f1 abort + 321
5  libc.so.6       0x00007f72f3f553fa
6  libc.so.6       0x00007f72f3f55472
7  mlir-opt        0x000055718beb3767 mlir::LLVM::LLVMFunctionType::clone(mlir::TypeRange, mlir::TypeRange) const + 199
8  mlir-opt        0x000055718bdbd7d1
9  mlir-opt        0x000055718d642304
10 mlir-opt        0x000055718d7cf301 mlir::detail::OpToOpPassAdaptor::run(mlir::Pass*, mlir::Operation*, mlir::AnalysisManager, bool, unsigned int) + 1297
11 mlir-opt        0x000055718d7d0223
12 mlir-opt        0x000055718d7d08c1 mlir::PassManager::run(mlir::Operation*) + 1153
13 mlir-opt        0x000055718d7c0efc
14 mlir-opt        0x000055718d7c28b5
15 mlir-opt        0x000055718d7c2a71
16 mlir-opt        0x000055718d8c7d3d
17 mlir-opt        0x000055718d8c8602 mlir::splitAndProcessBuffer(std::unique_ptr<llvm::MemoryBuffer, std::default_delete<llvm::MemoryBuffer>>, llvm::function_ref<mlir::LogicalResult (std::unique_ptr<llvm::MemoryBuffer, std::default_delete<llvm::MemoryBuffer>>, llvm::raw_ostream&)>, llvm::raw_ostream&, bool, bool) + 1026
18 mlir-opt        0x000055718d7bbbc9 mlir::MlirOptMain(llvm::raw_ostream&, std::unique_ptr<llvm::MemoryBuffer, std::default_delete<llvm::MemoryBuffer>>, mlir::DialectRegistry&, mlir::MlirOptMainConfig const&) + 185
19 mlir-opt        0x000055718d7c2d9a mlir::MlirOptMain(int, char**, llvm::StringRef, mlir::DialectRegistry&) + 746
20 mlir-opt        0x000055718afaa0c5 main + 165
21 libc.so.6       0x00007f72f3f46c87 __libc_start_main + 231
22 mlir-opt        0x000055718b02b95a _start + 42
Aborted
